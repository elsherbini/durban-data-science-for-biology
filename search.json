[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Keynote Speaker\nDr. Lenine Liebenberg\nChief Researcher\nCentre for Epidemic Response and Innovation (CERI) - Stellenbosch\nCentre for the AIDS Programme of Research in South Africa (CAPRISA) - UKZN\n\n\n\n\n\n\n\n\n\nWorkshop Instructor\nDr. Laura Symul\nAssistant Professor\nUCLouvain Institute of Statistics, Biostatistics and Actuarial Sciences\n\n\n\n\n\n\n\n\n\nWorkshop Instructor\nMarothi Peter Letsoalo\nSenior Biostatistician\nCentre for the AIDS Programme of Research in South Africa (CAPRISA) - UKZN\n\n\n\n\n\n\n\n\n\nWorkshop Instructor\nSalina Hussain\nResearch Technician\nRagon Institute of MGH, MIT and Harvard\n\n\n\n\n\n\n\n\n\nWorkshop Instructor\nSuuba Demby\nResearch Technician\nRagon Institute of MGH, MIT and Harvard\n\n\n\n\n\n\n\n\n\nSeries Organizer and Instructor\nDr. Scott Handley\nProfessor\nWashington University School of Medicine\nDepartment of Pathology and Immunology\n\n\n\n\n\n\n\n\n\nSeries Organizer and Instructor\nDr. Joseph Elsherbini\nData Scientist\nRagon Institute of MGH, MIT and Harvard\n\n\n\n\n\n\n\n\n\nSeries Organizer and Instructor\nChandani Desai\nProject Manager\nRagon Institute of MGH, MIT and Harvard\n\n\n\n\n\n\n\n\n\nSeries Logistics and Management\nSarah Eisa\nProgram Manager\nRagon Institute of MGH, MIT and Harvard\n\n\n\n\n\n\n\n\n\nTeaching Assistant\nDerek Tshiabuila\nPhD Research Fellow\nCentre for Epidemic Response and Innovation (CERI) - Stellenbosch\n\n\n\n\n\n\n\n\n\nTeaching Assistant\nAsavela Kama\nBioinformatician\nCentre for the AIDS Programme of Research in South Africa (CAPRISA) - UKZN\n\n\n\n\n\n\n\n\n\nTeaching Assistant\nAfrah Khairallah\nPostdoctoral research fellow Africa Health Research Institute (AHRI) - UKZN\n\n\n\n\n\n\n\n\n\nTeaching Assistant\nKwabena Asare\nStatistician\nCentre for the AIDS Programme of Research in South Africa (CAPRISA) - UKZN\n\n\n\n\n\n\n\n\n\nTeaching Assistant\nJohan van der Molen\nCentre for the AIDS Programme of Research in South Africa (CAPRISA) - UKZN\n\n\n\n\n\nTeaching Assistant\nWasim Abdool Karim\nBioinformatician Centre for Epidemic Response and Innovation (CERI) - Stellenbosch"
  },
  {
    "objectID": "about.html#reproducible-data-analysis-with-r---teaching-team",
    "href": "about.html#reproducible-data-analysis-with-r---teaching-team",
    "title": "About",
    "section": "",
    "text": "Keynote Speaker\nDr. Lenine Liebenberg\nChief Researcher\nCentre for Epidemic Response and Innovation (CERI) - Stellenbosch\nCentre for the AIDS Programme of Research in South Africa (CAPRISA) - UKZN\n\n\n\n\n\n\n\n\n\nWorkshop Instructor\nDr. Laura Symul\nAssistant Professor\nUCLouvain Institute of Statistics, Biostatistics and Actuarial Sciences\n\n\n\n\n\n\n\n\n\nWorkshop Instructor\nMarothi Peter Letsoalo\nSenior Biostatistician\nCentre for the AIDS Programme of Research in South Africa (CAPRISA) - UKZN\n\n\n\n\n\n\n\n\n\nWorkshop Instructor\nSalina Hussain\nResearch Technician\nRagon Institute of MGH, MIT and Harvard\n\n\n\n\n\n\n\n\n\nWorkshop Instructor\nSuuba Demby\nResearch Technician\nRagon Institute of MGH, MIT and Harvard\n\n\n\n\n\n\n\n\n\nSeries Organizer and Instructor\nDr. Scott Handley\nProfessor\nWashington University School of Medicine\nDepartment of Pathology and Immunology\n\n\n\n\n\n\n\n\n\nSeries Organizer and Instructor\nDr. Joseph Elsherbini\nData Scientist\nRagon Institute of MGH, MIT and Harvard\n\n\n\n\n\n\n\n\n\nSeries Organizer and Instructor\nChandani Desai\nProject Manager\nRagon Institute of MGH, MIT and Harvard\n\n\n\n\n\n\n\n\n\nSeries Logistics and Management\nSarah Eisa\nProgram Manager\nRagon Institute of MGH, MIT and Harvard\n\n\n\n\n\n\n\n\n\nTeaching Assistant\nDerek Tshiabuila\nPhD Research Fellow\nCentre for Epidemic Response and Innovation (CERI) - Stellenbosch\n\n\n\n\n\n\n\n\n\nTeaching Assistant\nAsavela Kama\nBioinformatician\nCentre for the AIDS Programme of Research in South Africa (CAPRISA) - UKZN\n\n\n\n\n\n\n\n\n\nTeaching Assistant\nAfrah Khairallah\nPostdoctoral research fellow Africa Health Research Institute (AHRI) - UKZN\n\n\n\n\n\n\n\n\n\nTeaching Assistant\nKwabena Asare\nStatistician\nCentre for the AIDS Programme of Research in South Africa (CAPRISA) - UKZN\n\n\n\n\n\n\n\n\n\nTeaching Assistant\nJohan van der Molen\nCentre for the AIDS Programme of Research in South Africa (CAPRISA) - UKZN\n\n\n\n\n\nTeaching Assistant\nWasim Abdool Karim\nBioinformatician Centre for Epidemic Response and Innovation (CERI) - Stellenbosch"
  },
  {
    "objectID": "about.html#about-these-materials",
    "href": "about.html#about-these-materials",
    "title": "About",
    "section": "About these materials",
    "text": "About these materials\nThis website started with the code from Andrew P. Bray’s workshop website and much of the R content has been remixed and adapted from SDS375, a course by Claus O. Wilke."
  },
  {
    "objectID": "datasets.html",
    "href": "datasets.html",
    "title": "Datasets",
    "section": "",
    "text": "Download here"
  },
  {
    "objectID": "datasets.html#icebreaker-survey",
    "href": "datasets.html#icebreaker-survey",
    "title": "Datasets",
    "section": "",
    "text": "Download here"
  },
  {
    "objectID": "datasets.html#download-the-instructional-dataset",
    "href": "datasets.html#download-the-instructional-dataset",
    "title": "Datasets",
    "section": "Download the instructional dataset:",
    "text": "Download the instructional dataset:\nThe main data set for use in lectures is split into 5 tables. The idea of this dataset is that there is a randomized controlled trial of a drug aimed at reducing HIV risk by reducing inflammation. There were 23 participants in the placebo arm and 21 in the treatment arm. There were 3 visits for the trial – baseline (before any treatment occurred), week_1 (1 week after treatment) and week_7 (7 weeks after treatment). At each time point inflammation was measured using luminex (elisa_cytokines table) and immune cells counts were measured from a pap-smear (flow_cytometry table).\n\n00_sample_ids_UKZN_workshop_2023.csv\n\npid – participant id\ntime_point – “baseline”, “week_1”, or “week_7” arm – “treatment” or “placebo”\nsample_id – the “wet-lab” sample id associated with this timepoint\n\n01_participant_metadata_UKZN_workshop_2023.csv\n\npid - participant id\narm - “treatment” or “placebo”\nsmoker - “yes” or “no”\nage – integer age in years\neducation – 4 options (“less than grade 9”, “grade 10-12, not matriculated”, “grade 10-12, matriculated”, “post-secondary”)\nsex – all participants are “F”\n\n02_visit_clinical_measurements_UKZN_workshop_2023.csv\n\npid – particpant id\ntime_point – “baseline”, “week_1”, or “week_7”\narm – “treatment” or “placebo”\nnugent_score – Nugent Score, a number from 0-10. 0-3 is no BV, 4-6 is intermediate BV, and 7-10 is BV . crp_blood – decimal number representing C-reactive protein blood test (CRP) ph – vaginal pH\n\n03_elisa_cytokines_UKZN_workshop_2023.csv\n\nsample_id - the “wet-lab” sample id associated with this timepoint\ncytokine - “IL-1a”, “IL-10”, “IL-1b”, “IL-8”, “IL-6”, “TNFa”, “IP-10”, “MIG”, “IFN-Y”, “MIP-3a”\nconc – decimal number representing concentration\nlimits – either “within limits” or “out of range”\n\n04_flow_cytometry_UKZN_workshop_2023.csv\n\nsample_id - the “wet-lab” sample id associated with this timepoint\nAll other columns – the integer count of this type of cell in this sample\ncd4_t_cells might best be analyzed as a proportion of cd3_t_cells…"
  },
  {
    "objectID": "datasets.html#download-the-yogurt-dataset-odd-number-groups",
    "href": "datasets.html#download-the-yogurt-dataset-odd-number-groups",
    "title": "Datasets",
    "section": "Download the yogurt dataset (Odd number groups)",
    "text": "Download the yogurt dataset (Odd number groups)\n\n00_sample_ids_yogurt.csv\n01_participant_metadata_yogurt.csv\n02_qpcr_results_yogurt.csv\n03_luminex_results_yogurt.csv"
  },
  {
    "objectID": "datasets.html#download-the-birth-control-dataset-even-number-groups",
    "href": "datasets.html#download-the-birth-control-dataset-even-number-groups",
    "title": "Datasets",
    "section": "Download the birth control dataset (Even number groups)",
    "text": "Download the birth control dataset (Even number groups)\n\n00_sample_ids_period.csv\n01_participant_metadata_period.csv\n02_luminex_period.csv\n03_flow_cytometry_period.csv"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science for Biology",
    "section": "",
    "text": "Data Science for Biology\nWorkshop 1 - R, RStudio, and Quarto for clinical research\nThis week of content will prepare you to use R, RStudio, and Quarto for data analysis in clinical research.\n\n\n\n\n\nGroup Projects\nWednesday PM Session\nSession Structure\n- 1:30-2:00:\n- Read Research Project description below for your project\n- Download project data files and put them in your folder\n- Make a new .qmd file for this project.\n- 2:00-3:00\n- Load the demographic table into an R tibble.\n- Make notes about what each column name is and what it means.\n- Examine and note basic parameters (using R commands) - number of participants, visit structure, number of features measured for each, type of data measured (binary, categorical)\n- Plot a histogram of all numeric features (eg, distribution of age) and bar plots for counts of categorical variables (eg. how many female).\n- 3:00 - 3:30 - Break\n- 3:30 - 5:00\n- Preproccessing the data to prepare for tableone\n- Use tableone for the dataset\nResearch Project A - Does eating yogurt change the vaginal microbiome?\nStudy Description\nThis is a randomized controlled trial to study whether yogurt consumption has an effect on the microbiome post antibiotic treatment. Absolute abundance of bacteria was measured by 3 qPCR assays (for total, L. crispatus, L. iners). Cytokine levels (in copies/ml of vaginal fluid) were also measured by Luminex. We also looked at the number and type of immune cells in the vagina using Flow Cytometry. Data was collected at two timepoints, pre and post antibiotic treatment.\nPrimary Aim\nTo investigate whether the consumption of yogurt influences microbiome composition after antibiotics treatment.\nResearch Project B - Does birth control change inflammation during menses?\nStudy Description\nThis is an observational study to evaluate the relationship between birth control and vaginal inflammation In response to menstruation. Absolute abundance of bacteria was measured by 3 qPCR assays (for total Bacteria, L. crispatus, L. iners). Cytokine levels (in copies/ml of vaginal fluid) were also measured by Luminex. We also looked at the number and type of immune cells in the vagina using Flow Cytometry. Data was collected at four timepoints; before, at the start, the end, and after menstruation.\nPrimary Aim\nTo investigate whether taking birth control is associated with vaginal inflammation throughout the menstrual cycle.\n\nWelcome to the workshop!\nNetwork: KTB Free Wifi (no password needed)\nNetwork AHRI Password: @hR1W1F1!17\nNetwork CAPRISA-Corp Password: corp@caprisa17\n\nFill out the pre-workshop survey here\n\nFill out the icebreaker survey here\n\nJoin the discord here (once you’ve joined, you can bookmark https://discord.com/channels/1158136582201692202/ to go straight to the channel.)\n\nGet your RStudio and R installation checked by an instructor or TA\n\nBefore the workshop: Installing R and RStudio\nPlease install R and RStudio on your laptop. If you already have R and Rstudio installed, please make sure they are up-to date. Please install R version 4.3.1 and RStudio version 2023.09.0 Click here for instructions on installing R and RStudio\n\n\nTable 1: Schedule\n\n\n\n\n\n\n\nDate/Time\nTopic\nInstructor\n\n\n\n\nMonday, October 16th\n–\n–\n\n\nAM\nCourse Introduction & Introduction to data types\nSalina Hussain and Suuba Demby (Ragon Institute)\n\n\nPM\nIntro to R, Rstudio, and Quarto\nChandani Desai and Joseph Elsherbini (Ragon Institute)\n\n\nTuesday, October 17th\n–\n–\n\n\nAM\nIntro to data visualizaion with the tidyverse\nScott Handley (Wash U School of Medicine)\n\n\nPM\nData wrangling and more data visualization\nJoseph Elsherbini (Ragon Institute)\n\n\nWednesday, October 18th\n–\n–\n\n\nAM\ntableone and statistics for clinical data\nMarothi Letsoalo (CAPRISA)\n\n\nPM\nSmall group worktime\nParticipants\n\n\nThursday, October 19th\n–\n–\n\n\nAM\nData transformations and more statistics\nLaura Symul (UCLouvain)\n\n\nPM\nSmall group worktime\nParticipants\n\n\nEvening\nReception\n\n\n\nFriday, October 20th\n–\n–\n\n\nAM\nKeynote\nLenine Liebenberg (CERI Stellenbosch)\n\n\n\nSmall group work time\nParticipants\n\n\nPM\nSmall group presentations"
  },
  {
    "objectID": "installation-instructions.html",
    "href": "installation-instructions.html",
    "title": "Installing R and RStudio",
    "section": "",
    "text": "adapted from datacarpentry.org\nFor this workshop, we will need R as well RStudio. R and RStudio are both completely free and open source software. While R is the underlying statistical computing environment, RStudio is the graphical IDE (integrated development environment) that makes using R easier, more intuitive, and interactive. Both are separate downloads and installations, and you will need to install R first, followed by RStudio. Once both are installed, you would just open and work in RStudio, which will run R in the background. Then you will install some R packages (collections of functions you can use in your own coding) which we are using for this workshop. Please install R version 4.3.1 or later and RStudio version 2023.09.0 or later."
  },
  {
    "objectID": "installation-instructions.html#step-1---follow-instructions-for-your-operating-system",
    "href": "installation-instructions.html#step-1---follow-instructions-for-your-operating-system",
    "title": "Installing R and RStudio",
    "section": "1 Step 1 - follow instructions for your operating system",
    "text": "1 Step 1 - follow instructions for your operating system\n\n1.0.1 For Windows see Section 3\n\n\n1.0.2 For MacOS see Section 4\n\n\n1.0.3 For Linux see Section 5"
  },
  {
    "objectID": "installation-instructions.html#step-2---install-r-packages",
    "href": "installation-instructions.html#step-2---install-r-packages",
    "title": "Installing R and RStudio",
    "section": "2 Step 2 - install R packages",
    "text": "2 Step 2 - install R packages\nOpen RStudio and Paste the following into your console on the left/bottom-left.\ninstall.packages(c(\"broom\", \"cluster\", \"colorspace\", \"cowplot\", \"distill\", \"gapminder\", \"GGally\", \"gganimate\", \"ggbeeswarm\", \"ggiraph\", \"ggdendro\", \"ggdist\", \"ggforce\",\"ggplot2movies\", \"ggrepel\", \"ggridges\", \"ggthemes\", \"gifski\", \"glue\",\"knitr\", \"learnr\", \"naniar\", \"margins\", \"MASS\", \"Matrix\",\"nycflights13\", \"palmerpenguins\", \"patchwork\", \"quarto\", \"rgdal\", \"rmarkdown\",\"rnaturalearth\", \"sf\", \"shinyjs\", \"tableone\", \"tidyverse\", \"transformr\", \"umap\"))"
  },
  {
    "objectID": "installation-instructions.html#sec-windows",
    "href": "installation-instructions.html#sec-windows",
    "title": "Installing R and RStudio",
    "section": "3 Windows",
    "text": "3 Windows\n\n3.1 If you don’t have R and RStudio installed:\nGo to https://posit.co/download/rstudio-desktop/ and follow this instruction for windows.\n\n\n3.2 If you already have R and RStudio installed, check to see if updates are available.\nRStudio: Open RStudio and click on Help &gt; Check for updates. If a new version is available, quit RStudio, and download the latest version.\nR: Upon starting RStudio, the version of R you are running will appear on the console. You can also type sessionInfo() in the console to display the version of R you are running. The CRAN website will tell you if there is a more recent version available. You can update R using the installr package, by running:\n# installr is for windows only!\nif( !(\"installr\" %in% installed.packages()) ){install.packages(\"installr\")} \n\ninstallr::updateR(TRUE)"
  },
  {
    "objectID": "installation-instructions.html#sec-mac",
    "href": "installation-instructions.html#sec-mac",
    "title": "Installing R and RStudio",
    "section": "4 MacOs",
    "text": "4 MacOs\n\n4.1 Check your processor\nadapted from https://docs.cse.lehigh.edu/determine-mac-architecture/\nMake sure you are downloading and installing the right version of R and R Studio for your laptop’s CPU. Some Macs have an intel chip (also known as x64 or x86_64 architecture), while the newest macs have M1 or M2 chips (also known as ARM architecture).\nTo determine whether a Mac is running an Intel Processor or Apple ARM M1 or M2, click on the  Apple Menu and select ‘About this Mac’:\n\n\n\nclick about this mac\n\n\nFrom the ‘About this Mac’ screen, on the ‘Overview’ tab, look for a line that indicates either ‘Chip’ or ‘Processor’. If the line contains M1 or M2, the machine is running Apple Silicon. Alternatively, the word Intel indicates that the machine is running an Intel-based Core series processor.\n\n\n\nM1 or M2\n\n\n\n\n\nintel\n\n\n\n\n4.2 If you don’t have R and RStudio installed:\nGo to https://posit.co/download/rstudio-desktop/ and follow this instruction for MacOS.\n\n\n4.3 If you already have R and RStudio installed, check to see if updates are available.\nRStudio: Open RStudio and click on Help &gt; Check for updates. If a new version is available, quit RStudio, and download the latest version.\nR: Upon starting RStudio, the version of R you are running will appear on the console. You can also type sessionInfo() to display the version of R you are running. The CRAN website will tell you if there is a more recent version available. For this workshop install version 4.3.1 of R"
  },
  {
    "objectID": "installation-instructions.html#sec-linux",
    "href": "installation-instructions.html#sec-linux",
    "title": "Installing R and RStudio",
    "section": "5 Linux",
    "text": "5 Linux\n\n5.1 If you don’t have R and RStudio installed:\nGo to https://posit.co/download/rstudio-desktop/ and follow this instruction for your Linux OS.\n\n\n5.2 If you already have R and RStudio installed, check to see if updates are available.\nRStudio: Open RStudio and click on Help &gt; Check for updates. If a new version is available, quit RStudio, and download the latest version.\nR: Upon starting RStudio, the version of R you are running will appear on the console. You can also type sessionInfo() to display the version of R you are running. The CRAN website will tell you if there is a more recent version available. For this workshop install version 4.3.1 of R"
  },
  {
    "objectID": "materials/1-workshop1/0-welcome/exercise_1.html#activity",
    "href": "materials/1-workshop1/0-welcome/exercise_1.html#activity",
    "title": "Exploring Data for Patterns",
    "section": "Activity",
    "text": "Activity\n\nPatterns are the essence of data exploration and our eyes’ ability to pick them out is integral to data understanding. Much of the data we work with, however, do not have a natural form and we need to make decisions about how they are to be represented. Try different ways to visualize the datasets so meaningful patterns may be found.\n\n\nGenetic profiles of cancer\nThese datasets contains 10 cancer samples. Table 1 describes the mutational status for a set of genes (A-E) and whether a mutation if absent (0) or present (1). Table 2 summarizes the expression levels of those genes, ranging from no expression (0) to high expression (3).\n\n\nTable 1: Mutational status for a set of genes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsample -&gt;\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\nGene A\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n\n\nGene B\n0\n0\n0\n0\n1\n1\n1\n0\n1\n1\n\n\nGene C\n0\n0\n1\n0\n0\n0\n1\n1\n1\n1\n\n\nGene D\n1\n1\n0\n0\n1\n1\n0\n0\n0\n0\n\n\nGene E\n0\n1\n1\n0\n1\n0\n0\n0\n1\n0\n\n\n\n\n\n\nTable 2: Expression levels for a set of genes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsample -&gt;\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\nGene A\n2\n1\n1\n2\n2\n0\n2\n1\n1\n2\n\n\nGene B\n1\n1\n2\n1\n0\n0\n0\n2\n0\n0\n\n\nGene C\n1\n1\n3\n1\n2\n2\n3\n0\n3\n0\n\n\nGene D\n0\n0\n2\n1\n3\n3\n2\n1\n1\n1\n\n\nGene E\n1\n3\n3\n1\n3\n1\n2\n1\n3\n2\n\n\n\n\n\n\n          1. Think about the problem on your own for 5 minutes.\n          2. In your groups, discuss and create different visualizations to highlight underlying patterns\n          3. Summarize the group’s approach\n          4. Elect/volunteer a spokesperson to present the solution\n\n\nConsider the following concepts when creating your visualizations\n\n\n\n\nPatterns\nPatterns are the essence of data exploration. What kinds of representation will produce the most meaningful insights?\n   \n\n\nEncodings\nSome visual estimations are easier to make than others. How might you use encodings that are less accurate but otherwise better at conveying overall trends?\n  \n\n\n\n\nColor\nColor is a powerful encoding that presents several challenges. Have you chosen a color scale that is optimal for that data type?\n   \n\n\nSalience and Relevance\nPop-out effects enable quick recognition. Are the most noticeable elements of your visualizations also the most relevant?"
  },
  {
    "objectID": "materials/1-workshop1/0-welcome/index.html",
    "href": "materials/1-workshop1/0-welcome/index.html",
    "title": "Welcome to the workshop",
    "section": "",
    "text": "Get to know your neighbors and instructors and learn what to expect from this workshop"
  },
  {
    "objectID": "materials/1-workshop1/0-welcome/index.html#slides",
    "href": "materials/1-workshop1/0-welcome/index.html#slides",
    "title": "Welcome to the workshop",
    "section": "Slides",
    "text": "Slides\nMake slides full screen"
  },
  {
    "objectID": "materials/1-workshop1/0-welcome/index.html#before-the-workshop-installing-r-and-rstudio",
    "href": "materials/1-workshop1/0-welcome/index.html#before-the-workshop-installing-r-and-rstudio",
    "title": "Welcome to the workshop",
    "section": "Before the workshop: Installing R and RStudio",
    "text": "Before the workshop: Installing R and RStudio\nPlease install R and RStudio on your laptop. If you already have R and Rstudio installed, please make sure they are up-to date. Please install R version 4.3.1 and RStudio version 2023.09.0 Click here for instructions on installing R and RStudio"
  },
  {
    "objectID": "materials/1-workshop1/0-welcome/slides.html#section",
    "href": "materials/1-workshop1/0-welcome/slides.html#section",
    "title": "Welcome to the workshop",
    "section": "",
    "text": "Goals for this session\n\n\nGet to know your instructors and neighbors\nSet expectations for the week\nGet excited!"
  },
  {
    "objectID": "materials/1-workshop1/0-welcome/slides.html#section-1",
    "href": "materials/1-workshop1/0-welcome/slides.html#section-1",
    "title": "Welcome to the workshop",
    "section": "",
    "text": "Workshop materials are at:\nhttps://elsherbini.github.io/durban-data-science-for-biology/"
  },
  {
    "objectID": "materials/1-workshop1/0-welcome/slides.html#discussions-discord",
    "href": "materials/1-workshop1/0-welcome/slides.html#discussions-discord",
    "title": "Welcome to the workshop",
    "section": "Discussions: discord",
    "text": "Discussions: discord\nAsk questions at #workshop-questions on https://discord.gg/UDAsYTzZE."
  },
  {
    "objectID": "materials/1-workshop1/0-welcome/slides.html#stickies",
    "href": "materials/1-workshop1/0-welcome/slides.html#stickies",
    "title": "Welcome to the workshop",
    "section": "Stickies",
    "text": "Stickies\n\n\n\n\n\n\nDuring an activity, place a yellow sticky on your laptop if you’re good to go and a pink sticky if you want help.\n\n\n\n\nImage by Megan Duffy"
  },
  {
    "objectID": "materials/1-workshop1/0-welcome/slides.html#practicalities",
    "href": "materials/1-workshop1/0-welcome/slides.html#practicalities",
    "title": "Welcome to the workshop",
    "section": "Practicalities",
    "text": "Practicalities\n\nWiFi:\nNetwork: KTB Free Wifi (no password needed)\nNetwork AHRI Password: @hR1W1F1!17\nNetwork CAPRISA-Corp Password: corp@caprisa17\nBathrooms are out the lobby to your left"
  },
  {
    "objectID": "materials/1-workshop1/0-welcome/slides.html#introductions",
    "href": "materials/1-workshop1/0-welcome/slides.html#introductions",
    "title": "Welcome to the workshop",
    "section": "Introductions",
    "text": "Introductions\n\n\n\n−+\n03:00\n\n\n\nTake ~3 minutes to introduce yourself to your neighbors.\nPlease share …\n\nYour name\nWhere you’re from and where you work\nYour current go-to method for analyzing data"
  },
  {
    "objectID": "materials/1-workshop1/0-welcome/slides.html#your-instructors",
    "href": "materials/1-workshop1/0-welcome/slides.html#your-instructors",
    "title": "Welcome to the workshop",
    "section": "Your Instructors",
    "text": "Your Instructors\nWho are we?"
  },
  {
    "objectID": "materials/1-workshop1/0-welcome/slides.html#lets-make-this-workshop-work-for-all",
    "href": "materials/1-workshop1/0-welcome/slides.html#lets-make-this-workshop-work-for-all",
    "title": "Welcome to the workshop",
    "section": "Let’s make this workshop work for all",
    "text": "Let’s make this workshop work for all\n\n\nYou belong here. This workshop is intended for a wide-audience with a focus on beginners. If you feel out of place - it’s our problem, not yours!\nStay committed. This week-long workshop is intended to build each day and leave you with skills you can really use. Commit to stay engaged for best results, for you and your group!\nThis is a challenging but friendly environment. We are here to learn and grow. In order to make the right environment please follow “the 4 social rules” and code-of-conduct."
  },
  {
    "objectID": "materials/1-workshop1/0-welcome/slides.html#flow-of-the-workshop",
    "href": "materials/1-workshop1/0-welcome/slides.html#flow-of-the-workshop",
    "title": "Welcome to the workshop",
    "section": "Flow of the Workshop",
    "text": "Flow of the Workshop"
  },
  {
    "objectID": "materials/1-workshop1/0-welcome/slides.html#the-premise-of-the-workshop",
    "href": "materials/1-workshop1/0-welcome/slides.html#the-premise-of-the-workshop",
    "title": "Welcome to the workshop",
    "section": "The premise of the workshop",
    "text": "The premise of the workshop\nWe’ve created a true-to-life “medium dimensional” dataset that we’ll use for all instruction\n\nabout 40 participants split across two treatment arms\nthree time points (before treatment, after treatment, and longer follow-up)\nseveral measurements per time-point including cytokine concentrations and flow cytometry data (more from Salina and Suuba next!)\n\nWe’ve also created group datasets so you can practice applying what you’ve learned on new data."
  },
  {
    "objectID": "materials/1-workshop1/0-welcome/slides.html#why-this-format",
    "href": "materials/1-workshop1/0-welcome/slides.html#why-this-format",
    "title": "Welcome to the workshop",
    "section": "Why this format",
    "text": "Why this format\nWe’ve taught workshops here before where we packed a lot (too much) into one week.\nBased on feedback, we’re trying to focus on R for the whole week, and to make the example data relevant to a lot of your actual work.\nHowever, many of you in the room know a lot more immunology than us - and even if you know none you can learn the R and generalize it to your research.\nThis is the first time running this new workshop - please give lots of feedback on how to improve it for next time."
  },
  {
    "objectID": "materials/1-workshop1/0-welcome/slides.html#the-content-of-this-workshop",
    "href": "materials/1-workshop1/0-welcome/slides.html#the-content-of-this-workshop",
    "title": "Welcome to the workshop",
    "section": "The content of this workshop",
    "text": "The content of this workshop\n\nWe’ve created 7 modules as well as a group activity for this workshop.\n\nThis is probably too much material to get through in this week!\n\nAs instructors we’re going to be trying to teach at the right pace to keep everyone learning all week.\n\nThe materials will stay on the website forever for you to work through at your own pace."
  },
  {
    "objectID": "materials/1-workshop1/0-welcome/slides.html#lets-take-a-poll",
    "href": "materials/1-workshop1/0-welcome/slides.html#lets-take-a-poll",
    "title": "Welcome to the workshop",
    "section": "Let’s take a poll",
    "text": "Let’s take a poll\nGo to the event on wooclap\n\n\n\nback to module"
  },
  {
    "objectID": "materials/1-workshop1/1-data-generation/index.html",
    "href": "materials/1-workshop1/1-data-generation/index.html",
    "title": "How data analysis is informed by data generation",
    "section": "",
    "text": "Let’s learn about the types of data we’ll use for this workshop"
  },
  {
    "objectID": "materials/1-workshop1/1-data-generation/index.html#slides",
    "href": "materials/1-workshop1/1-data-generation/index.html#slides",
    "title": "How data analysis is informed by data generation",
    "section": "Slides",
    "text": "Slides"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/images/ex-2.html",
    "href": "materials/1-workshop1/2-intro-to-r/images/ex-2.html",
    "title": "Data Science for Biology Workshop Series",
    "section": "",
    "text": "Spatial Logical Toy Inventor: Erno Rubik Assignee: Politoys Ipari Szovetkezet, Budapest, Hungary The first patent by the inventor is registered in Hungary. Appl. No.: 289,192 Filed: Aug. 3, 1981 Background of the Invention The invention relates to a spatial logical toy having a total of eighteen toy elements which form a regular or an irregular spatial body, preferably an oblong body, in the assembled state. Spatial logical toys are well known, such as that described in the HU-PS No. 170 062 of the same applicant, which relates to a spatial logical toy consisting of twenty-seven solids which form a cube in the assembled state. The toy elements, in the shape of small cubes, may be turned along the spatial axes of the cube by means of connecting elements arranged in the geometric center of the large cube. The surfaces of the small cubes forming each surface of the large cube are colored or carry numbers, figures or any other symbols which can be assembled into the predetermined logical order of sequence by simultaneously rotating the nine toy elements forming the surfaces of the large cube. Summary of the Invention The logical toy according to the present invention represents an improved form of the previously described spatial logical toy. The construction is based on the same principles, however, the internal connection is performed by means of absolutely new and particular solids. The key feature according to the invention, i.e. shape, name, sounds, mode of interconnection and central fixture will be described in detail by means of two preferred embodiments, by the aid of the accompanying drawings, wherein. Component blocks of the spatial logial toy. ex-2-figs.png What is claimed is: 1. In a spatial logical toy assembled from a plurality of toy elements, of which a predetermined number may be rotated in the direction of the spatial axes starting from the geometrical center of the logical toy, the improvement wherein the spatial logical toy is formed by a total of eighteen toy elements. Two sets of eight toy elements each comprise substantially cubiforms with integally formed cam elements and each of the sets comprise eight identical toy elements, and two connecting toy elements, and means for joining the connecting toy elements to coact with the cam elements to form an integrated toy body, the joining means comprising a single screw enclosed by a spring. The spatial logical toy as claimed in claim 1, wherein the toy has the shape of a regular geometrical body in the assembled state. The toy elements thereof belonging to one set comprise eight cubiform homologous elements each having a first cam element connected to one corner thereof. Two confining surfaces of which lie at a unit distance from two surfaces of the cube and are parallel therewith and are cut-off in the form of an ellipsis-quarter, and a third confining surface thereof is coplanar with another surface of the cube and between the two confining faces of the first cam element running parallel with the cube and the cube there is a hollow with a convex spherical surface."
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/index.html",
    "href": "materials/1-workshop1/2-intro-to-r/index.html",
    "title": "Intro to R, RStudio, and Quarto",
    "section": "",
    "text": "Let’s learn how to use RStudio to run R code and render documents with Quarto."
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/index.html#slides-intro-to-rstudio-quarto-and-r",
    "href": "materials/1-workshop1/2-intro-to-r/index.html#slides-intro-to-rstudio-quarto-and-r",
    "title": "Intro to R, RStudio, and Quarto",
    "section": "Slides: Intro to RStudio, Quarto, and R",
    "text": "Slides: Intro to RStudio, Quarto, and R\nMake slides full screen"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/index.html#worksheet-introduction-to-r-and-quarto",
    "href": "materials/1-workshop1/2-intro-to-r/index.html#worksheet-introduction-to-r-and-quarto",
    "title": "Intro to R, RStudio, and Quarto",
    "section": "Worksheet: Introduction to R and Quarto",
    "text": "Worksheet: Introduction to R and Quarto\n\n1. Operators and Functions in R\nIn order to get familiar with the R language, we shall start by using simple operators and functions that are intuitive to us in our everyday lives.\n\n1.1 Arithmetic operators\n\n+                addition\n-                subtraction\n*                multiplication\n/                division\n^ or **          power\n\nx %*% y          matrix multiplication c(5, 3) %*% c(2, 4) == 22\nx %% y           modulo (x mod y) 5 %% 2 == 1\nx %/% y          whole number division: 5 %/% 2 == 2\n\nNote that while the first half is self-explanatory, the second is more specific to programming and/or R.\nLet’s try a few examples in R. First, always have a code chunk at the top that loads the libraries you need:\n\n```{r}\nlibrary(tidyverse)\n```\n\nThen, copy the following code chunk into your quarto document.\n\n99 + 1 + -1\n\n64 / 4\n\n64 / (2+2)\n\n64 / 2 + 2\n\nNotice the difference in the last two commands and it’s effect on the output.\n\n\n1.2 Logical operators and functions\n\n&lt;                less than\n&lt;=               less than or equal to\n&gt;                greater than\n&gt;=               greater than or equal to\n==               equal\n!=               not equal\n!x               not x (negation)\nx | y            x OR y\nx & y            x AND y\nxor(x, y)        exclusive OR (either in x or y, but not in both)\nisTRUE(x)        truth test for x\n\nFew examples for you to copy in your quarto document or directly on the console,\n\n99 &lt; 1\n\n!(99 &lt; 1)\n\n64 == 8*8\n\n(3 &gt; 2) | (4 &gt; 5)\n\n\n\n1.3 Numeric functions\n\nabs(x)             absolute value\nsqrt(x)            square root\nceiling(x)         round up: ceiling(3.475) is 4\nfloor(x)           round down: floor(3.475) is 3\nround(x, digits=n) round: round(3.475, digits=2) is 3.48\ncos(x), sin(x), tan(x), acos(x), cosh(x), acosh(x) etc.\nlog(x)             natural logarithm\nlog(10, base = n)  base n logarithm\nlog2(x)            base 2 logarithm\nlog10(x)           base 10 logarithm\nexp(x)             exponential function: e^x\n\nFew examples for you to copy in your quarto document or directly on the console,\n\nabs(99)\n\nabs(-99)\n\nsqrt(64)\n\nfloor(6.789)\n\n\n\n1.4 Statistical functions\nBelow is a list of statistical functions. These functions can have the argument na.rm, which is set to FALSE by default. This will let you deal with missing values (na = not available). If set to false, these are not removed (rm = remove).\n\nmean(x, na.rm = FALSE)  mean\nsd(x)                   standard deviation\nvar(x)                  variance\n\nmedian(x)               median\nquantile(x, probs)      quantile of x.  probs: vector of probabilities\n\nsum(x)                  sum\nmin(x)                  minimal value of x (x_min)\nmax(x)                  xaximal value of x (x_max)\nrange(x)                x_min und x_max\n\n# if center  = TRUE: subtract mean\n# if scale   = TRUE: divide by sd\nscale(x, center = TRUE, scale = TRUE)   center and standardize\n\n# weighted sampling with argument prob:\nsample(x, size, replace = FALSE, prob)  sampling with or without replacement. prob: vector of weights\n\nTo get help with a function, type ?function_name in the console.\nFor example, try typing ?mean into the console. Check out this guide on how to read the help page.\n\n\n1.5 Other useful functions\n\nc()                    combine: used to create a vector\nseq(from, to, by)      generates a sequence\n:                      colon operator: generates a 'regular' sequence in increments of 1\nrep(x, times, each)    repeats x\n                          times: sequence is repeated n times\n                          each: each element is repeated n times\n\nhead(x, n = 6)         first 6 elements of x\ntail(x, n = 6)         last 6 elements of x\n\nFew examples for you to copy in your quarto document or directly on the console,\n\nc(1, 2, 3, 4, 5, 6)\n\nmean(c(1, 2, 3, 4, 5, 6))\n\nmean(c(1, NA, 3, 4, 5, 6), na.rm = TRUE)\n\nmean(c(1, NA, 3, 4, 5, 6), na.rm = FALSE)\n\nsum(c(1, 2, 3, 4, 5, 6))\n\nseq(from = 1, to = 6, by = 1)\n\nseq(from = 1, to = 6, by = 2)\n\nrep(1:6, times = 2, each = 2)\n\nReady to put these new skills to use? Here’s an exercise.\n\n\n\nExercise 1\nWrite R commands to calculate the following:\n\nThe sum of your birth day, month and year\n250 divided by the product of 4 and 5\nHalf of the sum of 37.5, 51.3, and 101.7\n\\(\\frac{1}{3} * { (1+3+5+7+2) \\over (3+5+4)}\\)\n\\(\\sqrt[3]{8}\\)\n\\(\\sin\\pi\\), \\(\\cos\\pi\\), \\(\\tan\\pi\\)\nCalculate the 10-based logarithm of 100, and multiply the result with the cosine of pi. Hint: see ?log and ?pi.\nCalculate the mean, sd and range of the vector [1, 3, 4, 7, 11, 16]\nGenerate the following output: 4 4 4 5 5 5 6 6 6 7 7 7\nGenerate the following output: 2 4 6 8 10 12\n\n\n\nChallenge Exercise 1\nWrite R commands to evaluate the following:\n\nYou have 83 chocolates in a bag. You would like to divide them into smaller bags of 8.\n1.1 How many small bags will you need?\n1.2 After the bags are filled, how many extra chocolates will you have remaining?\nYou are planning a research study with the following eligibility criteria:\n\n\nStudy participant should be between 18-25 years old (variable: age)\n\nHemoglobin should be over 10 (variable: hgb)\n\nStudy participant should not weigh over 50 (variable: wgt)\n\nStudy location should be X or Y (variable: loc)\n\n\nI have the following observations from a clinical parameter – x &lt;- c(23.1924, 21.4545, 24.6778) However, I would prefer to limit the values to 1 decimal point. How would you do that?\nLook up the rnorm() function in the Help Viewer. What arguments does this function take? Any default values?\nTry to nest a function within another\n\nAssuming you get all the information in forms of the above variables, write an R command to determine eligibility.\n\n\n2. Objects and Vectors in R\n\n2.1 Objects / Variables\nSo far, we have been happy to run functions and read the results on the screen. What if you’d like to read results later? You will need to save them by creating Objects.\nCopy the following code chunk into your quarto document\n\nnumber1 &lt;- 9\nsqrt(number1)\n\n[1] 3\n\nnumber2 &lt;- 10\n\nnumber1 * number2\n\n[1] 90\n\n\nWhat do you think happens when you use the same object name to another value? Try it!\n\nnewnumber &lt;- 100\nnewnumber &lt;- 150\n\n#What does R pick?\nnewnumber\n\nObject/Variable names\nYou can choose almost any name you like for an object, as long as the name does not begin with a number or a special character like +, -, *, /, ^, !, @, or &.\n\n# good variable names\nx_mean\nx_sd\n\nnum_people\nage\n\n# not so good\np\na\n\n# bad variable names\nx.mean\nsd.of-x\n\n\n\n2.2 Vectors\nVectors are the fundamental data type in R - all other data types are composed of vectors. These can subdivided into:\nnumeric vectors: a further subdivision is into integer (whole numbers) and double (floating point numbers).\ncharacter vectors: these consist of characters strings and are surrounded by quotes, either single ' or double \", e.g. 'word' or \"word\".\nlogical vectors: these can take three values: TRUE, FALSE or NA.\nVectors consist of elements of the same type, i.e., we cannot combine logical and character elements in a vector. Vectors have three properties:\nType: typeof(): what is it? Length: length(): how many elements? Attribute: attributes(): additional metadata\nVectors are created using the c() function or by using special function, such as seq() or rep().\n\n# Numeric vectors\nnum_vec &lt;- c(2.1,2.2,2.3,2.4,2.5)\nlength(num_vec)\n\n[1] 5\n\n# Character vectors\nchar_vec &lt;- c(\"hello\",\"hi\")\nlength(char_vec)\n\n[1] 2\n\n# Logical vectors\nlog_vec &lt;- c(TRUE,FALSE,TRUE)\ntypeof(log_vec)\n\n[1] \"logical\"\n\n\nSome fun with vectors\n\nnum_vec[1] # what's the first element of num_vec?\n\nnum_vec[4] # 4th?\n\nnum_vec[-1] # what does -1 do?\n\nnum_vec[1:3]\n\nnum_vec[-c(1, 3)]\n\nTry this on your own with the character vectors. What differences and similarities do you notice?\nExercise time!\n\n\n\nExercise 2\n\nCalculate the mean and standard deviation of a numeric vector of the first 6 multiples of 5.\nWhat happens if you attempt at arithmetic function on a numeric vector? (Example: num_vec + 1)\nWhat happens if you attempt the same on a character vector?\nExplore the str_length() function on a character vector.\nWhat happens if you try to make a vector consisting of different data types?\nMetadata hygiene: Give examples of good and bad ways to make variable names for the following columns in the Metadata spreadsheet –\n\nParticipant ID\nDate of Sample Collection\nType of Sample\nMean of past 3 weights\nNumber of people\n\n\n\n\nChallenge Exercise 2\n\nCalculate the mean of the sum of the first 6 even numbers - using one R command.\nfirst_name and last_name are two separate variables. Make one variable with both together, calling it full_name. Hint: it is a function\n\n\n\n3. Dataframes in R\nFor data analysis and statistics, data frames are important objects of data representation. A data frame is a two dimensional structure with rows and columns, like a table. You can think of it as a collection of vectors. Let us try making one.\n\n# creating a vector with an ID \nid &lt;- c(1, 2, 3)\n\n# creating another vector with names\nname &lt;- c(\"PersonA\", \"PersonB\", \"PersonC\")\n\n# creating another vector with year of birth \nyear_of_birth &lt;- c(1990, 1995, 2000)\n\n# creating another vector with favourite colour\nfav_colour &lt;- c(\"red\", \"green\", \"yellow\")\n\n#Make a dataframe from the above\n# note, make sure you've added the tidyverse library\nlibrary(tidyverse)\ndf &lt;- tibble(id, name, year_of_birth, fav_colour)\n\ndf\n\n# A tibble: 3 × 4\n     id name    year_of_birth fav_colour\n  &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;     \n1     1 PersonA          1990 red       \n2     2 PersonB          1995 green     \n3     3 PersonC          2000 yellow    \n\n\nYou just made a dataframe!\nNow, normally you will be importing one and using it to get useful information. You can extract useful information like number of rows, columns, details of each, summary of values, etc\nHere are a few helpful functions -\n\nattributes(df)\n\n$class\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n$row.names\n[1] 1 2 3\n\n$names\n[1] \"id\"            \"name\"          \"year_of_birth\" \"fav_colour\"   \n\nrownames(df)\n\n[1] \"1\" \"2\" \"3\"\n\ncolnames(df)\n\n[1] \"id\"            \"name\"          \"year_of_birth\" \"fav_colour\"   \n\n# We didn't assign any yet! Let us try to assign column names\ncolnames(df) &lt;- c(\"ID\",\"name\",\"year_of_birth\",\"favourite_colour\")\ncolnames(df)\n\n[1] \"ID\"               \"name\"             \"year_of_birth\"    \"favourite_colour\"\n\n## Note: When importing an existing data file, depending on your it's structure, you can ask R to import with or without row and column names)\n\nnrow(df)\n\n[1] 3\n\nncol(df)\n\n[1] 4\n\n# Data frame subsetting (I want only a few columns of my interest)\nselect(df, name)\n\n# A tibble: 3 × 1\n  name   \n  &lt;chr&gt;  \n1 PersonA\n2 PersonB\n3 PersonC\n\nselect(df, year_of_birth)\n\n# A tibble: 3 × 1\n  year_of_birth\n          &lt;dbl&gt;\n1          1990\n2          1995\n3          2000\n\n#extract row 2 only\nslice(df, 2)\n\n# A tibble: 1 × 4\n     ID name    year_of_birth favourite_colour\n  &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;           \n1     2 PersonB          1995 green           \n\n#extract rows 1, and 3\nslice(df, c(1,3))\n\n# A tibble: 2 × 4\n     ID name    year_of_birth favourite_colour\n  &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;           \n1     1 PersonA          1990 red             \n2     3 PersonC          2000 yellow          \n\n#extract column 3 only\nselect(df, 3)\n\n# A tibble: 3 × 1\n  year_of_birth\n          &lt;dbl&gt;\n1          1990\n2          1995\n3          2000\n\n#extract rows based on one condition\nfilter(df, year_of_birth &gt; 1995)\n\n# A tibble: 1 × 4\n     ID name    year_of_birth favourite_colour\n  &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;           \n1     3 PersonC          2000 yellow          \n\n#extract rows based on multiple conditions\nfilter(df, year_of_birth &gt; 1995 & favourite_colour==\"red\")\n\n# A tibble: 0 × 4\n# ℹ 4 variables: ID &lt;dbl&gt;, name &lt;chr&gt;, year_of_birth &lt;dbl&gt;,\n#   favourite_colour &lt;chr&gt;\n\nfilter(df, year_of_birth &gt; 1995 | favourite_colour==\"red\")\n\n# A tibble: 2 × 4\n     ID name    year_of_birth favourite_colour\n  &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;           \n1     1 PersonA          1990 red             \n2     3 PersonC          2000 yellow          \n\n#Note the difference in output upon use of different logical operators AND and OR\n\n\n\nExercise 3\n\nMake an expression to get only rows when the name is Person C or the favorite color is green.\nMake a new dataframe with 6 rows and 5 columns (get creative!)\nAdd different combinations of data to be able to use the above functions and compare output.\nTry above functions on your new dataframe and note any interesting observations.\nTry some other functions: str(), head(), view().\n\n\n\nChallenge Exercise 3\n\nCan you think of other simple questions you may need to query your dataset?\nTry to look your query up on google and see if you can find a function that addresses your need! (add ‘in R’ at the end for relevant answers!)\n\nCongratulations! You have successfully reached the end of this exercise. You now possess the most important skill: google your query!"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/index.html#end-of-session-worksheet-introduction-to-r-and-quarto",
    "href": "materials/1-workshop1/2-intro-to-r/index.html#end-of-session-worksheet-introduction-to-r-and-quarto",
    "title": "Intro to R, RStudio, and Quarto",
    "section": "End of session worksheet: Introduction to R and Quarto",
    "text": "End of session worksheet: Introduction to R and Quarto"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/index.html#introduction",
    "href": "materials/1-workshop1/2-intro-to-r/index.html#introduction",
    "title": "Intro to R, RStudio, and Quarto",
    "section": "Introduction",
    "text": "Introduction\nNow that we practiced a bit on mock and small datasets, let us try a ‘real’ one. In this worksheet, we will look at the Ice Breaker Poll from this morning and learn how to perform basic data manipulations, such as filtering data rows that meet certain conditions, choosing data columns, and arranging data in ascending or descending order.\nFirst, download the icebreaker poll file containing the dataset. Download the dataset here and move it to your project directory.\nUse the following command to read in the data from the Ice Breaker poll. ::: {.cell}\nice_breaker_df &lt;- read_csv(\"Ice Breaker Survey (Responses) - Form Responses 1.csv\") # make sure this file name exists in your current directory!\n\nRows: 5 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (9): Timestamp, first_thing_in_morning, vanilla_chocolate, superpower, s...\ndbl (3): num_languages, num_browser_tabs, height_cm\nlgl (1): years_current_country\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n:::\nWe will be using the R package tidyverse for the data manipulation functions %&gt;%, filter(), select(), arrange(), count(), and mutate().\n\nlibrary(tidyverse)\n\n\nThe pipe (%&gt;%, read: “and then”)\nWhen writing complex data analysis pipelines, we frequently use the pipe operator %&gt;% to move data from one analysis step to the next. The pipe is pronounced “and then”, and it takes the data on its left and uses it as the first argument for the function on its right.\nFor example, to see the first few lines of a dataset, we often write head(dataframe). Instead, we can write dataframe %&gt;% head().\nTry this yourself. Write code that displays the first few lines of the ice_breaker_df dataset, using %&gt;% and head():\n\n # build all the code for this exercise\n\nNow get all the column names using the colnames() function on the ice_breaker_df.\n\n # build all the code for this exercise\n\n\n\nChoosing data rows\nThe function filter() allows you to find rows in a dataset that meet one or more specific conditions. The syntax is dataframe %&gt;% filter(condition), where condition is a logical condition. For example, filter(x &gt; 5) would pick all rows for which the value in column x is greater than 5.\nAs an example, the following code picks all survey responses where people prefer chocolate over vanilla ice cream:\n\nice_breaker_df %&gt;%\n  filter(vanilla_chocolate == \"Chocolate\")\n\n# A tibble: 2 × 13\n  Timestamp    first_thing_in_morning num_languages vanilla_chocolate superpower\n  &lt;chr&gt;        &lt;chr&gt;                          &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt;     \n1 10/5/2023 1… Go back to sleep                3.25 Chocolate         Shape shi…\n2 10/5/2023 1… Go back to sleep                2.5  Chocolate         Flight    \n# ℹ 8 more variables: social_media &lt;chr&gt;, num_browser_tabs &lt;dbl&gt;,\n#   height_cm &lt;dbl&gt;, procrastinate &lt;chr&gt;, extreme_sport &lt;chr&gt;,\n#   r_experience &lt;chr&gt;, travel_to_workshop &lt;chr&gt;, years_current_country &lt;lgl&gt;\n\n\nCan you tell how many people that is from looking at the size of the tibble?\nNow it’s your turn to try one. Pick all responses where people would like to try Skydiving.\n\nice_breaker_df %&gt;%\n  filter(___)\n\n\nFiltering for multiple conditions\nYou can also state multiple conditions, separated by a comma. For example, filter(x &gt; 5, y &lt; 2) would pick all rows for which the value in the column x is greater than 5 and the value in the column y is less than 2. Note that the conditions are combined via logical and, both need to be satisfied for the row to be picked.\nTo try this out, pick all survey responses where people taller than XXX cm would like to retain their Facebook.\n\n # build all the code for this exercise\n\n\n\n\nChoosing data columns\nThe function select() allows you to pick specific data columns by name. This is frequently useful when a dataset has many more columns than we are interested in at the time. For example, if we are only interested in the responses regarding what people do first thing in the morning, what superpower they would like, and how they procrastinate, we could select just those three columns:\n\nice_breaker_df %&gt;%\n  select(first_thing_in_morning, superpower, procrastinate)\n\n# A tibble: 5 × 3\n  first_thing_in_morning superpower     procrastinate        \n  &lt;chr&gt;                  &lt;chr&gt;          &lt;chr&gt;                \n1 Check text messages    Flight         Watching TV          \n2 Go back to sleep       Shape shifting Eating snacks        \n3 Go back to sleep       Flight         Watching TV          \n4 Turn off the alarm     Flight         Browsing the internet\n5 Turn off the alarm     &lt;NA&gt;           &lt;NA&gt;                 \n\n\nTry this yourself, picking the columns representing responses to how many browser tabs people have open right now and what social media they would like to keep.\n\n # build all the code for this exercise\n\n\n\nChoosing columns for removal\nAnother situation that arises frequently is one where we want to remove specific columns. We can also do this with select(), but now write select(-column) to remove one or more columns.\nTry this. Remove the column num_browser_tabs.\n\n # build all the code for this exercise\n\nAnd now try removing both num_browser_tabs and procrastinate.\n\n\nSorting data\nThe function arrange() allows you to sort data by one or more columns. For example, dataframe %&gt;% arrange(x) would sort the data by increasing values of x, and dataframe %&gt;% arrange(x, y) would sort the data first by x and then, for ties in x, by y.\nAs an example, the following code sorts responses by the person’s height:\n\nice_breaker_df %&gt;%\n  arrange(height_cm)\n\n# A tibble: 5 × 13\n  Timestamp    first_thing_in_morning num_languages vanilla_chocolate superpower\n  &lt;chr&gt;        &lt;chr&gt;                          &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt;     \n1 10/5/2023 1… Go back to sleep                2.5  Chocolate         Flight    \n2 10/5/2023 1… Go back to sleep                3.25 Chocolate         Shape shi…\n3 10/5/2023 1… Turn off the alarm              2    Vanilla           Flight    \n4 10/5/2023 1… Check text messages             1    Vanilla           Flight    \n5 10/15/2023 … Turn off the alarm             NA    &lt;NA&gt;              &lt;NA&gt;      \n# ℹ 8 more variables: social_media &lt;chr&gt;, num_browser_tabs &lt;dbl&gt;,\n#   height_cm &lt;dbl&gt;, procrastinate &lt;chr&gt;, extreme_sport &lt;chr&gt;,\n#   r_experience &lt;chr&gt;, travel_to_workshop &lt;chr&gt;, years_current_country &lt;lgl&gt;\n\n\nNow it’s your turn. Sort responses by the number of languages people can speak:\n\n # build all the code for this exercise\n\n\nArranging in descending order\nTo arrange data in descending order, enclose the data column in desc(). For example, dataframe %&gt;% arrange(desc(x)) would sort the data by decreasing values of x. (desc stands for “descending”.)\nTry this out. Sort the responses by height again, this time from largest to smallest:\n\n # build all the code for this exercise\n\n\n\n\nCounting\nWe frequently want to count how many times a particular value or combination of values occurs in a dataset. We do this using the count() function. For example, the following code counts how many of each number we got for the number of languages people can speak.\n\n\n# A tibble: 5 × 2\n  num_languages     n\n          &lt;dbl&gt; &lt;int&gt;\n1          1        1\n2          2        1\n3          2.5      1\n4          3.25     1\n5         NA        1\n\n\nNow try this yourself. Count how many prefer vanilla ice cream and how many chocolate.\n\n # build all the code for this exercise\n\n\n\nChaining analysis steps into pipelines\nWe can chain multiple analysis steps into a pipeline by continuing to add “and then” statements. For example, dataframe %&gt;% count(...) %&gt;% arrange(...) would first count and then sort the data.\nTry this out by counting the number of responses of languages spoken and and then sorting by the number.\n\n # build all the code for this exercise\n\n\n\nCreating new data columns\nThe function mutate() allows you to add new columns to a data table. For example, dataframe %&gt;% mutate(sum = x + y) would create a new column sum that is the sum of the columns x and y:\n\ndata &lt;- tibble(x = 1:3, y = c(10, 20, 30))\ndata\n\n# A tibble: 3 × 2\n      x     y\n  &lt;int&gt; &lt;dbl&gt;\n1     1    10\n2     2    20\n3     3    30\n\n\n\ndata %&gt;%\n  mutate(sum = x + y)\n\n# A tibble: 3 × 3\n      x     y   sum\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1    10    11\n2     2    20    22\n3     3    30    33\n\n\nNote that the part to the left of the equals sign (here, sum) is the name of the new column, and the part to the right of the equals sign (here, x + y) is an R expression that evaluates to the values in the new column.\nNow apply this concept to the ice_breaker_df dataset. Add a new column browsing by language that is the ratio of number of browser tabs currently open and number of languages spoken:\n\n # build all the code for this exercise\n\n\nCounting with custom conditions\nIt is quite common that we want to count items that meet a specific condition. For example, let’s say we want to count how many people are taller than 155 cm. To do this efficiently, we first create a new column that indicates whether the condition is met or not, and we then use count with that indicator column.\nThe easiest way to create indicator columns is via the function if_else(), which takes three arguments: a condition, a result if the condition is met, and a result if the condition is not met. The following example shows how to create an indicator column showing whether a variable is positive or negative:\n\ndata &lt;- tibble(x = c(-0.5, 2.3, 50, -1.4))\ndata\n\n# A tibble: 4 × 1\n      x\n  &lt;dbl&gt;\n1  -0.5\n2   2.3\n3  50  \n4  -1.4\n\n\n\ndata %&gt;%\n  mutate(\n    sign_of_x = if_else(x &gt;= 0, \"positive\", \"negative\")\n  ) %&gt;%\n  count(sign_of_x)\n\n# A tibble: 2 × 2\n  sign_of_x     n\n  &lt;chr&gt;     &lt;int&gt;\n1 negative      2\n2 positive      2\n\n\nNow try this yourself. Count how many people are taller than 155 cm. Then sort your results.\nHere are a few additional exercises that you can work on to practice and learn more about survey responses from everyone in this room!\n\n\n\nExercise - fun with the survey\nWrite R commands for the following -\n1. How many people took this survey?\n2. How many questions did we ask?\n3. What questions did we ask?\n4. Give a few examples of the data types captured in the questions\n5. Look at responses of questions 4-6 from all participants\n6. Try to rename a column (question)\n7. Make a new dataframe of 5 questions of your choice.\n8. Can you get the height of the tallest person in this room?\n9. How many people speak more than 2 languages?\n10. Select the question about R experience and sort by the kind of R background and experience in this room.\n12. What is the ratio of people who took a plane to this workshop vs those who walked?"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#section",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#section",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "",
    "text": "Workshop materials are at:\nhttps://elsherbini.github.io/durban-data-science-for-biology/"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#section-1",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#section-1",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "",
    "text": "Goals for this session\n\n\nAnswer the question “Why R?”\nLearn how to use Quarto to make notebook reports.\nBegin interacting with data in R."
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#discussions-discord",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#discussions-discord",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Discussions: discord",
    "text": "Discussions: discord\nAsk questions at #workshop-questions on https://discord.gg/UDAsYTzZE."
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#stickies",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#stickies",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Stickies",
    "text": "Stickies\n\n\n\n\n\n\nDuring an activity, place a blue sticky on your laptop if you’re good to go and a pink sticky if you want help.\n\n\n\n\nImage by Megan Duffy"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#practicalities",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#practicalities",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Practicalities",
    "text": "Practicalities\n\nWiFi:\nNetwork: KTB Free Wifi (no password needed)\nNetwork AHRI Password: @hR1W1F1!17\nNetwork CAPRISA-Corp Password: corp@caprisa17\nBathrooms are out the lobby to your left"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#what-is-r",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#what-is-r",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "What is R?",
    "text": "What is R?\nR is a general purpose programming language that’s really well suited to statistics, manipulating tabular data, and plotting."
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#why-r",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#why-r",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Why R?",
    "text": "Why R?"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#why-r-1",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#why-r-1",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Why R?",
    "text": "Why R?\n\nR is completely free and open source\nUsing R connects you with a community around the whole world\nR has a huge amount of packages - code someone else wrote so you don’t have to!"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#obtaining-r",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#obtaining-r",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Obtaining R",
    "text": "Obtaining R\nWindows, Mac or Linux OS: https://www.r-project.org"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#running-r",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#running-r",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Running R",
    "text": "Running R\n\n\n\nRStudio\n\nRStudio: http://www.rstudio.com\nBuilt-in tools for viewing plots, tables, and rendering documents\nThe best way to work if you only use R\n\n\n\nVSCode\n\nhttps://code.visualstudio.com/download\nnot a full IDE, but you can customize it with extensions\nWorks well with not just R, but all major programming languages\nGuide on setting up VSCode for R programming: link and link"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#create-an-r-project",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#create-an-r-project",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Create an R Project",
    "text": "Create an R Project\n\n\n\nFile -&gt; New Project…"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#create-an-r-project-1",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#create-an-r-project-1",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Create an R Project",
    "text": "Create an R Project\n\n\n\nClick on New Directory"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#create-an-r-project-2",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#create-an-r-project-2",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Create an R Project",
    "text": "Create an R Project\n\n\n\nName your directory and click “Create Project”"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#create-an-r-project-3",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#create-an-r-project-3",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Create an R Project",
    "text": "Create an R Project\n\n\n\nYou made a project! This creates a file for you with the .qmd extension"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#create-an-r-project-4",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#create-an-r-project-4",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Create an R Project",
    "text": "Create an R Project\n\n\n\nSwitch from “visual” to “source” to see the plain-text version of this document."
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#create-an-r-project-5",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#create-an-r-project-5",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Create an R Project",
    "text": "Create an R Project\n\n\n\nClick on “Render” to ask Quarto to turn this plain-text document into an HTML page"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#create-an-r-project-6",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#create-an-r-project-6",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Create an R Project",
    "text": "Create an R Project\n\n\n\nYour default web-browser will open and show you the rendered document!"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#what-are-the-parts-of-rstudio",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#what-are-the-parts-of-rstudio",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "What are the parts of RStudio?",
    "text": "What are the parts of RStudio?"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#the-text-editor",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#the-text-editor",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "The text editor",
    "text": "The text editor"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#the-console",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#the-console",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "The console",
    "text": "The console"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#the-right-panes",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#the-right-panes",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "The right panes",
    "text": "The right panes"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#lets-take-a-poll",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#lets-take-a-poll",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Let’s take a poll",
    "text": "Let’s take a poll\nGo to the event on wooclap\n\nM2. Match the areas with the right functionality"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#what-is-programming",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#what-is-programming",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "What is programming?",
    "text": "What is programming?\nProgramming is giving the computer instructions using text. The tricky part is learning how to speak to a computer.\n\n\n\n\nComputers are incredibly literal\n\n\n```{r}\n\"a\" == \"A\"\n```\n\n[1] FALSE\n\n\n\n\n\nComputers care about punctuation\n\n\n```{r error=TRUE}\nmax(c(1,2,3,4)]\n```\n\nError: &lt;text&gt;:1:15: unexpected ']'\n1: max(c(1,2,3,4)]\n                  ^\n\n\n\n\n\nComputers only know what you tell them\n\n\n```{r error=TRUE}\n# how old will I be in 10 years?\nmy_age + 10\n```\n\nError in eval(expr, envir, enclos): object 'my_age' not found\n\n\n\n\n\nMost bugs happen because of one of these things."
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#what-is-programming-1",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#what-is-programming-1",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "What is programming?",
    "text": "What is programming?\nSo why bother at all? Because if you can tell a computer how to do it once, it is reproducible!\nIf the data changes or you find a mistake, just rerun!\nYou can run the same code on new data\nYou can share your code with others so they can start where you left off"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#lets-use-r-for-math",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#lets-use-r-for-math",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Let’s use R for math",
    "text": "Let’s use R for math\n\n\n\n−+\n08:00\n\n\n\nIn the console, try typing some commands:\n\n# arithmetic\n3 + 5 + 10\n10 * (5 + 1)\n3**2 # what does the ** operator do in R?\n# check inequalities and equalities\n4 &gt;= 1 # what does this mean?\n5 + 4 == 9\n# make some errors\n\"3\" + 5 # why is this an error?\nmy_age + 5  # why is this an error?\n\n# write a math expression to calculate what percentage\n# of your life has been in post-secondary school/training\n# (university, training programs, masters, PhD)"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#say-hello-to-the-text-editor",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#say-hello-to-the-text-editor",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Say hello to the text-editor",
    "text": "Say hello to the text-editor\nWhen you write code in the console, it is gone.\nIt is better to work inside quarto notebooks in order to be able to save and share your code and results."
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#articles",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#articles",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Articles",
    "text": "Articles"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#presentations",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#presentations",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Presentations",
    "text": "Presentations"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#websites",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#websites",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Websites",
    "text": "Websites"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#books",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#books",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Books",
    "text": "Books"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#quarto-render",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#quarto-render",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Quarto Render",
    "text": "Quarto Render\nQuarto is integrated into RStudio\nClick  in Editor pane of RStudio.\nRender input file to various document formats.\n\n\n\nInput\n\n*.qmd\n*.ipynb\n*.md\n*.Rmd\n\n\n\nFormat\n\nhtml\npdf\nrevealjs (like these slides!)\ndocx\nppt\nand many more!"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#quartos-code-chunk",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#quartos-code-chunk",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Quarto’s Code Chunk",
    "text": "Quarto’s Code Chunk\n\n\n\n\n```{r}\n#| echo: false\nrnorm(3)\n```\n\n\n\n\n\nThis is a Quarto Code Chunk."
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#lets-explore-the-survey-data",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#lets-explore-the-survey-data",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Let’s explore the survey data",
    "text": "Let’s explore the survey data"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#quartos-code-chunk-1",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#quartos-code-chunk-1",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Quarto’s Code Chunk",
    "text": "Quarto’s Code Chunk\n\n\n\n\n```{r}\n#| echo: false\nrnorm(3)\n```\n\n\n\n\nThis is a Quarto Code Chunk.\nMake a new code chunk in three ways:\n\nType it out\ngot to Code -&gt; Insert Chunk on the top menu\nclick in your document and hit the key combination Alt+Ctrl+i\n\nWrite a math expression in a chunk and press the green arrow at the top-right of the chunk."
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#execution-options",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#execution-options",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Execution Options",
    "text": "Execution Options\nControl how the code is executed with options.\nOptions are denoted with the “hash-pipe” #|\n\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\neval\nEvaluate the code chunk (if false, just echos the code into the output).\n\n\necho\nInclude the source code in output\n\n\noutput\nInclude the results of executing the code in the output (true, false, or asis to indicate that the output is raw markdown and should not have any of Quarto’s standard enclosing markdown).\n\n\nwarning\nInclude warnings in the output.\n\n\nerror\nInclude errors in the output.\n\n\ninclude\nCatch all for preventing any output (code or results) from being included (e.g. include: false suppresses all output from the code block)."
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#example-figures-from-code",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#example-figures-from-code",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Example: Figures from Code",
    "text": "Example: Figures from Code\n\n\n```{r}\nlibrary(palmerpenguins)\nlibrary(ggplot2)\n\nggplot(penguins,\n       aes(x = bill_length_mm,\n           y = bill_depth_mm,\n           col = island)) +\n  geom_point()\n```"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#example-figures-from-code-1",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#example-figures-from-code-1",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Example: Figures from Code",
    "text": "Example: Figures from Code\n\n\n```{r}\n#| fig-width: 5\n#| fig-height: 3\n\nlibrary(palmerpenguins)\nlibrary(ggplot2)\n\nggplot(penguins,\n       aes(x = bill_length_mm,\n           y = bill_depth_mm,\n           col = island)) +\n  geom_point()\n```"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#section-2",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#section-2",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "",
    "text": "Markdown is designed to be easy to write and easy to read:\n\nA Markdown-formatted document should be publishable as-is, as plain text, without looking like it’s been marked up with tags or formatting instructions.\n-John Gruber\n\n\n\n\nQuarto uses extended version of Pandoc markdown.\nPandoc classifies markdown in terms of Inline and Block elements."
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#inline-elements-text-formatting",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#inline-elements-text-formatting",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Inline Elements: Text Formatting",
    "text": "Inline Elements: Text Formatting\n\n\nMarkdown\nMarkdown allows you to format text\nwith *emphasis* and **strong emphasis**.\nYou can also add superscripts^2^, \nsubscripts~2~, and display code \n`verbatim`. Little known fact: you can \nalso ~~strikethrough~~ text and present\nit in [small caps]{.smallcaps}.\n\n\nOutput\nMarkdown allows you to format text with emphasis and strong emphasis. You can also add superscripts2, subscripts2, and display code verbatim. Little known fact: you can also strikethrough text and present it in small caps.\n\n\n\n1\n\nEither the * or _ can be used for emphasis and strong."
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#inline-elements-links-and-images",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#inline-elements-links-and-images",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Inline Elements: Links and Images",
    "text": "Inline Elements: Links and Images\nMarkdown\nYou can embed [links with names](https://quarto.org/), direct urls\nlike &lt;https://quarto.org/&gt;, and links to \n[other places](#inline-elements-text-formatting) in the document. \nThe syntax is similar for embedding an inline image:\n![render icon](images/render-icon.png).\n\n\n\n\nOutput\nYou can embed links with names, direct urls like https://quarto.org/, and links to other places in the document. The syntax is similar for embedding an inline image: ."
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#markdown-can-do-so-much-more",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#markdown-can-do-so-much-more",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Markdown can do so much more",
    "text": "Markdown can do so much more\nTo learn about footnotes, Math, tables, and diagrams, check out the quarto documentation on markdown\n\n\n\nMarkdown\nA short note.^[Fits inline.]\n\n|        |  1   |  2   |\n|--------|------|------|\n| **A**  | 0    | 0    |\n: example table {#tbl-1}\n\n$$\nf(x)={\\sqrt{\\frac{\\tau}{2\\pi}}}\n      e^{-\\tau (x-\\mu )^{2}/2}\n$$\n\n\nOutput\nA short note.1\n\n\nTable 1: example table\n\n\n\n1\n2\n\n\n\n\nA\n0\n0\n\n\n\n\n\\[\nf(x)=\\sqrt{\\frac{\\tau}{2\\pi}}\n    e^{-\\tau (x-\\mu )^{2}/2}\n\\]\n\n\nFits inline."
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#metadata-yaml",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#metadata-yaml",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Metadata: YAML",
    "text": "Metadata: YAML\n“Yet Another Markup Language” or “YAML Ain’t Markup Language” is used to provide document level metadata …\n\n\n\n\n[… in key-value pairs,]\n[… that can nest,]\n[… are fussy about indentation,]\n[… and are kept between ---.]\n\n\n\n---\nformat: \n  title: \"Intro to R\"\n  author: \"Yours Truly\"\n  html:\n    toc: true\n    code-fold: true\n---\n\n\nThere are many options for front matter and configuring rendering."
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#ok-but-how-do-you-write-code",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#ok-but-how-do-you-write-code",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Ok, but how do you write code?",
    "text": "Ok, but how do you write code?"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#assignment",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#assignment",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Assignment",
    "text": "Assignment\nYou can use &lt;- or = to assign values to variables\na &lt;- 6\nb = 8\nc &lt;- 5.44\nd = TRUE\ne = \"hello world\" \ne &lt;- 'hello world' # same as double quote\nWe will use &lt;- for all examples going forward, but do whichever melts your brain less"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#naming-variables",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#naming-variables",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Naming variables",
    "text": "Naming variables\nA lot of R people use . inside variable names, but in most languages besides R this would be an error. It’s good practice these days to use the _ underscore if you want separation in your variable names.\nr.people.sometimes.put.dots &lt;- TRUE\ndots.are.confusing &lt;- \"maybe\"\njust_use_underscores &lt;- \"please\""
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#functions",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#functions",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Functions",
    "text": "Functions\nFunctions are named bits of code that take parameters as input and return some output\n\nlibrary(tidyverse)\nword_1 &lt;- \"hello\"\nword_2 &lt;- \"world\"\nstr_c(word_1, word_2)\n\n[1] \"helloworld\"\n\n\nstr_c is a function that puts concatenates strings."
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#functions-1",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#functions-1",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Functions",
    "text": "Functions\nFunctions are named bits of code that take parameters as input and return some output\n\nlibrary(tidyverse)\nword_1 &lt;- \"hello\"\nword_2 &lt;- \"world\"\nstr_c(word_1, word_2, sep = \" \")\n\n[1] \"hello world\"\n\n\nstr_c is a function that puts concatenates strings.\nfunctions can have named parameters as well as positional parameters."
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#functions-2",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#functions-2",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Functions",
    "text": "Functions\nFunctions are named bits of code that take parameters as input and return some output\n\nlibrary(tidyverse)\nword_1 &lt;- \"hello\"\nword_2 &lt;- \"world\"\nstr_c(word_1, word_2, sep = \" \")\n\n[1] \"hello world\"\n\n\nstr_c is a function that puts concatenates strings.\nfunctions can have named parameters as well as positional parameters.\nnamed parameters always take an = sign for assignment."
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#getting-help-with-functions",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#getting-help-with-functions",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Getting help with functions",
    "text": "Getting help with functions\nType ?str_c in the console to get a help page. check out this guide on how to read the R help pages.\nalso try googling str_c R tidyverse to get help.\nchatGPT and phind.com are really good at answering specific questions about R functions - not always correct but most of the time."
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#everything-is-a-vector",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#everything-is-a-vector",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "“Everything is a vector”",
    "text": "“Everything is a vector”\nThis sounds like nonsense - let’s unpack:\n\nc(1, 2, 3, 4)\n\n[1] 1 2 3 4\n\n\n\nA Vector is a collection of values surrounded by c() and separated with ,"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#everything-is-a-vector-1",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#everything-is-a-vector-1",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "“Everything is a vector”",
    "text": "“Everything is a vector”\nThis sounds like nonsense - let’s unpack:\n\nc(1, 2, 3, 4) * 3\n\n[1]  3  6  9 12\n\n\n\nA vector is a collection of values surrounded by c() and separated with ,\nVectors in R do smart things with most functions and operations."
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#everything-is-a-vector-2",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#everything-is-a-vector-2",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "“Everything is a vector”",
    "text": "“Everything is a vector”\nThis sounds like nonsense - let’s unpack:\n\nc(1, 2, 3, \"potato\") * 3\n\nError in c(1, 2, 3, \"potato\") * 3: non-numeric argument to binary operator\n\n\n\nA vector is a collection of values surrounded by c() and separated with ,\nVectors in R do smart things with most functions and operations.\nVectors have only one type of value."
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#value-types-in-r",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#value-types-in-r",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Value types in R",
    "text": "Value types in R\nThe type of the value can be\n# numeric\nc(1,2,3,4) \n\n# character\nc(\"a\",\"b\",\"c\",\"d\")\n\n# boolean\nc(TRUE, FALSE)\n\n# factor\nc(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\") %&gt;% as_factor()"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#tibbles-aka-data-frames",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#tibbles-aka-data-frames",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "tibbles (aka data frames)",
    "text": "tibbles (aka data frames)\ntibbles are the big reason R is great for working with tabular data.\nA data frame is a rectangular collection of variables (in the columns) and observations (in the rows).\n\ntable_02\n\n# A tibble: 132 × 6\n   pid    time_point arm     nugent_score crp_blood    ph\n   &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1 pid_01 baseline   placebo            8      0.44   5.7\n 2 pid_01 week_1     placebo            7      1.66   5.2\n 3 pid_01 week_7     placebo            7      1.44   5.4\n 4 pid_02 baseline   placebo            7      1.55   5.2\n 5 pid_02 week_1     placebo            7      0.75   4.8\n 6 pid_02 week_7     placebo            4      1.17   4.2\n 7 pid_03 baseline   placebo            6      1.78   4.8\n 8 pid_03 week_1     placebo           10      0.57   5.3\n 9 pid_03 week_7     placebo            7      1.79   5.2\n10 pid_04 baseline   placebo            5      1.76   4.8\n# ℹ 122 more rows"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#exercise",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#exercise",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Exercise",
    "text": "Exercise\nThat’s enough slides for now time to try for yourself! Go to the module and go to the first exercise.\n\n\n\n−+\n30:00"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#how-to-read-in-data",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#how-to-read-in-data",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "How to read in data?",
    "text": "How to read in data?\nData is often in tables, and the easiest way to store tabular data is in csv or tsv format.\ncsv - comma separated values\ntsv - tab separated values\nto read in data stored this way use read_csv(filename) or read_tsv(filename)\ntable_02 &lt;- read_csv(\"02_visit_clinical_measurements_UKZN_workshop_2023.csv\")"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#but-first-the-pipe-operator",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#but-first-the-pipe-operator",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "But first: the pipe operator %>%",
    "text": "But first: the pipe operator %&gt;%"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#but-first-the-pipe-operator-1",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#but-first-the-pipe-operator-1",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "But first: the pipe operator %>%",
    "text": "But first: the pipe operator %&gt;%\n\n%&gt;% is pronounced “and then”"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#the-pipe-feeds-data-into-functions",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#the-pipe-feeds-data-into-functions",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "The pipe %>% feeds data into functions",
    "text": "The pipe %&gt;% feeds data into functions\n\n```{r}\nhead(table_02)\n```\n\n# A tibble: 6 × 6\n  pid    time_point arm     nugent_score crp_blood    ph\n  &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 pid_01 baseline   placebo            8      0.44   5.7\n2 pid_01 week_1     placebo            7      1.66   5.2\n3 pid_01 week_7     placebo            7      1.44   5.4\n4 pid_02 baseline   placebo            7      1.55   5.2\n5 pid_02 week_1     placebo            7      0.75   4.8\n6 pid_02 week_7     placebo            4      1.17   4.2"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#the-pipe-feeds-data-into-functions-1",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#the-pipe-feeds-data-into-functions-1",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "The pipe %>% feeds data into functions",
    "text": "The pipe %&gt;% feeds data into functions\n\n```{r}\n# head(table_02)\ntable_02 %&gt;%\n  head()\n```\n\n# A tibble: 6 × 6\n  pid    time_point arm     nugent_score crp_blood    ph\n  &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 pid_01 baseline   placebo            8      0.44   5.7\n2 pid_01 week_1     placebo            7      1.66   5.2\n3 pid_01 week_7     placebo            7      1.44   5.4\n4 pid_02 baseline   placebo            7      1.55   5.2\n5 pid_02 week_1     placebo            7      0.75   4.8\n6 pid_02 week_7     placebo            4      1.17   4.2"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#the-pipe-feeds-data-into-functions-2",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#the-pipe-feeds-data-into-functions-2",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "The pipe %>% feeds data into functions",
    "text": "The pipe %&gt;% feeds data into functions\n\n```{r}\nggplot(table_02, aes(crp_blood, ph, color = arm)) + geom_point()\n```"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#the-pipe-feeds-data-into-functions-3",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#the-pipe-feeds-data-into-functions-3",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "The pipe %>% feeds data into functions",
    "text": "The pipe %&gt;% feeds data into functions\n\n```{r}\ntable_02 %&gt;%\n  ggplot(aes(crp_blood, ph, color = arm)) + geom_point()\n```"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#since-r-4.1-native-pipe",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#since-r-4.1-native-pipe",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Since R 4.1: Native pipe |>",
    "text": "Since R 4.1: Native pipe |&gt;\n\n```{r}\ntable_02 |&gt;\n  ggplot(aes(crp_blood, ph, color = arm)) + geom_point()\n```"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#which-to-use-native-pipe-or-old-school-pipe",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#which-to-use-native-pipe-or-old-school-pipe",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Which to use? Native pipe or old-school pipe?",
    "text": "Which to use? Native pipe or old-school pipe?\n\n\n|&gt; is the future. If you can, use it.\n%&gt;% works on older installations. It’s the safe choice for now.\n\nWe use %&gt;% here because many people still run older R versions. Also, we’re old school."
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#pick-rows-from-a-table-filter",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#pick-rows-from-a-table-filter",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Pick rows from a table: filter()",
    "text": "Pick rows from a table: filter()"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#filter-only-placebo",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#filter-only-placebo",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Filter only placebo",
    "text": "Filter only placebo\n\n```{r}\ntable_02 %&gt;%\n  filter(arm == \"placebo\")\n```\n\n# A tibble: 69 × 6\n   pid    time_point arm     nugent_score crp_blood    ph\n   &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1 pid_01 baseline   placebo            8      0.44   5.7\n 2 pid_01 week_1     placebo            7      1.66   5.2\n 3 pid_01 week_7     placebo            7      1.44   5.4\n 4 pid_02 baseline   placebo            7      1.55   5.2\n 5 pid_02 week_1     placebo            7      0.75   4.8\n 6 pid_02 week_7     placebo            4      1.17   4.2\n 7 pid_03 baseline   placebo            6      1.78   4.8\n 8 pid_03 week_1     placebo           10      0.57   5.3\n 9 pid_03 week_7     placebo            7      1.79   5.2\n10 pid_04 baseline   placebo            5      1.76   4.8\n# ℹ 59 more rows"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#filter-out-samples-with-ph-4",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#filter-out-samples-with-ph-4",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Filter out samples with ph < 4",
    "text": "Filter out samples with ph &lt; 4\n\n```{r}\ntable_02 %&gt;%\n  filter(ph &lt; 4)\n```\n\n# A tibble: 39 × 6\n   pid    time_point arm       nugent_score crp_blood    ph\n   &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1 pid_05 week_1     treatment            3      0.19   3.2\n 2 pid_05 week_7     treatment            2      0.45   3.5\n 3 pid_09 week_1     treatment            3      0.27   3.6\n 4 pid_10 week_1     treatment            0      0.01   3.5\n 5 pid_10 week_7     treatment            1      2.87   2.9\n 6 pid_11 week_1     treatment            1      0.1    3.3\n 7 pid_15 week_1     treatment            3      0.84   3.4\n 8 pid_15 week_7     treatment            3      0.68   3.5\n 9 pid_16 week_1     treatment            0      0.03   3.7\n10 pid_16 week_7     treatment            2      0.5    3.2\n# ℹ 29 more rows"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#pick-columns-from-a-table-select",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#pick-columns-from-a-table-select",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Pick columns from a table: select()",
    "text": "Pick columns from a table: select()"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#pick-columns-pid-ph-and-nugent",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#pick-columns-pid-ph-and-nugent",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Pick columns pid, ph, and nugent",
    "text": "Pick columns pid, ph, and nugent\n\n```{r}\ntable_02 %&gt;%\n  select(pid, ph, nugent_score)\n```\n\n# A tibble: 132 × 3\n   pid       ph nugent_score\n   &lt;chr&gt;  &lt;dbl&gt;        &lt;dbl&gt;\n 1 pid_01   5.7            8\n 2 pid_01   5.2            7\n 3 pid_01   5.4            7\n 4 pid_02   5.2            7\n 5 pid_02   4.8            7\n 6 pid_02   4.2            4\n 7 pid_03   4.8            6\n 8 pid_03   5.3           10\n 9 pid_03   5.2            7\n10 pid_04   4.8            5\n# ℹ 122 more rows"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#rename-columns-and-subset-with-select",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#rename-columns-and-subset-with-select",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Rename columns and subset with select",
    "text": "Rename columns and subset with select\n\n```{r}\ntable_02 %&gt;%\n  select(participant_id = pid, ph, nugent_score)\n```\n\n# A tibble: 132 × 3\n   participant_id    ph nugent_score\n   &lt;chr&gt;          &lt;dbl&gt;        &lt;dbl&gt;\n 1 pid_01           5.7            8\n 2 pid_01           5.2            7\n 3 pid_01           5.4            7\n 4 pid_02           5.2            7\n 5 pid_02           4.8            7\n 6 pid_02           4.2            4\n 7 pid_03           4.8            6\n 8 pid_03           5.3           10\n 9 pid_03           5.2            7\n10 pid_04           4.8            5\n# ℹ 122 more rows"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#sort-the-rows-in-a-table-arrange",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#sort-the-rows-in-a-table-arrange",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Sort the rows in a table: arrange()",
    "text": "Sort the rows in a table: arrange()"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#sort-samples-by-ph-ascending",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#sort-samples-by-ph-ascending",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Sort samples by ph ascending",
    "text": "Sort samples by ph ascending\n\n```{r}\ntable_02 %&gt;%\n  arrange(ph)\n```\n\n# A tibble: 132 × 6\n   pid    time_point arm       nugent_score crp_blood    ph\n   &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1 pid_31 week_7     treatment            2      1.36   2.8\n 2 pid_10 week_7     treatment            1      2.87   2.9\n 3 pid_28 baseline   treatment            3      0.67   2.9\n 4 pid_26 week_1     treatment            0      0.11   3  \n 5 pid_23 week_7     placebo              3      3.67   3.1\n 6 pid_40 baseline   treatment            3      1.48   3.1\n 7 pid_40 week_1     treatment            2      0.17   3.1\n 8 pid_05 week_1     treatment            3      0.19   3.2\n 9 pid_16 week_7     treatment            2      0.5    3.2\n10 pid_37 week_7     treatment            2      0.7    3.2\n# ℹ 122 more rows"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#sort-samples-by-ph-descending",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#sort-samples-by-ph-descending",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Sort samples by ph, descending",
    "text": "Sort samples by ph, descending\n\n```{r}\ntable_02 %&gt;%\n  arrange(desc(ph))\n```\n\n# A tibble: 132 × 6\n   pid    time_point arm       nugent_score crp_blood    ph\n   &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1 pid_29 baseline   placebo              7      2.39   5.8\n 2 pid_01 baseline   placebo              8      0.44   5.7\n 3 pid_16 baseline   treatment            6      1.91   5.7\n 4 pid_06 week_1     placebo              8      1.72   5.6\n 5 pid_26 baseline   treatment            7      0.94   5.6\n 6 pid_13 week_1     placebo              7      2.57   5.5\n 7 pid_23 week_1     placebo              8      0.8    5.5\n 8 pid_27 baseline   placebo              7      1.17   5.5\n 9 pid_01 week_7     placebo              7      1.44   5.4\n10 pid_04 week_7     placebo              7      5.68   5.4\n# ℹ 122 more rows"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#counting-things",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#counting-things",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Counting things",
    "text": "Counting things\nTo demonstrate counting, let’s switch to table_01\n\n```{r}\ntable_01\n```\n\n# A tibble: 44 × 6\n   pid    arm       smoker       age education                     sex  \n   &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                         &lt;lgl&gt;\n 1 pid_01 placebo   non-smoker    26 grade 10-12, matriculated     FALSE\n 2 pid_02 placebo   smoker        33 grade 10-12, matriculated     FALSE\n 3 pid_03 placebo   smoker        30 post-secondary                FALSE\n 4 pid_04 placebo   non-smoker    34 grade 10-12, not matriculated FALSE\n 5 pid_05 treatment non-smoker    29 grade 10-12, matriculated     FALSE\n 6 pid_06 placebo   smoker        34 post-secondary                FALSE\n 7 pid_07 placebo   non-smoker    31 grade 10-12, not matriculated FALSE\n 8 pid_08 placebo   smoker        30 grade 10-12, not matriculated FALSE\n 9 pid_09 treatment non-smoker    35 grade 10-12, not matriculated FALSE\n10 pid_10 treatment non-smoker    32 less than grade 9             FALSE\n# ℹ 34 more rows"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#counting-things-1",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#counting-things-1",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Counting things",
    "text": "Counting things\n\n```{r}\ntable_01 %&gt;%\n  count(smoker)\n```\n\n# A tibble: 2 × 2\n  smoker         n\n  &lt;chr&gt;      &lt;int&gt;\n1 non-smoker    27\n2 smoker        17"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#counting-things-2",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#counting-things-2",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Counting things",
    "text": "Counting things\n\n```{r}\ntable_01 %&gt;%\n  count(arm, smoker)\n```\n\n# A tibble: 4 × 3\n  arm       smoker         n\n  &lt;chr&gt;     &lt;chr&gt;      &lt;int&gt;\n1 placebo   non-smoker    12\n2 placebo   smoker        11\n3 treatment non-smoker    15\n4 treatment smoker         6"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#lets-take-a-poll-1",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#lets-take-a-poll-1",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Let’s take a poll",
    "text": "Let’s take a poll\nGo to the event on wooclap\n\nM2. Does filter get rid of rows that match TRUE, or keep rows that match TRUE?"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#use-the-pipe-to-build-analysis-pipelines",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#use-the-pipe-to-build-analysis-pipelines",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Use the pipe to build analysis pipelines",
    "text": "Use the pipe to build analysis pipelines\n\n```{r}\ntable_01 %&gt;%\n  filter(arm == \"placebo\")\n```\n\n# A tibble: 23 × 6\n   pid    arm     smoker       age education                     sex  \n   &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                         &lt;lgl&gt;\n 1 pid_01 placebo non-smoker    26 grade 10-12, matriculated     FALSE\n 2 pid_02 placebo smoker        33 grade 10-12, matriculated     FALSE\n 3 pid_03 placebo smoker        30 post-secondary                FALSE\n 4 pid_04 placebo non-smoker    34 grade 10-12, not matriculated FALSE\n 5 pid_06 placebo smoker        34 post-secondary                FALSE\n 6 pid_07 placebo non-smoker    31 grade 10-12, not matriculated FALSE\n 7 pid_08 placebo smoker        30 grade 10-12, not matriculated FALSE\n 8 pid_12 placebo non-smoker    31 grade 10-12, matriculated     FALSE\n 9 pid_13 placebo non-smoker    32 post-secondary                FALSE\n10 pid_14 placebo smoker        32 grade 10-12, matriculated     FALSE\n# ℹ 13 more rows"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#use-the-pipe-to-build-analysis-pipelines-1",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#use-the-pipe-to-build-analysis-pipelines-1",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Use the pipe to build analysis pipelines",
    "text": "Use the pipe to build analysis pipelines\n\n```{r}\ntable_01 %&gt;%\n  filter(age &lt; 30) %&gt;%\n  select(pid, arm, smoker)\n```\n\n# A tibble: 12 × 3\n   pid    arm       smoker    \n   &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;     \n 1 pid_01 placebo   non-smoker\n 2 pid_05 treatment non-smoker\n 3 pid_15 treatment non-smoker\n 4 pid_17 treatment non-smoker\n 5 pid_21 treatment non-smoker\n 6 pid_27 placebo   smoker    \n 7 pid_30 placebo   non-smoker\n 8 pid_31 treatment non-smoker\n 9 pid_35 placebo   non-smoker\n10 pid_36 placebo   non-smoker\n11 pid_41 treatment smoker    \n12 pid_44 treatment non-smoker"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#use-the-pipe-to-build-analysis-pipelines-2",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#use-the-pipe-to-build-analysis-pipelines-2",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Use the pipe to build analysis pipelines",
    "text": "Use the pipe to build analysis pipelines\n\n```{r}\ntable_01 %&gt;%\n  filter(age &lt; 30) %&gt;%\n  select(pid, arm, smoker) %&gt;%\n  count(arm, smoker)\n```\n\n# A tibble: 4 × 3\n  arm       smoker         n\n  &lt;chr&gt;     &lt;chr&gt;      &lt;int&gt;\n1 placebo   non-smoker     4\n2 placebo   smoker         1\n3 treatment non-smoker     6\n4 treatment smoker         1"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#adding-new-columns-to-a-table",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#adding-new-columns-to-a-table",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Adding new columns to a table",
    "text": "Adding new columns to a table"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#make-a-new-table-column-mutate",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#make-a-new-table-column-mutate",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Make a new table column: mutate()",
    "text": "Make a new table column: mutate()"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#example-c-reactive-protein",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#example-c-reactive-protein",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Example: C-reactive protein",
    "text": "Example: C-reactive protein\nThe crp_blood column is in units of mg/L. What if you needed it in ug/ul? What’s the calculation?\n\n```{r}\ntable_02 %&gt;%\n  select(pid, time_point, crp_blood)\n```\n\n# A tibble: 132 × 3\n   pid    time_point crp_blood\n   &lt;chr&gt;  &lt;chr&gt;          &lt;dbl&gt;\n 1 pid_01 baseline        0.44\n 2 pid_01 week_1          1.66\n 3 pid_01 week_7          1.44\n 4 pid_02 baseline        1.55\n 5 pid_02 week_1          0.75\n 6 pid_02 week_7          1.17\n 7 pid_03 baseline        1.78\n 8 pid_03 week_1          0.57\n 9 pid_03 week_7          1.79\n10 pid_04 baseline        1.76\n# ℹ 122 more rows"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#example-c-reactive-protein-1",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#example-c-reactive-protein-1",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Example: C-reactive protein",
    "text": "Example: C-reactive protein\nThe crp_blood column is in units of mg/L. What if you needed it in ug/ul? What’s the calculation?\nTo get ug/L you would multiply by 1000. To get ug/ul you need to then divide by 1000000\n\n```{r}\ntable_02 %&gt;%\n  select(pid, time_point, crp_blood)\n```\n\n# A tibble: 132 × 3\n   pid    time_point crp_blood\n   &lt;chr&gt;  &lt;chr&gt;          &lt;dbl&gt;\n 1 pid_01 baseline        0.44\n 2 pid_01 week_1          1.66\n 3 pid_01 week_7          1.44\n 4 pid_02 baseline        1.55\n 5 pid_02 week_1          0.75\n 6 pid_02 week_7          1.17\n 7 pid_03 baseline        1.78\n 8 pid_03 week_1          0.57\n 9 pid_03 week_7          1.79\n10 pid_04 baseline        1.76\n# ℹ 122 more rows"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#example-c-reactive-protein-2",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#example-c-reactive-protein-2",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Example: C-reactive protein",
    "text": "Example: C-reactive protein\nThe crp_blood column is in units of mg/L. What if you needed it in ug/ul? What’s the calculation?\nTo get ug/L you would multiply by 1000. To get ug/ul you need to then divide by 1000000\n\n```{r}\ntable_02 %&gt;%\n  select(pid, time_point, crp_blood) %&gt;%\n  mutate(crp_blood_ugul = crp_blood / 1000)\n```\n\n# A tibble: 132 × 4\n   pid    time_point crp_blood crp_blood_ugul\n   &lt;chr&gt;  &lt;chr&gt;          &lt;dbl&gt;          &lt;dbl&gt;\n 1 pid_01 baseline        0.44        0.00044\n 2 pid_01 week_1          1.66        0.00166\n 3 pid_01 week_7          1.44        0.00144\n 4 pid_02 baseline        1.55        0.00155\n 5 pid_02 week_1          0.75        0.00075\n 6 pid_02 week_7          1.17        0.00117\n 7 pid_03 baseline        1.78        0.00178\n 8 pid_03 week_1          0.57        0.00057\n 9 pid_03 week_7          1.79        0.00179\n10 pid_04 baseline        1.76        0.00176\n# ℹ 122 more rows"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#make-multiple-columns-at-once",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#make-multiple-columns-at-once",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Make multiple columns at once",
    "text": "Make multiple columns at once\n\n```{r}\ntable_02 %&gt;%\n  select(pid, time_point, crp_blood) %&gt;%\n  mutate(crp_blood_ugul = crp_blood / 1000,\n         crp_blood_ugl = crp_blood * 1000)\n```\n\n# A tibble: 132 × 5\n   pid    time_point crp_blood crp_blood_ugul crp_blood_ugl\n   &lt;chr&gt;  &lt;chr&gt;          &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;\n 1 pid_01 baseline        0.44        0.00044           440\n 2 pid_01 week_1          1.66        0.00166          1660\n 3 pid_01 week_7          1.44        0.00144          1440\n 4 pid_02 baseline        1.55        0.00155          1550\n 5 pid_02 week_1          0.75        0.00075           750\n 6 pid_02 week_7          1.17        0.00117          1170\n 7 pid_03 baseline        1.78        0.00178          1780\n 8 pid_03 week_1          0.57        0.00057           570\n 9 pid_03 week_7          1.79        0.00179          1790\n10 pid_04 baseline        1.76        0.00176          1760\n# ℹ 122 more rows"
  },
  {
    "objectID": "materials/1-workshop1/2-intro-to-r/slides.html#exercise-1",
    "href": "materials/1-workshop1/2-intro-to-r/slides.html#exercise-1",
    "title": "Intro to R,R Studio, and Quarto",
    "section": "Exercise",
    "text": "Exercise\nThat’s enough slides for now time to try for yourself! Go to the module and go to the second exercise.\n\n\n\n−+\n30:00\n\n\n\n\n\nback to module"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/index.html",
    "href": "materials/1-workshop1/3-tidyverse-101/index.html",
    "title": "Intro to data visualization and data wrangling with the\ntidyverse",
    "section": "",
    "text": "Learn the elements of scientific data visualization and how to use them with ggplot2"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/index.html#slides",
    "href": "materials/1-workshop1/3-tidyverse-101/index.html#slides",
    "title": "Intro to data visualization and data wrangling with the\ntidyverse",
    "section": "Slides",
    "text": "Slides\nMake slides full screen"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/index.html#data-visualization-activity",
    "href": "materials/1-workshop1/3-tidyverse-101/index.html#data-visualization-activity",
    "title": "Intro to data visualization and data wrangling with the\ntidyverse",
    "section": "Data Visualization Activity",
    "text": "Data Visualization Activity\nreproduced from a Schmidt Science Fellowship activity, thanks to Fatima Hussain\n\nPatterns are the essence of data exploration and our eyes’ ability to pick them out is integral to data understanding. Much of the data we work with, however, do not have a natural form and we need to make decisions about how they are to be represented. Try different ways to visualize the datasets so meaningful patterns may be found.\n\n\nGenetic profiles of cancer\nThese datasets contains 10 cancer samples. Table 1 describes the mutational status for a set of genes (A-E) and whether a mutation if absent (0) or present (1). Table 2 summarizes the expression levels of those genes, ranging from no expression (0) to high expression (3).\n\n\nTable 1: Mutational status for a set of genes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsample -&gt;\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\nGene A\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n\n\nGene B\n0\n0\n0\n0\n1\n1\n1\n0\n1\n1\n\n\nGene C\n0\n0\n1\n0\n0\n0\n1\n1\n1\n1\n\n\nGene D\n1\n1\n0\n0\n1\n1\n0\n0\n0\n0\n\n\nGene E\n0\n1\n1\n0\n1\n0\n0\n0\n1\n0\n\n\n\n\n\n\nTable 2: Expression levels for a set of genes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsample -&gt;\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\nGene A\n2\n1\n1\n2\n2\n0\n2\n1\n1\n2\n\n\nGene B\n1\n1\n2\n1\n0\n0\n0\n2\n0\n0\n\n\nGene C\n1\n1\n3\n1\n2\n2\n3\n0\n3\n0\n\n\nGene D\n0\n0\n2\n1\n3\n3\n2\n1\n1\n1\n\n\nGene E\n1\n3\n3\n1\n3\n1\n2\n1\n3\n2\n\n\n\n\n\n\n          1. Think about the problem on your own for 5 minutes.\n          2. In your groups, discuss and create different visualizations to highlight underlying patterns\n          3. Summarize the group’s approach\n          4. Elect/volunteer a spokesperson to present the solution\n\n\nConsider the following concepts when creating your visualizations\n\n\n\n\nPatterns\nPatterns are the essence of data exploration. What kinds of representation will produce the most meaningful insights?\n   \n\n\nEncodings\nSome visual estimations are easier to make than others. How might you use encodings that are less accurate but otherwise better at conveying overall trends?\n  \n\n\n\n\nColor\nColor is a powerful encoding that presents several challenges. Have you chosen a color scale that is optimal for that data type?\n   \n\n\nSalience and Relevance\nPop-out effects enable quick recognition. Are the most noticeable elements of your visualizations also the most relevant?"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/index.html#coding-exercise-3.1",
    "href": "materials/1-workshop1/3-tidyverse-101/index.html#coding-exercise-3.1",
    "title": "Intro to data visualization and data wrangling with the\ntidyverse",
    "section": "Coding exercise 3.1",
    "text": "Coding exercise 3.1\nFor this exercise we’ll be using the instructional dataset. Download the dataset here.\nIn this worksheet, we will discuss a core concept of ggplot, the mapping of data values onto aesthetics.\nWe will be using the R package tidyverse, which includes ggplot() and related functions.\nCopy the following code chunk into your quarto document. Notice the error in the read_csv() line - it wants you to supply the file name to read. Fix the error!\n\nlibrary(tidyverse) # load the tidyverse library\n\n# we want to use the data in the visit_clinical_measurements file\nclinical_measurements &lt;- read_csv() # read in your data \n\nError in read_csv(): argument \"file\" is missing, with no default\n\n#then show the first few rows\nhead(clinical_measurements)\n\nError in eval(expr, envir, enclos): object 'clinical_measurements' not found\n\n\n\nBasic use of ggplot\nIn the most basic use of ggplot, we call the ggplot() function with a dataset and an aesthetic mapping (created with aes()), and then we add a geom, such as geom_line() to draw lines or geom_point() to draw points.\nTry this for yourself. Map the column ph onto the x axis and the column crp_blood onto the y axis, and use geom_line() to display the data.\nWhenever you see ___ in the code below, that means you should swap it in with your own code.\n\nggplot(clinical_measurements, aes(x = ___, y = ___)) +\n  ___()\n\nTry again. Now use geom_point() instead of geom_line().\n\nggplot(clinical_measurements, aes(x = ___, y = ___)) +\n  ___()\n\nAnd now swap which column you map to x and which to y.\n\nggplot(clinical_measurements, aes(x = ___, y = ___)) +\n  ___()\n\n\n\nMore complex geoms\nYou can use other geoms to make different types of plots. For example, geom_boxplot() will make boxplots. For boxplots, we frequently want categorical data on the x or y axis. For example, we might want a separate boxplot for each month. Try this out. Put nugent_score on the x axis, ph on the y axis, and use geom_boxplot().\n\nggplot(clinical_measurements, aes(x = ___, y = ___)) +\n  ___()\n\nNow try swapping the x and y axis geom_jitter()\n\nggplot(clinical_measurements, aes(x = ___, y = ___)) +\n  ___()\n\nNow try swapping the x and y axis\n\nggplot(clinical_measurements, aes(x = ___, y = ___)) +\n  ___()\n\n\n\nAdding color\nTry again with geom_jitter(), this time using ph as the location along the y axis and arm for the color. Remember to check the ggplot cheat sheet, or type ?geom_jitter() in the console to and look at the “Aesthetics” section if you get stuck.\n\nggplot(clinical_measurements, aes(x = ___, y = ___)) +\n  ___()\n\n(Hint: Try adding size = 3 as a parameter to the geom_jitter() to create larger points.)\n\n\nUsing aesthetics as parameters\nMany of the aesthetics (such as color, fill, and also size to change line size or point thickness) can be used as parameters inside a geom rather than inside an aes() statement. The difference is that when you use an aesthetic as a parameter, you specify a specific value, such as color = \"blue\", rather than a mapping, such as aes(color = arm). Notice the difference: Inside the aes() function, we don’t actually specify the specific color values, ggplot does that for us. We only say that we want the data values of the arm column to correspond to different colors. (We will learn later how to tell ggplot to use specific colors in this mapping.)\nTry this with the boxplot example from the previous section. Map arm onto the fill aesthetic but set the color of the lines to \"navyblue\".\n\nggplot(clinical_measurements, aes(x = ___, y = ___)) +\n  ___()\n\nNow do the reverse. Map arm onto the line colors of the boxplot, but will the box with the color \"navyblue\".\n\nggplot(clinical_measurements, aes(x = ___, y = ___)) +\n  ___()\n\nGreat, that’s all for now! If you are done, but a green sticky note on your laptop!"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#section",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#section",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "",
    "text": "Workshop materials are at:\nhttps://elsherbini.github.io/durban-data-science-for-biology/"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#section-1",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#section-1",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "",
    "text": "Goals for this session\n\n\nGet the big picture of data visualization\nLearn how to wrangle data and make plots with the tidyverse\n\n\n\n\ndata wrangling (n.) - the art of taking data in one format and filtering, reshaping, and deriving values to make the data format you need."
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#discussions-discord",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#discussions-discord",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Discussions: discord",
    "text": "Discussions: discord\nAsk questions at #workshop-questions on https://discord.gg/UDAsYTzZE."
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#stickies",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#stickies",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Stickies",
    "text": "Stickies\n\n\n\n\n\n\nDuring an activity, place a yellow sticky on your laptop if you’re good to go and a pink sticky if you want help.\n\n\n\n\nImage by Megan Duffy"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#practicalities",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#practicalities",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Practicalities",
    "text": "Practicalities\n\nWiFi:\nNetwork: KTB Free Wifi (no password needed)\nNetwork AHRI Password: @hR1W1F1!17\nNetwork CAPRISA-Corp Password: corp@caprisa17\nBathrooms are out the lobby to your left"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#group-pen-and-paper-exercise",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#group-pen-and-paper-exercise",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Group Pen and Paper exercise",
    "text": "Group Pen and Paper exercise\n\n\n\n−+\n10:00\n\n\n\n\n−+\n30:00\n\n\n\nGet with your group. Go to the activity\n\nFor the first 10 minutes think on your own\nFor 30 minutes discuss with your group and produce at least one plot\nSomeone post a picture on the  #pen-and-paper-activity channel.\nDecide on one member of your group to present your plot (3 minute limit per group)"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#presentation",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#presentation",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Presentation",
    "text": "Presentation\nHave one member from your group present the plot to everyone! 3 minute limit!\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#plots-map-data-onto-graphical-elements.",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#plots-map-data-onto-graphical-elements.",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Plots map data onto graphical elements.",
    "text": "Plots map data onto graphical elements.\n\n\n\n\nTable 1: 02_visit_clinical_measurements_UKZN_workshop_2023.csv\n\n\npid\ntime_point\narm\nnugent_score\ncrp_blood\nph\n\n\n\n\npid_01\nbaseline\nplacebo\n8\n0.44\n5.7\n\n\npid_01\nweek_1\nplacebo\n7\n1.66\n5.2\n\n\npid_01\nweek_7\nplacebo\n7\n1.44\n5.4\n\n\npid_02\nbaseline\nplacebo\n7\n1.55\n5.2\n\n\npid_02\nweek_1\nplacebo\n7\n0.75\n4.8\n\n\npid_02\nweek_7\nplacebo\n4\n1.17\n4.2"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#ph-mapped-to-y-position",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#ph-mapped-to-y-position",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "pH mapped to y position",
    "text": "pH mapped to y position"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#ph-mapped-to-color",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#ph-mapped-to-color",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "pH mapped to color",
    "text": "pH mapped to color"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#commonly-used-aesthetics",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#commonly-used-aesthetics",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Commonly used aesthetics",
    "text": "Commonly used aesthetics\n\nFigure from  Claus O. Wilke. Fundamentals of Data Visualization. O’Reilly, 2019"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#the-same-data-values-can-be-mapped-to-different-aesthetics",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#the-same-data-values-can-be-mapped-to-different-aesthetics",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "The same data values can be mapped to different aesthetics",
    "text": "The same data values can be mapped to different aesthetics\n\nFigure from  Claus O. Wilke. Fundamentals of Data Visualization. O’Reilly, 2019"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#we-can-use-many-different-aesthetics-at-once",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#we-can-use-many-different-aesthetics-at-once",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "We can use many different aesthetics at once",
    "text": "We can use many different aesthetics at once"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#we-define-the-mapping-with-aes",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#we-define-the-mapping-with-aes",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "We define the mapping with aes()",
    "text": "We define the mapping with aes()\n\n```{r}\ntable_02 %&gt;%\n  ggplot(mapping = aes(x = time_point, y = ph, color = ph)) +\n  geom_jitter()\n```"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#we-frequently-omit-argument-names",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#we-frequently-omit-argument-names",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "We frequently omit argument names",
    "text": "We frequently omit argument names\nLong form, all arguments are named:\n\n```{r}\n#| eval: false\n\nggplot(\n  data= table_02,\n  mapping = aes(x = time_point, y = ph, color = ph)\n) +\n  geom_jitter()\n```"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#we-frequently-omit-argument-names-1",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#we-frequently-omit-argument-names-1",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "We frequently omit argument names",
    "text": "We frequently omit argument names\nAbbreviated form, common arguments remain unnamed:\n\n```{r}\n#| eval: false\n\nggplot(table_02, aes(x = time_point, y = ph, color = ph)) +\n  geom_jitter()\n```"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#the-geom-determines-how-the-data-is-shown",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#the-geom-determines-how-the-data-is-shown",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "The geom determines how the data is shown",
    "text": "The geom determines how the data is shown\n\n```{r}\nggplot(table_02, aes(x = time_point, y = ph, color = ph)) +\n  geom_point()\n```"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#the-geom-determines-how-the-data-is-shown-1",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#the-geom-determines-how-the-data-is-shown-1",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "The geom determines how the data is shown",
    "text": "The geom determines how the data is shown\n\n```{r}\nggplot(table_02, aes(x = time_point, y = ph, color = ph)) +\n  geom_boxplot()\n```"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#the-geom-determines-how-the-data-is-shown-2",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#the-geom-determines-how-the-data-is-shown-2",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "The geom determines how the data is shown",
    "text": "The geom determines how the data is shown\n\n```{r}\nggplot(table_02, aes(x = time_point, y = ph, color = ph)) +\n  geom_jitter()\n```"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#different-geoms-have-parameters-for-control",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#different-geoms-have-parameters-for-control",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Different geoms have parameters for control",
    "text": "Different geoms have parameters for control\n\n```{r}\nggplot(table_02, aes(x = time_point, y = ph, color = ph)) +\n  geom_jitter(size=3)\n```"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#different-geoms-have-parameters-for-control-1",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#different-geoms-have-parameters-for-control-1",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Different geoms have parameters for control",
    "text": "Different geoms have parameters for control\n\n```{r}\nggplot(table_02, aes(x = time_point, y = ph, color = ph)) +\n  geom_jitter(size=3, width = 0.2)\n```"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#important-color-and-fill-apply-to-different-elements",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#important-color-and-fill-apply-to-different-elements",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Important: color and fill apply to different elements",
    "text": "Important: color and fill apply to different elements\ncolor Applies color to points, lines, text, borders\nfill Applies color to any filled areas"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#many-geoms-have-both-color-and-fill-aesthetics",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#many-geoms-have-both-color-and-fill-aesthetics",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Many geoms have both color and fill aesthetics",
    "text": "Many geoms have both color and fill aesthetics\n\n\n```{r}\n#| output-location: column\nggplot(\n  data = table_02,\n  mapping = aes(\n    x = time_point,\n    y = ph,\n    color = time_point\n  )\n) + geom_boxplot()\n```"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#many-geoms-have-both-color-and-fill-aesthetics-1",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#many-geoms-have-both-color-and-fill-aesthetics-1",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Many geoms have both color and fill aesthetics",
    "text": "Many geoms have both color and fill aesthetics\n\n\n```{r}\n#| output-location: column\nggplot(\n  data = table_02,\n  mapping = aes(\n    x = time_point,\n    y = ph,\n    fill = time_point\n  )\n) + geom_boxplot()\n```"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#many-geoms-have-both-color-and-fill-aesthetics-2",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#many-geoms-have-both-color-and-fill-aesthetics-2",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Many geoms have both color and fill aesthetics",
    "text": "Many geoms have both color and fill aesthetics\n\n\n```{r}\n#| output-location: column\nggplot(\n  data = table_02,\n  mapping = aes(\n    x = time_point,\n    y = ph,\n    fill = time_point,\n    color = time_point\n  )\n) + geom_boxplot()\n```"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#aesthetics-can-also-be-used-as-parameters-in-geoms",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#aesthetics-can-also-be-used-as-parameters-in-geoms",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Aesthetics can also be used as parameters in geoms",
    "text": "Aesthetics can also be used as parameters in geoms\n\n\n```{r}\n#| output-location: column\nggplot(\n  data = table_02,\n  mapping = aes(\n    x = time_point,\n    y = ph\n  )\n) + geom_boxplot()\n```"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#aesthetics-can-also-be-used-as-parameters-in-geoms-1",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#aesthetics-can-also-be-used-as-parameters-in-geoms-1",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Aesthetics can also be used as parameters in geoms",
    "text": "Aesthetics can also be used as parameters in geoms\n\n\n```{r}\n#| output-location: column\nggplot(\n  data = table_02,\n  mapping = aes(\n    x = time_point,\n    y = ph\n  )\n) + geom_boxplot(fill=\"orange\")\n```"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#exercise",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#exercise",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n−+\n30:00\n\n\n\nTime to try it yourself. Go to the first coding exercise.\n\nDuring an activity, place a blue sticky on your laptop if you’re good to go and a pink sticky if you want help."
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#we-often-encounter-datasets-containing-simple-amounts",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#we-often-encounter-datasets-containing-simple-amounts",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "We often encounter datasets containing simple amounts",
    "text": "We often encounter datasets containing simple amounts\nExample: Highest grossing movies 2023 to date\n\n\n\n\n\nrank\ntitle\namount\n\n\n\n\n1\nBarbie\n1437.8\n\n\n2\nThe Super Mario Bros Movie\n1361.9\n\n\n3\nOppenheimer\n939.3\n\n\n4\nGuardians of the Galaxy 3\n845.5\n\n\n5\nThe Little Mermaid\n569.6\n\n\n\n\n\n\n\nMillions USD. Data source: Box Office Mojo"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#we-can-visualize-amounts-with-bar-plots",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#we-can-visualize-amounts-with-bar-plots",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "We can visualize amounts with bar plots",
    "text": "We can visualize amounts with bar plots"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#bars-can-also-run-horizontally",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#bars-can-also-run-horizontally",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Bars can also run horizontally",
    "text": "Bars can also run horizontally"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#avoid-rotated-axis-labels",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#avoid-rotated-axis-labels",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Avoid rotated axis labels",
    "text": "Avoid rotated axis labels"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#avoid-rotated-axis-labels---flip-the-axes",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#avoid-rotated-axis-labels---flip-the-axes",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Avoid rotated axis labels - flip the axes!",
    "text": "Avoid rotated axis labels - flip the axes!"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#pay-attention-to-the-order-of-the-bars",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#pay-attention-to-the-order-of-the-bars",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Pay attention to the order of the bars",
    "text": "Pay attention to the order of the bars"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#pay-attention-to-the-order-of-the-bars-1",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#pay-attention-to-the-order-of-the-bars-1",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Pay attention to the order of the bars",
    "text": "Pay attention to the order of the bars"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#we-can-use-dots-instead-of-bars",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#we-can-use-dots-instead-of-bars",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "We can use dots instead of bars",
    "text": "We can use dots instead of bars"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#dots-are-preferable-if-we-want-to-truncate-the-axes",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#dots-are-preferable-if-we-want-to-truncate-the-axes",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Dots are preferable if we want to truncate the axes",
    "text": "Dots are preferable if we want to truncate the axes"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#dots-are-preferable-if-we-want-to-truncate-the-axes-1",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#dots-are-preferable-if-we-want-to-truncate-the-axes-1",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Dots are preferable if we want to truncate the axes",
    "text": "Dots are preferable if we want to truncate the axes\n\nbar lengths do not accurately represent the data values"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#dots-are-preferable-if-we-want-to-truncate-the-axes-2",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#dots-are-preferable-if-we-want-to-truncate-the-axes-2",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Dots are preferable if we want to truncate the axes",
    "text": "Dots are preferable if we want to truncate the axes\n\nkey features of the data are obscured"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#dots-are-preferable-if-we-want-to-truncate-the-axes-3",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#dots-are-preferable-if-we-want-to-truncate-the-axes-3",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Dots are preferable if we want to truncate the axes",
    "text": "Dots are preferable if we want to truncate the axes"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#lets-take-a-poll",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#lets-take-a-poll",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Let’s take a poll",
    "text": "Let’s take a poll\nGo to the event on wooclap\n\nM3. Do you think it makes sense to truncate the axes for the life expectancy data?"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#we-use-grouped-bars-for-higher-dimensional-datasets",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#we-use-grouped-bars-for-higher-dimensional-datasets",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "We use grouped bars for higher-dimensional datasets",
    "text": "We use grouped bars for higher-dimensional datasets"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#we-are-free-to-choose-by-which-variable-to-group",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#we-are-free-to-choose-by-which-variable-to-group",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "We are free to choose by which variable to group",
    "text": "We are free to choose by which variable to group"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#we-can-also-use-multiple-plot-panels-facets",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#we-can-also-use-multiple-plot-panels-facets",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "We can also use multiple plot panels (facets)",
    "text": "We can also use multiple plot panels (facets)"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#the-simple-dataset",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#the-simple-dataset",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "The simple dataset",
    "text": "The simple dataset\n\n# Data from Box Office Mojo for 2023. \nboxoffice &lt;- tibble(\n  rank = 1:5,\n  title = c(\"Barbie\", \"The Super Mario Bros Movie\", \"Oppenheimer\", \"Guardians of the Galaxy 3\", \"The Little Mermaid\"),\n  amount = c(1437.8, 1361.9, 939.3, 845.5, 569.6) # million USD\n)\n\n\n\n\n\n\nrank\ntitle\namount\n\n\n\n\n1\nBarbie\n1437.8\n\n\n2\nThe Super Mario Bros Movie\n1361.9\n\n\n3\nOppenheimer\n939.3\n\n\n4\nGuardians of the Galaxy 3\n845.5\n\n\n5\nThe Little Mermaid\n569.6"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#visualize-as-a-bar-plot",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#visualize-as-a-bar-plot",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Visualize as a bar plot",
    "text": "Visualize as a bar plot\n\nggplot(boxoffice, aes(title, amount)) +\n  geom_col()  # \"col\" stands for column"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#order-by-data-value",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#order-by-data-value",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Order by data value",
    "text": "Order by data value\n\nggplot(boxoffice, aes(fct_reorder(title, amount), amount)) +\n  geom_col()"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#order-by-data-value-descending",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#order-by-data-value-descending",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Order by data value, descending",
    "text": "Order by data value, descending\n\nggplot(boxoffice, aes(fct_reorder(title, -amount), amount)) +\n  geom_col() + \n  xlab(NULL) # remove x axis label"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#flip-x-and-y-set-custom-x-axis-label",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#flip-x-and-y-set-custom-x-axis-label",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Flip x and y, set custom x axis label",
    "text": "Flip x and y, set custom x axis label\n\nggplot(boxoffice, aes(amount, fct_reorder(title, amount))) +\n  geom_col() +\n  xlab(\"amount (in million USD)\") +\n  ylab(NULL)"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#sometimes-we-need-to-count-before-visualization",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#sometimes-we-need-to-count-before-visualization",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Sometimes we need to count before visualization",
    "text": "Sometimes we need to count before visualization\n\nlibrary(here)\nlibrary(tidyverse)\n\ntable_02 &lt;- read_csv(here(\"datasets/instructional_dataset/02_visit_clinical_measurements_UKZN_workshop_2023.csv\")) %&gt;%\n  mutate(nugent_score = as_factor(nugent_score))\n\n\n\n\n\n\npid\ntime_point\narm\nnugent_score\ncrp_blood\nph\n\n\n\n\npid_01\nbaseline\nplacebo\n8\n0.44\n5.7\n\n\npid_01\nweek_1\nplacebo\n7\n1.66\n5.2\n\n\npid_01\nweek_7\nplacebo\n7\n1.44\n5.4\n\n\npid_02\nbaseline\nplacebo\n7\n1.55\n5.2\n\n\npid_02\nweek_1\nplacebo\n7\n0.75\n4.8\n\n\npid_02\nweek_7\nplacebo\n4\n1.17\n4.2\n\n\npid_03\nbaseline\nplacebo\n6\n1.78\n4.8\n\n\npid_03\nweek_1\nplacebo\n10\n0.57\n5.3\n\n\npid_03\nweek_7\nplacebo\n7\n1.79\n5.2\n\n\npid_04\nbaseline\nplacebo\n5\n1.76\n4.8\n\n\npid_04\nweek_1\nplacebo\n9\n2.58\n5.1\n\n\npid_04\nweek_7\nplacebo\n7\n5.68\n5.4\n\n\npid_05\nbaseline\ntreatment\n8\n0.95\n4.9\n\n\npid_05\nweek_1\ntreatment\n3\n0.19\n3.2\n\n\npid_05\nweek_7\ntreatment\n2\n0.45\n3.5\n\n\npid_06\nbaseline\nplacebo\n10\n4.03\n5.3\n\n\npid_06\nweek_1\nplacebo\n8\n1.72\n5.6\n\n\npid_06\nweek_7\nplacebo\n8\n3.19\n5.0\n\n\npid_07\nbaseline\nplacebo\n7\n0.10\n5.2\n\n\npid_07\nweek_1\nplacebo\n7\n1.36\n4.9\n\n\npid_07\nweek_7\nplacebo\n5\n0.38\n5.1\n\n\npid_08\nbaseline\nplacebo\n9\n3.18\n5.4\n\n\npid_08\nweek_1\nplacebo\n5\n1.55\n4.8\n\n\npid_08\nweek_7\nplacebo\n7\n1.77\n5.0\n\n\npid_09\nbaseline\ntreatment\n5\n2.13\n4.9\n\n\npid_09\nweek_1\ntreatment\n3\n0.27\n3.6\n\n\npid_09\nweek_7\ntreatment\n4\n1.04\n4.2\n\n\npid_10\nbaseline\ntreatment\n8\n0.98\n4.9\n\n\npid_10\nweek_1\ntreatment\n0\n0.01\n3.5\n\n\npid_10\nweek_7\ntreatment\n1\n2.87\n2.9\n\n\npid_11\nbaseline\ntreatment\n7\n0.31\n5.0\n\n\npid_11\nweek_1\ntreatment\n1\n0.10\n3.3\n\n\npid_11\nweek_7\ntreatment\n4\n1.15\n5.1\n\n\npid_12\nbaseline\nplacebo\n8\n2.42\n5.0\n\n\npid_12\nweek_1\nplacebo\n6\n0.64\n4.5\n\n\npid_12\nweek_7\nplacebo\n9\n4.36\n5.2\n\n\npid_13\nbaseline\nplacebo\n8\n2.69\n5.1\n\n\npid_13\nweek_1\nplacebo\n7\n2.57\n5.5\n\n\npid_13\nweek_7\nplacebo\n8\n1.98\n4.8\n\n\npid_14\nbaseline\nplacebo\n7\n0.34\n5.3\n\n\npid_14\nweek_1\nplacebo\n5\n2.07\n4.2\n\n\npid_14\nweek_7\nplacebo\n7\n5.06\n5.1\n\n\npid_15\nbaseline\ntreatment\n7\n0.29\n4.8\n\n\npid_15\nweek_1\ntreatment\n3\n0.84\n3.4\n\n\npid_15\nweek_7\ntreatment\n3\n0.68\n3.5\n\n\npid_16\nbaseline\ntreatment\n6\n1.91\n5.7\n\n\npid_16\nweek_1\ntreatment\n0\n0.03\n3.7\n\n\npid_16\nweek_7\ntreatment\n2\n0.50\n3.2\n\n\npid_17\nbaseline\ntreatment\n5\n1.39\n4.8\n\n\npid_17\nweek_1\ntreatment\n2\n0.00\n3.3\n\n\npid_17\nweek_7\ntreatment\n3\n0.90\n3.7\n\n\npid_18\nbaseline\ntreatment\n6\n0.45\n4.3\n\n\npid_18\nweek_1\ntreatment\n1\n1.81\n3.6\n\n\npid_18\nweek_7\ntreatment\n6\n0.41\n3.9\n\n\npid_19\nbaseline\nplacebo\n7\n1.34\n5.3\n\n\npid_19\nweek_1\nplacebo\n5\n2.91\n4.3\n\n\npid_19\nweek_7\nplacebo\n5\n1.27\n4.5\n\n\npid_20\nbaseline\nplacebo\n4\n0.86\n4.3\n\n\npid_20\nweek_1\nplacebo\n8\n1.45\n5.2\n\n\npid_20\nweek_7\nplacebo\n5\n3.95\n4.9\n\n\npid_21\nbaseline\ntreatment\n5\n0.50\n4.6\n\n\npid_21\nweek_1\ntreatment\n1\n1.60\n3.4\n\n\npid_21\nweek_7\ntreatment\n4\n1.23\n4.8\n\n\npid_22\nbaseline\ntreatment\n6\n1.10\n4.0\n\n\npid_22\nweek_1\ntreatment\n3\n0.58\n4.2\n\n\npid_22\nweek_7\ntreatment\n6\n1.67\n5.1\n\n\npid_23\nbaseline\nplacebo\n8\n0.99\n5.4\n\n\npid_23\nweek_1\nplacebo\n8\n0.80\n5.5\n\n\npid_23\nweek_7\nplacebo\n3\n3.67\n3.1\n\n\npid_24\nbaseline\nplacebo\n5\n4.91\n3.8\n\n\npid_24\nweek_1\nplacebo\n7\n0.94\n5.1\n\n\npid_24\nweek_7\nplacebo\n4\n1.03\n4.5\n\n\npid_25\nbaseline\ntreatment\n3\n2.84\n3.9\n\n\npid_25\nweek_1\ntreatment\n4\n3.52\n4.7\n\n\npid_25\nweek_7\ntreatment\n2\n0.49\n3.7\n\n\npid_26\nbaseline\ntreatment\n7\n0.94\n5.6\n\n\npid_26\nweek_1\ntreatment\n0\n0.11\n3.0\n\n\npid_26\nweek_7\ntreatment\n4\n0.29\n4.8\n\n\npid_27\nbaseline\nplacebo\n7\n1.17\n5.5\n\n\npid_27\nweek_1\nplacebo\n5\n1.62\n4.7\n\n\npid_27\nweek_7\nplacebo\n8\n0.76\n4.7\n\n\npid_28\nbaseline\ntreatment\n3\n0.67\n2.9\n\n\npid_28\nweek_1\ntreatment\n1\n0.05\n3.3\n\n\npid_28\nweek_7\ntreatment\n1\n0.22\n3.5\n\n\npid_29\nbaseline\nplacebo\n7\n2.39\n5.8\n\n\npid_29\nweek_1\nplacebo\n4\n4.09\n4.5\n\n\npid_29\nweek_7\nplacebo\n3\n3.13\n3.5\n\n\npid_30\nbaseline\nplacebo\n7\n0.85\n4.8\n\n\npid_30\nweek_1\nplacebo\n8\n2.56\n5.1\n\n\npid_30\nweek_7\nplacebo\n7\n1.62\n5.2\n\n\npid_31\nbaseline\ntreatment\n6\n1.78\n4.4\n\n\npid_31\nweek_1\ntreatment\n2\n0.41\n3.5\n\n\npid_31\nweek_7\ntreatment\n2\n1.36\n2.8\n\n\npid_32\nbaseline\ntreatment\n5\n4.83\n4.9\n\n\npid_32\nweek_1\ntreatment\n1\n0.03\n3.3\n\n\npid_32\nweek_7\ntreatment\n3\n0.21\n3.8\n\n\npid_33\nbaseline\ntreatment\n6\n5.26\n4.6\n\n\npid_33\nweek_1\ntreatment\n1\n0.07\n3.6\n\n\npid_33\nweek_7\ntreatment\n2\n1.92\n3.3\n\n\npid_34\nbaseline\nplacebo\n8\n3.16\n5.4\n\n\npid_34\nweek_1\nplacebo\n4\n1.12\n4.7\n\n\npid_34\nweek_7\nplacebo\n7\n2.34\n5.3\n\n\npid_35\nbaseline\nplacebo\n8\n0.74\n5.3\n\n\npid_35\nweek_1\nplacebo\n5\n0.16\n4.4\n\n\npid_35\nweek_7\nplacebo\n3\n1.97\n3.9\n\n\npid_36\nbaseline\nplacebo\n8\n1.21\n5.1\n\n\npid_36\nweek_1\nplacebo\n5\n2.28\n4.3\n\n\npid_36\nweek_7\nplacebo\n8\n1.10\n4.8\n\n\npid_37\nbaseline\ntreatment\n5\n1.16\n4.8\n\n\npid_37\nweek_1\ntreatment\n1\n0.07\n3.6\n\n\npid_37\nweek_7\ntreatment\n2\n0.70\n3.2\n\n\npid_38\nbaseline\nplacebo\n8\n0.41\n5.1\n\n\npid_38\nweek_1\nplacebo\n5\n1.55\n4.8\n\n\npid_38\nweek_7\nplacebo\n4\n3.22\n4.5\n\n\npid_39\nbaseline\ntreatment\n6\n1.61\n4.6\n\n\npid_39\nweek_1\ntreatment\n2\n0.09\n3.6\n\n\npid_39\nweek_7\ntreatment\n5\n0.77\n4.7\n\n\npid_40\nbaseline\ntreatment\n3\n1.48\n3.1\n\n\npid_40\nweek_1\ntreatment\n2\n0.17\n3.1\n\n\npid_40\nweek_7\ntreatment\n6\n0.21\n4.5\n\n\npid_41\nbaseline\ntreatment\n4\n1.51\n4.3\n\n\npid_41\nweek_1\ntreatment\n2\n0.64\n3.4\n\n\npid_41\nweek_7\ntreatment\n4\n0.78\n4.4\n\n\npid_42\nbaseline\nplacebo\n6\n0.91\n4.7\n\n\npid_42\nweek_1\nplacebo\n5\n0.88\n4.3\n\n\npid_42\nweek_7\nplacebo\n7\n3.06\n5.3\n\n\npid_43\nbaseline\nplacebo\n6\n1.08\n4.7\n\n\npid_43\nweek_1\nplacebo\n6\n0.94\n4.1\n\n\npid_43\nweek_7\nplacebo\n6\n1.79\n4.1\n\n\npid_44\nbaseline\ntreatment\n6\n0.48\n4.4\n\n\npid_44\nweek_1\ntreatment\n1\n1.67\n3.5\n\n\npid_44\nweek_7\ntreatment\n3\n0.60\n3.4"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#goal-visualize-number-of-people-with-different-nugent-scores",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#goal-visualize-number-of-people-with-different-nugent-scores",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Goal: Visualize number of people with different nugent scores",
    "text": "Goal: Visualize number of people with different nugent scores"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#use-geom_bar-to-count-before-plotting",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#use-geom_bar-to-count-before-plotting",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Use geom_bar() to count before plotting",
    "text": "Use geom_bar() to count before plotting\n\ntable_02 %&gt;%\n  ggplot(aes(y=nugent_score))+\n  geom_bar()"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#getting-the-bars-into-the-right-order",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#getting-the-bars-into-the-right-order",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Getting the bars into the right order",
    "text": "Getting the bars into the right order\n\ntable_01 %&gt;%\n  ggplot(aes(y=education))+\n  geom_bar()"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#getting-the-bars-into-the-right-order-1",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#getting-the-bars-into-the-right-order-1",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Getting the bars into the right order",
    "text": "Getting the bars into the right order\n\neducation_order &lt;- c(\"less than grade 9\",\"grade 10-12, not matriculated\",\"grade 10-12, matriculated\",\"post-secondary\")\ntable_01 %&gt;%\n  mutate(education = fct_relevel(education, education_order)) %&gt;%\n  ggplot(aes(y=education))+\n  geom_bar()"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#display-counts-by-smoking-and-education",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#display-counts-by-smoking-and-education",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Display counts by smoking and education",
    "text": "Display counts by smoking and education\n\ntable_01 %&gt;%\n  mutate(education = fct_relevel(education, education_order)) %&gt;%\n  ggplot(aes(y=education, fill=smoker))+\n  geom_bar()"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#positions-define-how-subgroups-are-shown",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#positions-define-how-subgroups-are-shown",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Positions define how subgroups are shown",
    "text": "Positions define how subgroups are shown\nposition = \"dodge\": Place bars for subgroups side-by-side\n\ntable_01 %&gt;%\n  mutate(education = fct_relevel(education, education_order)) %&gt;%\n  ggplot(aes(y=education, fill=smoker))+\n  geom_bar(position = \"dodge\")"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#positions-define-how-subgroups-are-shown-1",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#positions-define-how-subgroups-are-shown-1",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Positions define how subgroups are shown",
    "text": "Positions define how subgroups are shown\nposition = \"stack\": Place bars for subgroups on top of each other\n\ntable_01 %&gt;%\n  mutate(education = fct_relevel(education, education_order)) %&gt;%\n  ggplot(aes(y=education, fill=smoker))+\n  geom_bar(position = \"stack\")"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#positions-define-how-subgroups-are-shown-2",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#positions-define-how-subgroups-are-shown-2",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Positions define how subgroups are shown",
    "text": "Positions define how subgroups are shown\nposition = \"fill\": Like \"stack\", but scale to 100%\n\ntable_01 %&gt;%\n  mutate(education = fct_relevel(education, education_order)) %&gt;%\n  ggplot(aes(y=education, fill=smoker))+\n  geom_bar(position = \"fill\")"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#lets-take-a-poll-1",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#lets-take-a-poll-1",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Let’s take a poll",
    "text": "Let’s take a poll\nGo to the event on wooclap\n\n2 questions: M3. What’s the difference between geom_col and geom_bar? and M3. What patterns did you see in the smoker CRP data (slide 49)?"
  },
  {
    "objectID": "materials/1-workshop1/3-tidyverse-101/slides.html#exercise-1",
    "href": "materials/1-workshop1/3-tidyverse-101/slides.html#exercise-1",
    "title": "Intro to data visualization and data wrangling with the tidyverse",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n−+\n30:00\n\n\n\nTime to try it yourself. Go to back to the module.\n\nDuring an activity, place a yellow sticky on your laptop if you’re good to go and a pink sticky if you want help.\n\n\nback to module"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/index.html",
    "href": "materials/1-workshop1/4-tidyverse-201/index.html",
    "title": "More data wrangling and data visualization with the\ntidyverse",
    "section": "",
    "text": "Make slides full screen"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/index.html#slides",
    "href": "materials/1-workshop1/4-tidyverse-201/index.html#slides",
    "title": "More data wrangling and data visualization with the\ntidyverse",
    "section": "",
    "text": "Make slides full screen"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/index.html#exercise-data-wrangling-2",
    "href": "materials/1-workshop1/4-tidyverse-201/index.html#exercise-data-wrangling-2",
    "title": "More data wrangling and data visualization with the\ntidyverse",
    "section": "Exercise: Data wrangling 2",
    "text": "Exercise: Data wrangling 2\nIn this exercise, we will continue with basic data manipulations, now moving on to grouping and summarizing, making data tables wider or longer, and joining data tables.\nWe will be using the R package, tidyverse for the data manipulation functions %&gt;%, group_by(), summarize(), pivot_wider(), pivot_longer(), and join functions such as left_join()\nPaste the following into the top code chunk of your qmd file.\nDownload the data files from the dataset page and place all 5 files into this directory.\nPaste the following code chunk into a new qmd file in this project:\nlibrary(tidyverse)\n\ntable_01 &lt;- read_csv(\"01_participant_metadata_UKZN_workshop_2023.csv\")\n\ntable_02 &lt;- read_csv(\"02_visit_clinical_measurements_UKZN_workshop_2023.csv\")\n\nAnalyzing subsets\nIn many data analysis settings, we want to break a dataset into subsets and then perform some summary calculation on each subset. The simplest example is counting, which we have done previously with the count() function.\n\n```{r}\ntable_01 %&gt;%\n  count(arm)\n```\n\n# A tibble: 2 × 2\n  arm           n\n  &lt;chr&gt;     &lt;int&gt;\n1 placebo      23\n2 treatment    21\n\n\nThis function subdivides the penguins dataset into subsets for each species and then calculates the number n for each subset, which is the number of observations in each subset.\nThe function count() here does all the work for us, but what if instead of counting we wanted to calculate the mean weight of the penguins for each species, or calculate the mean weight and count at the same time? We need a general framework that allows us to do these kinds of calculations with maximum flexibility.\nThe tidyverse approach is to first group a dataset with group_by() and then to calculate grouped summaries with summarize().\n\n\nGrouping\nLet’s first consider just grouping. If we look at the raw R output of just the penguins table or the penguins table after running it through group_by(arm), we see that the table is the same, except in the second case there is a line # Groups: arm [2] which indicates that the table is grouped by arm and there are two groups. (Here, we need to pipe the tables into the print() function to see the raw R output instead of a formatted table that would hide the grouping information.)\n\ntable_01 %&gt;%\n  print()\n\n# A tibble: 44 × 6\n   pid    arm       smoker       age education                     sex  \n   &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                         &lt;lgl&gt;\n 1 pid_01 placebo   non-smoker    26 grade 10-12, matriculated     FALSE\n 2 pid_02 placebo   smoker        33 grade 10-12, matriculated     FALSE\n 3 pid_03 placebo   smoker        30 post-secondary                FALSE\n 4 pid_04 placebo   non-smoker    34 grade 10-12, not matriculated FALSE\n 5 pid_05 treatment non-smoker    29 grade 10-12, matriculated     FALSE\n 6 pid_06 placebo   smoker        34 post-secondary                FALSE\n 7 pid_07 placebo   non-smoker    31 grade 10-12, not matriculated FALSE\n 8 pid_08 placebo   smoker        30 grade 10-12, not matriculated FALSE\n 9 pid_09 treatment non-smoker    35 grade 10-12, not matriculated FALSE\n10 pid_10 treatment non-smoker    32 less than grade 9             FALSE\n# ℹ 34 more rows\n\n\n\ntable_01 %&gt;%\n  group_by(arm) %&gt;%\n  print()\n\n# A tibble: 44 × 6\n# Groups:   arm [2]\n   pid    arm       smoker       age education                     sex  \n   &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                         &lt;lgl&gt;\n 1 pid_01 placebo   non-smoker    26 grade 10-12, matriculated     FALSE\n 2 pid_02 placebo   smoker        33 grade 10-12, matriculated     FALSE\n 3 pid_03 placebo   smoker        30 post-secondary                FALSE\n 4 pid_04 placebo   non-smoker    34 grade 10-12, not matriculated FALSE\n 5 pid_05 treatment non-smoker    29 grade 10-12, matriculated     FALSE\n 6 pid_06 placebo   smoker        34 post-secondary                FALSE\n 7 pid_07 placebo   non-smoker    31 grade 10-12, not matriculated FALSE\n 8 pid_08 placebo   smoker        30 grade 10-12, not matriculated FALSE\n 9 pid_09 treatment non-smoker    35 grade 10-12, not matriculated FALSE\n10 pid_10 treatment non-smoker    32 less than grade 9             FALSE\n# ℹ 34 more rows\n\n\nWe can also group by multiple data columns at once, and we can undo any grouping with ungroup().\n\ntable_01 %&gt;%\n  group_by(arm, education) %&gt;%\n  print()\n\n# A tibble: 44 × 6\n# Groups:   arm, education [8]\n   pid    arm       smoker       age education                     sex  \n   &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                         &lt;lgl&gt;\n 1 pid_01 placebo   non-smoker    26 grade 10-12, matriculated     FALSE\n 2 pid_02 placebo   smoker        33 grade 10-12, matriculated     FALSE\n 3 pid_03 placebo   smoker        30 post-secondary                FALSE\n 4 pid_04 placebo   non-smoker    34 grade 10-12, not matriculated FALSE\n 5 pid_05 treatment non-smoker    29 grade 10-12, matriculated     FALSE\n 6 pid_06 placebo   smoker        34 post-secondary                FALSE\n 7 pid_07 placebo   non-smoker    31 grade 10-12, not matriculated FALSE\n 8 pid_08 placebo   smoker        30 grade 10-12, not matriculated FALSE\n 9 pid_09 treatment non-smoker    35 grade 10-12, not matriculated FALSE\n10 pid_10 treatment non-smoker    32 less than grade 9             FALSE\n# ℹ 34 more rows\n\n\n\ntable_01 %&gt;%\n  group_by(arm, education) %&gt;%\n  ungroup() %&gt;%\n  print()\n\n# A tibble: 44 × 6\n   pid    arm       smoker       age education                     sex  \n   &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                         &lt;lgl&gt;\n 1 pid_01 placebo   non-smoker    26 grade 10-12, matriculated     FALSE\n 2 pid_02 placebo   smoker        33 grade 10-12, matriculated     FALSE\n 3 pid_03 placebo   smoker        30 post-secondary                FALSE\n 4 pid_04 placebo   non-smoker    34 grade 10-12, not matriculated FALSE\n 5 pid_05 treatment non-smoker    29 grade 10-12, matriculated     FALSE\n 6 pid_06 placebo   smoker        34 post-secondary                FALSE\n 7 pid_07 placebo   non-smoker    31 grade 10-12, not matriculated FALSE\n 8 pid_08 placebo   smoker        30 grade 10-12, not matriculated FALSE\n 9 pid_09 treatment non-smoker    35 grade 10-12, not matriculated FALSE\n10 pid_10 treatment non-smoker    32 less than grade 9             FALSE\n# ℹ 34 more rows\n\n\nNow try this yourself. Group the table_01 dataset by education_level and smoker.\n\ntable_01 %&gt;%\n  ___ %&gt;%\n  print()\n\nAnswer for yourself How many distinct groups did this produce?\nNow undo the previous grouping.\n\n```{r}\n# build all the code for this exercise\n```\n\nAlso verify what the output looks like when you omit the print() function at the end.\n\n\nPerforming summaries\nOnce we have set up a grouping for a data table, we can then calculate summary data with the summarize() function. This function works similarly to mutate(), in that we provide it with statements of the form &lt;new column name&gt; = &lt;computation&gt;, where &lt;new column name&gt; stands for the name of the new column that is being created and &lt;computation&gt; stands for the computation that is used to generate the values in the new column.\nAs an example, using table_02 we want to calculate the median ph of participants, by arm, we could write summarise(median_ph = median(ph)), and this would create a new column called median_ph\nTry this out. First group by arm and then make the new column:\n\ntable_02 %&gt;%\n  group_by(____) %&gt;%\n  summarise(___)\n\nNow see what it looks like if you instead group by timepoint\n\ntable_02 %&gt;%\n  group_by(____) %&gt;%\n  summarise(___)\n\nNow try grouping by both timepoint and arm\n\ntable_02 %&gt;%\n  group_by(__, __) %&gt;%\n  summarise(___)\n\nWe can perform multiple summaries at once by adding more statements inside the summarise() function, separated by a ,. To try this out, calculate the median nugent in addition to the median ph\n\ntable_02 %&gt;%\n  group_by(____) %&gt;%\n  summarise(___, ___)\n\nWhen performing summaries, we often want to know how many observations there are in each group (i.e., we want to count). We can do this with the function n(), which inside summarise() gives us the group size. So, we can count by adding a statement such as count = n() inside `summarise(). Try this out.\n\ntable_02 %&gt;%\n  group_by(____) %&gt;%\n  summarise(___, ___)\n\n\n\nMaking tables wider or longer\nFor efficient data processing, we usually want tables in long form, where each columns is one variable and each row is one observation. However, in some applications, for example when making a table easier to read for humans, a wide format can be preferred. In a wide format, some variables are displayed as column names, and other variables are distributed over multiple columns.\nFirst, make a summary table that shows median ph by arm and time_point, just like you did above, and save it to a variable ph_summary_long\n\nph_summary_long &lt;- table_02 %&gt;%\n  group_by(___) %&gt;%\n  summarise(___)\n\nNow, try using pivot_wider() to make a column for each arm. Remember, use ?pivot_wider if you want help, and try asking google or chatGPT if you get stuck.\n\nph_summary_long %&gt;%\n  pivot_wider(____)\n\nWhat if you wanted to instead make a column for each time point, and have the arms be different rows?\n\nph_summary_long %&gt;%\n  pivot_wider(____)\n\n\n\nCombining datasets with joins\nFinally, we sometimes encounter the situation where we have two data sets that contain different pieces of information about the same subjects or objects, and we need to merge these tables for further analysis. In this situation, we need to perform a join, and there are multiple different types of joins available: left_join(), right_join(), inner_join(), full_join(). These joins all differ in how they handle cases where an observation is present in only one of the two tables but missing in the other.\nOur instructional dataset has no missing values, so all types of joins are actually equivalent. Try to join table_01 and table_02 using left_join()\n\n```{r}\n# join table_01 and table_02\n```"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#section",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#section",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "",
    "text": "Workshop materials are at:\nhttps://elsherbini.github.io/durban-data-science-for-biology/"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#section-1",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#section-1",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "",
    "text": "Goals for this session\n\n\nLearn more advanced table commands\nLearn about plotting distributions with the tidyverse\n\n\n\n\ndata wrangling (n.) - the art of taking data in one format and filtering, reshaping, and deriving values to make the data format you need."
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#discussions-discord",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#discussions-discord",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Discussions: discord",
    "text": "Discussions: discord\nAsk questions at #workshop-questions on https://discord.gg/UDAsYTzZE."
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#stickies",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#stickies",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Stickies",
    "text": "Stickies\n\n\n\n\n\n\nDuring an activity, place a yellow sticky on your laptop if you’re good to go and a pink sticky if you want help.\n\n\n\n\nImage by Megan Duffy"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#practicalities",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#practicalities",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Practicalities",
    "text": "Practicalities\n\nWiFi:\nNetwork: KTB Free Wifi (no password needed)\nNetwork AHRI Password: @hR1W1F1!17\nNetwork CAPRISA-Corp Password: corp@caprisa17\nBathrooms are out the lobby to your left"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#elementary-data-manipulations",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#elementary-data-manipulations",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Elementary data manipulations",
    "text": "Elementary data manipulations\n\n\nYesterday:\n\nPick rows: filter()\nPick columns: select()\nSort rows: arrange()\nCount things: count()\nMake new columns: mutate()\n\n\nToday:\n\nAnalyze subsets:group_by() and summarize()\nReshape:pivot_wider(), pivot_longer()\nCombine datasets:left_join(), inner_join(), ..."
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#analyze-subsets-group_by-and-summarize",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#analyze-subsets-group_by-and-summarize",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Analyze subsets: group_by() and summarize()",
    "text": "Analyze subsets: group_by() and summarize()"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#example-application-of-grouping-counting",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#example-application-of-grouping-counting",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Example application of grouping: Counting",
    "text": "Example application of grouping: Counting\nPreviously, we counted like so:\n\n```{r}\ntable_01 %&gt;%\n  count(smoker)\n```\n\n# A tibble: 2 × 2\n  smoker         n\n  &lt;chr&gt;      &lt;int&gt;\n1 non-smoker    27\n2 smoker        17\n\n\n\nNow let’s do it the hard way"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#example-application-of-grouping-counting-1",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#example-application-of-grouping-counting-1",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Example application of grouping: Counting",
    "text": "Example application of grouping: Counting\nLet’s go back to the original table\n\n```{r}\ntable_01\n```\n\n# A tibble: 44 × 6\n   pid    arm       smoker       age education                     sex  \n   &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                         &lt;lgl&gt;\n 1 pid_01 placebo   non-smoker    26 grade 10-12, matriculated     FALSE\n 2 pid_02 placebo   smoker        33 grade 10-12, matriculated     FALSE\n 3 pid_03 placebo   smoker        30 post-secondary                FALSE\n 4 pid_04 placebo   non-smoker    34 grade 10-12, not matriculated FALSE\n 5 pid_05 treatment non-smoker    29 grade 10-12, matriculated     FALSE\n 6 pid_06 placebo   smoker        34 post-secondary                FALSE\n 7 pid_07 placebo   non-smoker    31 grade 10-12, not matriculated FALSE\n 8 pid_08 placebo   smoker        30 grade 10-12, not matriculated FALSE\n 9 pid_09 treatment non-smoker    35 grade 10-12, not matriculated FALSE\n10 pid_10 treatment non-smoker    32 less than grade 9             FALSE\n# ℹ 34 more rows"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#example-application-of-grouping-counting-2",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#example-application-of-grouping-counting-2",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Example application of grouping: Counting",
    "text": "Example application of grouping: Counting\nThen we group the data\n\n```{r}\ntable_01 %&gt;%\n  group_by(smoker)\n```\n\n# A tibble: 44 × 6\n# Groups:   smoker [2]\n   pid    arm       smoker       age education                     sex  \n   &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                         &lt;lgl&gt;\n 1 pid_01 placebo   non-smoker    26 grade 10-12, matriculated     FALSE\n 2 pid_02 placebo   smoker        33 grade 10-12, matriculated     FALSE\n 3 pid_03 placebo   smoker        30 post-secondary                FALSE\n 4 pid_04 placebo   non-smoker    34 grade 10-12, not matriculated FALSE\n 5 pid_05 treatment non-smoker    29 grade 10-12, matriculated     FALSE\n 6 pid_06 placebo   smoker        34 post-secondary                FALSE\n 7 pid_07 placebo   non-smoker    31 grade 10-12, not matriculated FALSE\n 8 pid_08 placebo   smoker        30 grade 10-12, not matriculated FALSE\n 9 pid_09 treatment non-smoker    35 grade 10-12, not matriculated FALSE\n10 pid_10 treatment non-smoker    32 less than grade 9             FALSE\n# ℹ 34 more rows"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#example-application-of-grouping-counting-3",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#example-application-of-grouping-counting-3",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Example application of grouping: Counting",
    "text": "Example application of grouping: Counting\nThen we group the data, and then summarise\n\n```{r}\ntable_01 %&gt;%\n  group_by(smoker) %&gt;%\n  summarise(\n    n = n() # n() returns the number of observations per group\n    )\n```\n\n# A tibble: 2 × 2\n  smoker         n\n  &lt;chr&gt;      &lt;int&gt;\n1 non-smoker    27\n2 smoker        17"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#example-application-of-grouping-counting-4",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#example-application-of-grouping-counting-4",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Example application of grouping: Counting",
    "text": "Example application of grouping: Counting\nNow let’s group by multiple variables\n\n```{r}\ntable_01 %&gt;%\n  group_by(smoker, arm)\n```\n\n# A tibble: 44 × 6\n# Groups:   smoker, arm [4]\n   pid    arm       smoker       age education                     sex  \n   &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                         &lt;lgl&gt;\n 1 pid_01 placebo   non-smoker    26 grade 10-12, matriculated     FALSE\n 2 pid_02 placebo   smoker        33 grade 10-12, matriculated     FALSE\n 3 pid_03 placebo   smoker        30 post-secondary                FALSE\n 4 pid_04 placebo   non-smoker    34 grade 10-12, not matriculated FALSE\n 5 pid_05 treatment non-smoker    29 grade 10-12, matriculated     FALSE\n 6 pid_06 placebo   smoker        34 post-secondary                FALSE\n 7 pid_07 placebo   non-smoker    31 grade 10-12, not matriculated FALSE\n 8 pid_08 placebo   smoker        30 grade 10-12, not matriculated FALSE\n 9 pid_09 treatment non-smoker    35 grade 10-12, not matriculated FALSE\n10 pid_10 treatment non-smoker    32 less than grade 9             FALSE\n# ℹ 34 more rows"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#example-application-of-grouping-counting-5",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#example-application-of-grouping-counting-5",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Example application of grouping: Counting",
    "text": "Example application of grouping: Counting\nNow let’s group by multiple variables, and summarise\n\n```{r}\ntable_01 %&gt;%\n  group_by(smoker, arm) %&gt;%\n    summarise(\n    n = n() # n() returns the number of observations per group\n    )\n```\n\n# A tibble: 4 × 3\n# Groups:   smoker [2]\n  smoker     arm           n\n  &lt;chr&gt;      &lt;chr&gt;     &lt;int&gt;\n1 non-smoker placebo      12\n2 non-smoker treatment    15\n3 smoker     placebo      11\n4 smoker     treatment     6"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#example-application-of-grouping-counting-6",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#example-application-of-grouping-counting-6",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Example application of grouping: Counting",
    "text": "Example application of grouping: Counting\ncount(...) is a short-cut for group_by(...) %&gt;% summarize(n = n())\n\n```{r}\ntable_01 %&gt;%\n  count(smoker, arm)\n```\n\n# A tibble: 4 × 3\n  smoker     arm           n\n  &lt;chr&gt;      &lt;chr&gt;     &lt;int&gt;\n1 non-smoker placebo      12\n2 non-smoker treatment    15\n3 smoker     placebo      11\n4 smoker     treatment     6"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#group_by-and-summariseis-the-general-method",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#group_by-and-summariseis-the-general-method",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "group_by() and summarise()is the general method",
    "text": "group_by() and summarise()is the general method\n\n```{r}\ntable_01 %&gt;%\n  group_by(smoker, arm) %&gt;%\n  summarise(median_age = median(age))\n```\n\n# A tibble: 4 × 3\n# Groups:   smoker [2]\n  smoker     arm       median_age\n  &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt;\n1 non-smoker placebo         31  \n2 non-smoker treatment       30  \n3 smoker     placebo         33  \n4 smoker     treatment       33.5"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#you-can-make-multiple-summarise-at-once",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#you-can-make-multiple-summarise-at-once",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "You can make multiple summarise at once",
    "text": "You can make multiple summarise at once\n\n```{r}\ntable_01 %&gt;%\n  group_by(smoker, arm) %&gt;%\n  summarise(\n    n = n(),\n    median_age = median(age)\n    )\n```\n\n# A tibble: 4 × 4\n# Groups:   smoker [2]\n  smoker     arm           n median_age\n  &lt;chr&gt;      &lt;chr&gt;     &lt;int&gt;      &lt;dbl&gt;\n1 non-smoker placebo      12       31  \n2 non-smoker treatment    15       30  \n3 smoker     placebo      11       33  \n4 smoker     treatment     6       33.5"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#lets-take-a-poll",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#lets-take-a-poll",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Let’s take a poll",
    "text": "Let’s take a poll\nGo to the event on wooclap\n\nWhat 4 columns do you expect in the output of this code?\n\ntable_01 %&gt;%\n  group_by(education_level, smoker) %&gt;%\n  summarise(n = n(), average_age = mean(age))"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#reshape-pivot_wider-and-pivot_longer",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#reshape-pivot_wider-and-pivot_longer",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Reshape: pivot_wider() and pivot_longer()",
    "text": "Reshape: pivot_wider() and pivot_longer()"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#reshaping-example-making-a-wide-summary-table",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#reshaping-example-making-a-wide-summary-table",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Reshaping example: Making a wide summary table",
    "text": "Reshaping example: Making a wide summary table\n\n```{r}\ntable_01 %&gt;%\n  count(education, arm)\n```\n\n# A tibble: 8 × 3\n  education                     arm           n\n  &lt;chr&gt;                         &lt;chr&gt;     &lt;int&gt;\n1 grade 10-12, matriculated     placebo       7\n2 grade 10-12, matriculated     treatment     9\n3 grade 10-12, not matriculated placebo      11\n4 grade 10-12, not matriculated treatment     7\n5 less than grade 9             placebo       2\n6 less than grade 9             treatment     4\n7 post-secondary                placebo       3\n8 post-secondary                treatment     1"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#reshaping-example-making-a-wide-summary-table-1",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#reshaping-example-making-a-wide-summary-table-1",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Reshaping example: Making a wide summary table",
    "text": "Reshaping example: Making a wide summary table\n\n```{r}\ntable_01 %&gt;%\n  count(education, arm) %&gt;%\n  pivot_wider(names_from = arm, values_from = n)\n```\n\n# A tibble: 4 × 3\n  education                     placebo treatment\n  &lt;chr&gt;                           &lt;int&gt;     &lt;int&gt;\n1 grade 10-12, matriculated           7         9\n2 grade 10-12, not matriculated      11         7\n3 less than grade 9                   2         4\n4 post-secondary                      3         1"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#reshaping-example-making-a-wide-summary-table-2",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#reshaping-example-making-a-wide-summary-table-2",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Reshaping example: Making a wide summary table",
    "text": "Reshaping example: Making a wide summary table\n\n```{r}\neducation_wide &lt;- table_01 %&gt;%\n  count(education, arm) %&gt;%\n  pivot_wider(names_from = arm, values_from = n)\n\neducation_wide %&gt;%\n  pivot_longer(-education, names_to = \"arm\", values_to = \"n\")\n```\n\n# A tibble: 8 × 3\n  education                     arm           n\n  &lt;chr&gt;                         &lt;chr&gt;     &lt;int&gt;\n1 grade 10-12, matriculated     placebo       7\n2 grade 10-12, matriculated     treatment     9\n3 grade 10-12, not matriculated placebo      11\n4 grade 10-12, not matriculated treatment     7\n5 less than grade 9             placebo       2\n6 less than grade 9             treatment     4\n7 post-secondary                placebo       3\n8 post-secondary                treatment     1"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#we-use-joins-to-add-columns-from-one-table-into-another",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#we-use-joins-to-add-columns-from-one-table-into-another",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "We use joins to add columns from one table into another",
    "text": "We use joins to add columns from one table into another"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#joins-turn-two-tables-into-one",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#joins-turn-two-tables-into-one",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Joins turn two tables into one",
    "text": "Joins turn two tables into one"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#there-are-different-types-of-joins",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#there-are-different-types-of-joins",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "There are different types of joins",
    "text": "There are different types of joins\nThe differences are all about how to handle when the two tables have different key values\n\n\n\nleft_join() - the resulting table always has the same key_values as the “left” table\nright_join() - the resulting table always has the same key_values as the “right” table\ninner_join() - the resulting table always only keeps the key_values that are in both tables\nfull_join() - the resulting table always has all key_values found in both tables"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#left-join",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#left-join",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Left Join",
    "text": "Left Join\nleft_join() - the resulting table always has the same key_values as the “left” table\n\n\ntable_a %&gt;% left_join(table_b)"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#right-join",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#right-join",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Right Join",
    "text": "Right Join\nright_join() - the resulting table always has the same key_values as the “right” table\n\n\ntable_a %&gt;% right_join(table_b)"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#inner_join",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#inner_join",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "inner_join",
    "text": "inner_join\ninner_join() - the resulting table always only keeps the key_values that are in both tables\n\n\ntable_a %&gt;% inner_join(table_b)"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#full-join",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#full-join",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Full join",
    "text": "Full join\nfull_join() - the resulting table always has all key_values found in both tables\n\n\ntable_a %&gt;% full_join(table_b)\n\n\nBut what are those NAs?"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#aside-na-is-how-r-denotes-missing-data",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#aside-na-is-how-r-denotes-missing-data",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Aside: NA is how R denotes missing data",
    "text": "Aside: NA is how R denotes missing data\n\nCheck out the naniar package for help seeing the missing data in your datasets\nhttps://naniar.njtierney.com/index.html"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#in-case-of-doubt-use-left_join",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#in-case-of-doubt-use-left_join",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "In case of doubt, use left_join()",
    "text": "In case of doubt, use left_join()"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#note-merging-tables-vertically-is-bind_rows-not-a-join",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#note-merging-tables-vertically-is-bind_rows-not-a-join",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Note, merging tables vertically is bind_rows(), not a join",
    "text": "Note, merging tables vertically is bind_rows(), not a join\n\n\ntable_a %&gt;% bind_rows(table_b)"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#by-default-joins-will-match-all-column-names-in-common",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#by-default-joins-will-match-all-column-names-in-common",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "by default, joins will match all column names in common",
    "text": "by default, joins will match all column names in common\n\n```{r}\n#| message: true\ntable_01 %&gt;% left_join(table_02)\n```\n\nJoining with `by = join_by(pid, arm)`\n\n\n# A tibble: 132 × 10\n   pid    arm     smoker   age education sex   time_point nugent_score crp_blood\n   &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;     &lt;lgl&gt; &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;\n 1 pid_01 placebo non-s…    26 grade 10… FALSE baseline              8      0.44\n 2 pid_01 placebo non-s…    26 grade 10… FALSE week_1                7      1.66\n 3 pid_01 placebo non-s…    26 grade 10… FALSE week_7                7      1.44\n 4 pid_02 placebo smoker    33 grade 10… FALSE baseline              7      1.55\n 5 pid_02 placebo smoker    33 grade 10… FALSE week_1                7      0.75\n 6 pid_02 placebo smoker    33 grade 10… FALSE week_7                4      1.17\n 7 pid_03 placebo smoker    30 post-sec… FALSE baseline              6      1.78\n 8 pid_03 placebo smoker    30 post-sec… FALSE week_1               10      0.57\n 9 pid_03 placebo smoker    30 post-sec… FALSE week_7                7      1.79\n10 pid_04 placebo non-s…    34 grade 10… FALSE baseline              5      1.76\n# ℹ 122 more rows\n# ℹ 1 more variable: ph &lt;dbl&gt;"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#exercise",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#exercise",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Exercise",
    "text": "Exercise\nThat’s enough slides for now time to try for yourself! Go to the module and go to the first exercise.\n\n\n\n−+\n30:00"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#histograms-and-density-plots",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#histograms-and-density-plots",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Histograms and density plots",
    "text": "Histograms and density plots\n\n\n\n\n\n\n\nage\nsex\nclass\nsurvived\n\n\n\n\n0.17\nfemale\n3rd\nsurvived\n\n\n0.33\nmale\n3rd\ndied\n\n\n0.80\nmale\n2nd\nsurvived\n\n\n0.83\nmale\n2nd\nsurvived\n\n\n0.83\nmale\n3rd\nsurvived\n\n\n0.92\nmale\n1st\nsurvived\n\n\n1.00\nfemale\n2nd\nsurvived\n\n\n1.00\nfemale\n3rd\nsurvived\n\n\n1.00\nmale\n2nd\nsurvived\n\n\n1.00\nmale\n2nd\nsurvived\n\n\n1.00\nmale\n3rd\nsurvived\n\n\n1.50\nfemale\n3rd\ndied\n\n\n\n\n\n\n\n\n\n\n\nage\nsex\nclass\nsurvived\n\n\n\n\n1.5\nfemale\n3rd\ndied\n\n\n2.0\nfemale\n1st\ndied\n\n\n2.0\nfemale\n2nd\nsurvived\n\n\n2.0\nfemale\n3rd\ndied\n\n\n2.0\nfemale\n3rd\ndied\n\n\n2.0\nmale\n2nd\nsurvived\n\n\n2.0\nmale\n2nd\nsurvived\n\n\n2.0\nmale\n2nd\nsurvived\n\n\n3.0\nfemale\n2nd\nsurvived\n\n\n3.0\nfemale\n3rd\nsurvived\n\n\n3.0\nmale\n2nd\nsurvived\n\n\n3.0\nmale\n2nd\nsurvived\n\n\n\n\n\n\n\n\n\n\n\nage\nsex\nclass\nsurvived\n\n\n\n\n3\nmale\n3rd\nsurvived\n\n\n3\nmale\n3rd\nsurvived\n\n\n4\nfemale\n2nd\nsurvived\n\n\n4\nfemale\n2nd\nsurvived\n\n\n4\nfemale\n3rd\nsurvived\n\n\n4\nfemale\n3rd\nsurvived\n\n\n4\nmale\n1st\nsurvived\n\n\n4\nmale\n3rd\ndied\n\n\n4\nmale\n3rd\nsurvived\n\n\n5\nfemale\n3rd\nsurvived\n\n\n5\nfemale\n3rd\nsurvived\n\n\n5\nmale\n3rd\ndied"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#define-bins-and-count-classes",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#define-bins-and-count-classes",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Define bins and count classes",
    "text": "Define bins and count classes\n\n\n\n\n\n\n\nage range\ncount\n\n\n\n\n0–5\n36\n\n\n6–10\n19\n\n\n11–15\n18\n\n\n16–20\n99\n\n\n21–25\n139\n\n\n26–30\n121\n\n\n31–35\n76\n\n\n36–40\n74\n\n\n\n\n\n\n\n\n\n\n\n\n\nage range\ncount\n\n\n\n\n41–45\n54\n\n\n46–50\n50\n\n\n51–55\n26\n\n\n56–60\n22\n\n\n61–65\n16\n\n\n66–70\n3\n\n\n71–75\n3\n\n\n76–80\n0"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#define-bins-and-count-classes-1",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#define-bins-and-count-classes-1",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Define bins and count classes",
    "text": "Define bins and count classes\n\n\n\n\n\n\n\nage range\ncount\n\n\n\n\n0–5\n36\n\n\n6–10\n19\n\n\n11–15\n18\n\n\n16–20\n99\n\n\n21–25\n139\n\n\n26–30\n121\n\n\n31–35\n76\n\n\n36–40\n74\n\n\n\n\n\n\n\n\n\n\n\n\n\nage range\ncount\n\n\n\n\n41–45\n54\n\n\n46–50\n50\n\n\n51–55\n26\n\n\n56–60\n22\n\n\n61–65\n16\n\n\n66–70\n3\n\n\n71–75\n3\n\n\n76–80\n0"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#histograms-depend-on-the-chosen-bin-width",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#histograms-depend-on-the-chosen-bin-width",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Histograms depend on the chosen bin width",
    "text": "Histograms depend on the chosen bin width"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#alternative-to-histogram-kernel-density-estimate-kde",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#alternative-to-histogram-kernel-density-estimate-kde",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Alternative to histogram: Kernel density estimate (KDE)",
    "text": "Alternative to histogram: Kernel density estimate (KDE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHistograms show raw counts, KDEs show proportions. (Total area = 1)"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#kdes-also-depend-on-parameter-settings",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#kdes-also-depend-on-parameter-settings",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "KDEs also depend on parameter settings",
    "text": "KDEs also depend on parameter settings"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#careful-kdes-can-show-non-sensical-data",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#careful-kdes-can-show-non-sensical-data",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Careful: KDEs can show non-sensical data",
    "text": "Careful: KDEs can show non-sensical data"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#careful-are-bars-stacked-or-overlapping",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#careful-are-bars-stacked-or-overlapping",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Careful, are bars stacked or overlapping?",
    "text": "Careful, are bars stacked or overlapping?"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#alternatively-age-pyramid",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#alternatively-age-pyramid",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Alternatively: Age pyramid",
    "text": "Alternatively: Age pyramid"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#alternatively-kdes-showing-proportions-of-total",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#alternatively-kdes-showing-proportions-of-total",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Alternatively: KDEs showing proportions of total",
    "text": "Alternatively: KDEs showing proportions of total"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#making-histograms-with-ggplot-geom_histogram",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#making-histograms-with-ggplot-geom_histogram",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Making histograms with ggplot: geom_histogram()",
    "text": "Making histograms with ggplot: geom_histogram()\n\n```{r}\nggplot(titanic, aes(age)) +\n  geom_histogram()\n```"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#setting-the-bin-width",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#setting-the-bin-width",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Setting the bin width",
    "text": "Setting the bin width\n\n```{r}\nggplot(titanic, aes(age)) +\n  geom_histogram(binwidth = 5)\n```\n\n\n\nDo you like where there bins are? What does the first bin say?"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#always-set-the-center-as-well-to-half-the-bin_width",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#always-set-the-center-as-well-to-half-the-bin_width",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Always set the center as well, to half the bin_width",
    "text": "Always set the center as well, to half the bin_width\n\n```{r}\nggplot(titanic, aes(age)) +\n  geom_histogram(binwidth = 5, center=2.5)\n```\n\n\n\nSetting center 2.5 makes the bars start 0-5, 5-10, etc. instead of 2.5-7.5, etc. You could instead use the argument boundary=5 to accomplish the same behavior."
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#making-density-plots-with-ggplot-geom_density-auto-animatetrue",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#making-density-plots-with-ggplot-geom_density-auto-animatetrue",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Making density plots with ggplot: geom_density() {auto-animate:true}",
    "text": "Making density plots with ggplot: geom_density() {auto-animate:true}\n\n```{r}\nggplot(titanic, aes(age)) +\n  geom_density(fill = \"skyblue\")\n```"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#making-density-plots-with-ggplot-geom_density-auto-animatetrue-1",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#making-density-plots-with-ggplot-geom_density-auto-animatetrue-1",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Making density plots with ggplot: geom_density() {auto-animate:true}",
    "text": "Making density plots with ggplot: geom_density() {auto-animate:true}\n\n```{r}\nggplot(titanic, aes(age)) +\n  geom_density()\n```\n\n\nwithout fill"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#modifying-bandwidth-bw-and-kernel-parameters-auto-animatetrue",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#modifying-bandwidth-bw-and-kernel-parameters-auto-animatetrue",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Modifying bandwidth (bw) and kernel parameters {auto-animate:true}",
    "text": "Modifying bandwidth (bw) and kernel parameters {auto-animate:true}\n\n```{r}\nggplot(titanic, aes(age)) +\n  geom_density(\n    fill = \"skyblue\",\n    bw = 0.5,               # a small bandwidth\n    kernel = \"gaussian\"     # Gaussian kernel (the default)\n  )\n```"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#modifying-bandwidth-bw-and-kernel-parameters-auto-animatetrue-1",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#modifying-bandwidth-bw-and-kernel-parameters-auto-animatetrue-1",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Modifying bandwidth (bw) and kernel parameters {auto-animate:true}",
    "text": "Modifying bandwidth (bw) and kernel parameters {auto-animate:true}\n\n```{r}\nggplot(titanic, aes(age)) +\n  geom_density(\n    fill = \"skyblue\",\n    bw = 2,                 # a moderate bandwidth\n    kernel = \"rectangular\"  # rectangular kernel\n  )\n```"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#density-estimates-visualize-distributions",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#density-estimates-visualize-distributions",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Density estimates visualize distributions",
    "text": "Density estimates visualize distributions\nMean temperatures in Lincoln, NE, in January 2016:\n\n\n\n\n\n\n\ndate\nmean temp\n\n\n\n\n2016-01-01\n-4\n\n\n2016-01-02\n-5\n\n\n2016-01-03\n-5\n\n\n2016-01-04\n-8\n\n\n2016-01-05\n-2\n\n\n2016-01-06\n1\n\n\n2016-01-07\n-1\n\n\n2016-01-08\n-4\n\n\n2016-01-09\n-13\n\n\n2016-01-10\n-12\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can we compare distributions across months?"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#a-bad-idea-many-overlapping-density-plots",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#a-bad-idea-many-overlapping-density-plots",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "A bad idea: Many overlapping density plots",
    "text": "A bad idea: Many overlapping density plots"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#another-bad-idea-stacked-density-plots",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#another-bad-idea-stacked-density-plots",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Another bad idea: Stacked density plots",
    "text": "Another bad idea: Stacked density plots"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#somewhat-better-small-multiples",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#somewhat-better-small-multiples",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Somewhat better: Small multiples",
    "text": "Somewhat better: Small multiples"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#instead-show-values-along-y-conditions-along-x",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#instead-show-values-along-y-conditions-along-x",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Instead: Show values along y, conditions along x",
    "text": "Instead: Show values along y, conditions along x\n\nA boxplot is a crude way of visualizing a distribution."
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#how-to-read-a-boxplot",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#how-to-read-a-boxplot",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "How to read a boxplot",
    "text": "How to read a boxplot"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#if-you-like-density-plots-consider-violins",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#if-you-like-density-plots-consider-violins",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "If you like density plots, consider violins",
    "text": "If you like density plots, consider violins\n\n\nA violin plot is a density plot rotated 90 degrees and then mirrored."
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#how-to-read-a-violin-plot",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#how-to-read-a-violin-plot",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "How to read a violin plot",
    "text": "How to read a violin plot"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#for-small-datasets-you-can-also-use-a-strip-chart",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#for-small-datasets-you-can-also-use-a-strip-chart",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "For small datasets, you can also use a strip chart",
    "text": "For small datasets, you can also use a strip chart\nAdvantage: Can see raw data points instead of abstract representation.\n\n\nHorizontal jittering may be necessary to avoid overlapping points."
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#another-option-is-a-scatter-density-plot",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#another-option-is-a-scatter-density-plot",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Another option is a scatter-density plot",
    "text": "Another option is a scatter-density plot\nAdvantage: Best of both worlds for violin and jitter plot, see the raw data but also see the shape of the density"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#advice---always-show-the-finest-granularity-of-data-that-is-practical.",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#advice---always-show-the-finest-granularity-of-data-that-is-practical.",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Advice - always show the finest granularity of data that is practical.",
    "text": "Advice - always show the finest granularity of data that is practical.\nIf you don’t have too many points, show them! It makes it much easier to interpret the data. Especially when you are exploring new datasets.\nFavor showing distributions over just a mean with error bars."
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#making-boxplots-violins-etc.-in-ggplot2-1",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#making-boxplots-violins-etc.-in-ggplot2-1",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Making boxplots, violins, etc. in ggplot2",
    "text": "Making boxplots, violins, etc. in ggplot2\n\n\n\n\n\n\n\n\nPlot type\nGeom\nNotes\n\n\n\n\nboxplot\ngeom_boxplot()\n\n\n\nviolin plot\ngeom_violin()\n\n\n\nstrip chart\ngeom_point()\nJittering requires position_jitter()\n\n\nsina plot\ngeom_sina()\nFrom package ggforce\n\n\nscatter-density plot\ngeom_quasirandom()\nFrom package ggbeeswarm\n\n\nridgeline\ngeom_density_ridges()\nFrom package ggridges"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#examples-boxplot-auto-animate-true",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#examples-boxplot-auto-animate-true",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Examples: Boxplot {auto-animate: true}",
    "text": "Examples: Boxplot {auto-animate: true}\n\n```{r}\nggplot(lincoln_temps, aes(x = month, y = mean_temp)) +\n  geom_boxplot(fill = \"skyblue\") \n```"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#examples-violins-auto-animate-true",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#examples-violins-auto-animate-true",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Examples: Violins {auto-animate: true}",
    "text": "Examples: Violins {auto-animate: true}\n\n```{r}\nggplot(lincoln_temps, aes(x = month, y = mean_temp)) +\n  geom_violin(fill = \"skyblue\") \n```"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#examples-strip-chart-no-jitter-auto-animate-true",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#examples-strip-chart-no-jitter-auto-animate-true",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Examples: Strip chart (no jitter) {auto-animate: true}",
    "text": "Examples: Strip chart (no jitter) {auto-animate: true}\n\n```{r}\nggplot(lincoln_temps, aes(x = month, y = mean_temp)) +\n  geom_point(color = \"skyblue\") \n```"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#examples-strip-chart-w-jitter-auto-animate-true",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#examples-strip-chart-w-jitter-auto-animate-true",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Examples: Strip chart (w/ jitter) {auto-animate: true}",
    "text": "Examples: Strip chart (w/ jitter) {auto-animate: true}\n\n```{r}\nggplot(lincoln_temps, aes(x = month, y = mean_temp)) +\n  geom_jitter(color = \"skyblue\") \n```"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#examples-scatter-density-plot-auto-animate-true",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#examples-scatter-density-plot-auto-animate-true",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Examples: Scatter density plot {auto-animate: true}",
    "text": "Examples: Scatter density plot {auto-animate: true}\n\n```{r}\nggplot(lincoln_temps, aes(x = month, y = mean_temp)) +\n  geom_quasirandom(color = \"skyblue\") \n```"
  },
  {
    "objectID": "materials/1-workshop1/4-tidyverse-201/slides.html#exercise-1",
    "href": "materials/1-workshop1/4-tidyverse-201/slides.html#exercise-1",
    "title": "More data wrangling and data visualization with the tidyverse",
    "section": "Exercise",
    "text": "Exercise\nTry exploring different continuous variables in table 01, table 02, and table_03 using these density visualization strategies.\n\n\nback to module"
  },
  {
    "objectID": "materials/1-workshop1/5-tableone/index.html",
    "href": "materials/1-workshop1/5-tableone/index.html",
    "title": "tableone and its Basic Statistics",
    "section": "",
    "text": "Make slides full screen"
  },
  {
    "objectID": "materials/1-workshop1/5-tableone/index.html#slides",
    "href": "materials/1-workshop1/5-tableone/index.html#slides",
    "title": "tableone and its Basic Statistics",
    "section": "",
    "text": "Make slides full screen"
  },
  {
    "objectID": "materials/1-workshop1/5-tableone/index.html#research-questions",
    "href": "materials/1-workshop1/5-tableone/index.html#research-questions",
    "title": "tableone and its Basic Statistics",
    "section": "Research Questions",
    "text": "Research Questions"
  },
  {
    "objectID": "materials/1-workshop1/5-tableone/index.html#potential-outcomes-could-include",
    "href": "materials/1-workshop1/5-tableone/index.html#potential-outcomes-could-include",
    "title": "tableone and its Basic Statistics",
    "section": "Potential outcomes could include",
    "text": "Potential outcomes could include\nChanges in inflammation levels, as measured by the elisa_cytokines and flow_cytometry tables. Changes in clinical measurements such as Nugent Score, C-reactive protein blood test (CRP), and vaginal pH, as recorded in the visit_clinical_measurements table."
  },
  {
    "objectID": "materials/1-workshop1/5-tableone/index.html#potential-research-question-objective-and-statistical-approach",
    "href": "materials/1-workshop1/5-tableone/index.html#potential-research-question-objective-and-statistical-approach",
    "title": "tableone and its Basic Statistics",
    "section": "Potential Research Question, Objective and Statistical Approach",
    "text": "Potential Research Question, Objective and Statistical Approach\nEfficacy of the Treatment\n\nQuestion: How effective is the drug in reducing inflammation at different time points (week 1 and week 7) compared to the baseline? Is there a significant difference between the treatment and placebo groups?\nObjective: Determine the effectiveness of the drug in reducing inflammation.\nStatistical Analysis: Use a repeated measures ANOVA or mixed-effects model to compare inflammation levels at different time points between the treatment and placebo groups.\n\nImpact of Smoking\n\nQuestion: Does smoking status affect the efficacy of the drug? Is there a significant difference in outcomes between smokers and non-smokers?\nObjective: Investigate the influence of smoking on the efficacy of the drug.\nStatistical Analysis: Perform subgroup analysis or interaction analysis to compare outcomes between smokers and non-smokers.\n\nAge and Drug Efficacy\n\nQuestion: Does age influence the effectiveness of the drug? Are there differences in outcomes among different age groups?\nObjective: Explore the influence of age on the effectiveness of the drug.\nStatistical Analysis: Use regression analysis to examine the relationship between age and treatment outcomes.\n\nEducation Level and Treatment Outcome\n\nQuestion: Is there a correlation between the level of education and the treatment outcome? Do individuals with higher education levels have better outcomes?\nObjective: Investigate whether education level correlates with treatment outcomes.\nStatistical Analysis: Perform a chi-square test or Fisher’s exact test to examine the association between education level and treatment outcomes.\n\nCytokine Concentration Analysis\n\nQuestion: How do cytokine concentrations change over time in response to the treatment? Are certain cytokines more responsive to the treatment than others?\nObjective: Analyze changes in cytokine concentrations over time in response to treatment.\nStatistical Analysis: Use a repeated measures ANOVA or mixed-effects model to compare cytokine concentrations at different time points.\n\nCell Count Analysis\n\nQuestion: How do cell counts (from flow cytometry data) change over time in response to the treatment? Are certain cell types more affected by the treatment than others?\nObjective: Analyze changes in cell counts over time in response to treatment.\nStatistical Analysis: Use a repeated measures ANOVA or mixed-effects model to compare cell counts at different time points.\n\nCorrelation between Clinical Measurements and Outcomes\n\nQuestion: Is there a correlation between Nugent Score, C-reactive protein blood test (CRP), vaginal pH, and treatment outcomes?\nObjective: Examine correlations between clinical measurements (Nugent Score, CRP, vaginal pH) and treatment outcomes.\nStatistical Analysis: Use correlation analysis or multiple regression analysis to examine these relationships.\n\nLong-term Efficacy of the Drug\nQuestion: Does the drug’s efficacy persist over time (from week 1 to week 7), or does it diminish? Objective: Assess whether the drug’s efficacy persists over time. Statistical Analysis: Use a repeated measures ANOVA or mixed-effects model to compare treatment outcomes at week 1 and week 7."
  },
  {
    "objectID": "materials/1-workshop1/5-tableone/index.html#refresher",
    "href": "materials/1-workshop1/5-tableone/index.html#refresher",
    "title": "tableone and its Basic Statistics",
    "section": "Refresher",
    "text": "Refresher"
  },
  {
    "objectID": "materials/1-workshop1/5-tableone/index.html#notes",
    "href": "materials/1-workshop1/5-tableone/index.html#notes",
    "title": "tableone and its Basic Statistics",
    "section": "Notes",
    "text": "Notes"
  },
  {
    "objectID": "materials/1-workshop1/5-tableone/index.html#introduction",
    "href": "materials/1-workshop1/5-tableone/index.html#introduction",
    "title": "tableone and its Basic Statistics",
    "section": "Introduction",
    "text": "Introduction\nIn biomedical research, it is often necessary to compare the effects of different interventions or exposures on the health outcomes of interest. However, before making any causal inference, it is important to evaluate the baseline characteristics of the patients who participate in the study. Baseline characteristics are the demographic and clinical features of the participants at the start of a trial or a study, such as age, sex, disease severity, comorbidities, etc. They provide information about the population that is being studied and the context of the research question (Schulz, Altman, & Moher, 2010).\nEvaluating baseline characteristics of patients in different treatment groups is important for several reasons:\n\nIt allows readers to assess the external validity of the trial results, which is the extent to which the results can be generalised to other settings and populations. For example, if the trial participants are very different from the target population in terms of age, sex, or other factors that may affect the outcome, then the results may not be applicable to the target population (Altman, 1990).\nIt allows researchers to check the internal validity of the trial results, which is the extent to which the results are free from bias and confounding. Bias is a systematic error that leads to a deviation from the true effect of the intervention or exposure. Confounding is a situation where a third variable is associated with both the intervention or exposure and the outcome, and may distort the true effect of the intervention or exposure. For example, if the treatment groups are not balanced in terms of baseline characteristics that may influence the outcome, then there may be a bias or a confounding effect that needs to be adjusted for in the statistical analysis (Matthews, 2006).\nIt allows researchers to explore the heterogeneity of the treatment effect, which is the variation in the effect across different subgroups of participants. Heterogeneity can be due to biological, clinical, or methodological factors that may modify or interact with the intervention or exposure. For example, if the treatment effect differs by age, sex, or disease severity, then it may be useful to perform subgroup analyses to identify which subgroups benefit more or less from the intervention or exposure (Matthews, 2006).\n\nTo evaluate baseline characteristics, researchers need to use appropriate methods of summarisation, comparison, and adjustment, depending on the type and distribution of the variables. Summarisation involves describing the distribution and characteristics of the variables using descriptive statistics such as means, standard deviations, medians, interquartile ranges, counts, and percentages. Comparison involves testing whether there are significant differences or associations between the groups or variables using statistical tests such as t-tests, chi-squared tests, Fisher’s exact tests, and rank sum tests. Adjustment involves controlling for the potential confounding factors using methods such as stratification, matching, covariate adjustment, or weighting (Altman, 1990)."
  },
  {
    "objectID": "materials/1-workshop1/5-tableone/index.html#types-of-variables",
    "href": "materials/1-workshop1/5-tableone/index.html#types-of-variables",
    "title": "tableone and its Basic Statistics",
    "section": "Types of variables",
    "text": "Types of variables\n\nContinuous\nContinuous variables are variables that can take any numeric value within a range, such as age, weight, height, blood pressure, etc. They are usually measured or calculated using a scale or a device.\n\n\nCategorical\nCategorical variables are variables that can take only a limited number of values, such as sex, race, diagnosis, treatment group, etc. They are usually assigned or observed based on some criteria or classification."
  },
  {
    "objectID": "materials/1-workshop1/5-tableone/index.html#descriptive-statistics",
    "href": "materials/1-workshop1/5-tableone/index.html#descriptive-statistics",
    "title": "tableone and its Basic Statistics",
    "section": "Descriptive statistics",
    "text": "Descriptive statistics\nDescriptive statistics are numerical summaries that describe the distribution and characteristics of a variable. They include measures of central tendency (such as mean, median, mode), measures of variability (such as standard deviation, interquartile range, range), and measures of frequency (such as count, percentage, proportion).\n\nMean\nThe mean is the sum of all the values in a data set divided by the number of values. The formula is:\n\\[\\bar{x} = \\frac{\\sum x}{n}\\]\nwhere \\(\\bar{x}\\) is the mean, \\(\\sum x\\) is the sum of all the values, and \\(n\\) is the number of values.\n\n\nMedian\nThe median is the middle value in an ordered data set. To find the median, arrange the values from smallest to largest and then locate the middle one. If there are an even number of values, the median is the average of the two middle ones. The formula is:\n\\[\\tilde{x} = \\begin{cases}\nx_{(n+1)/2}, & \\text{if } n \\text{ is odd} \\\\\n\\frac{x_{n/2} + x_{(n/2)+1}}{2}, & \\text{if } n \\text{ is even}\n\\end{cases}\\]\nwhere\n\n\\(\\tilde{x}\\) is the median,\n\\(x_i\\) is the \\(i\\)th value in the ordered data set, and\n\\(n\\) is the number of values.\n\n\n\nMode\nThe mode is the most frequent value in a data set. There can be more than one mode if there are multiple values with the same frequency. There is no formula for the mode, but it can be found by counting how many times each value or category occurs and then selecting the one(s) with the highest frequency.\n\n\nStandard deviation\nThe variance is a measure of how much the values vary from the mean while the standard deviation is a measure of how spread out the values are from the mean. It is calculated by taking the square root of the variance. The formula is:\n\\[s = \\sqrt{\\frac{\\sum (x - \\bar{x})^2}{n-1}}\\]\nwhere\n\n\\(s\\) is the standard deviation,\n\\(x\\) is a value in the data set,\n\\(\\bar{x}\\) is the mean, and\n\\(n\\) is the number of values.\n\n\n\nCount\nThe count is the number of times a value or a category occurs in a data set. There is no formula for the count, but it can be found by counting how many times each value or category appears in the data set.\n\n\nPercentage\nThe proportion is the ratio of a part to the whole expressed as a fraction between 0 and 1 whereas the percentage is the ratio of a part to the whole expressed as a fraction of 100. The formula is:\n\\[p = \\frac{n}{N} \\times 100\\]\nwhere\n\n\\(p\\) is the percentage,\n\\(n\\) is the count of a value or a category, and\n\\(N\\) is the total count of all values or categories.\n\nThese are some of the basic formulas for descriptive statistics. You can find more information and examples on this website."
  },
  {
    "objectID": "materials/1-workshop1/5-tableone/index.html#types-of-statistical-tests",
    "href": "materials/1-workshop1/5-tableone/index.html#types-of-statistical-tests",
    "title": "tableone and its Basic Statistics",
    "section": "Types of statistical tests",
    "text": "Types of statistical tests\nOne way to expand the sentence on baseline characteristics of patients in biomedical research papers is:\nStatistical tests are methods to evaluate whether there is a significant difference or association between two or more groups or variables. They are often used to compare the baseline characteristics of patients in different treatment groups, such as intervention and control groups, in biomedical research papers (Altman, 1990). They usually involve calculating a test statistic, which is a numerical value that summarizes the strength and direction of the relationship between the groups or variables. Then they compare the test statistic with a critical value or a p-value, which are thresholds that indicate the level of significance of the test. The level of significance is the probability of obtaining a test statistic as extreme or more extreme than the observed one, if the null hypothesis of no difference or no association is true. If the test statistic exceeds the critical value or is lower than the p-value, then the null hypothesis can be rejected and the alternative hypothesis of a difference or an association can be accepted. Otherwise, the null hypothesis cannot be rejected and the alternative hypothesis cannot be accepted.\nDepending on the type and distribution of the variables, different statistical tests can be performed. For continuous variables, such as age, weight, height, blood pressure, etc., t-tests (for normally distributed data) or rank sum tests (for non-normally distributed data) can be performed. T-tests compare the means of two groups and assume that the data are normally distributed and have equal variances. Rank sum tests compare the medians of two groups and do not assume any distribution or variance equality (Altman, 1990). For categorical variables, such as sex, race, diagnosis, treatment group, etc., chi-squared tests (for large sample sizes) or Fisher’s exact tests (for small sample sizes) can be performed. Chi-squared tests compare the frequencies or proportions of two or more groups and assume that the expected frequencies are sufficiently large. Fisher’s exact tests compare the frequencies or proportions of two groups and do not assume any frequency requirement (Altman, 1990).\nAnother aspect that can be considered when comparing baseline characteristics is the standardized mean difference (SMD), It is a unitless measure that can be used to compare the magnitude of group differences across different variables. It can also be used to combine results from different studies that measure the same outcome but use different scales (Schulz, Altman, & Moher, 2010)."
  },
  {
    "objectID": "materials/1-workshop1/5-tableone/index.html#tableone-package",
    "href": "materials/1-workshop1/5-tableone/index.html#tableone-package",
    "title": "tableone and its Basic Statistics",
    "section": "tableone package",
    "text": "tableone package\n\nIntroduction\nR package tableone is a package by Yoshida & Victorina (2021) that eases the construction of “Table 1: Baseline demographics and clinical characteristics”. The package can handle both continuous and categorical variables, and provide descriptive statistics such as means, standard deviations, medians, interquartile ranges, counts, and percentages. It can also perform statistical tests to compare groups, such as t-tests, chi-squared tests, Fisher’s exact tests, and rank sum tests. It can also calculate standardized mean differences to measure the effect size of group differences. tableone can handle weighted data using the survey package, which allows researchers to account for complex sampling designs and adjust for confounding factors. tableone has a simple and flexible syntax, and can produce nice-looking tables using the kableone function.\n\n\nHow tableone works\n\nTo use tableone, you need to install it from CRAN or GitHub (Yoshida & Victorina, 2021).\nYou need to load the package using library(tableone).\nYou need to specify the variables you want to summarize using the vars argument. You can also specify which variables are categorical using the factorVars argument.\nYou need to provide the data frame that contains the variables using the data argument. You can also provide a grouping variable using the strata argument.\nYou need to create a tableone object using the Createtableone`` function. This object contains all the summary statistics and test results for each variable and group.\nYou can print or export the tableone object using the print or kableone functions.\n\n\n\nOther packages for creating tables\nBesides tableone, there are many other R packages that can be used to create tables in various output formats, such as PDF, HTML and Word. Some of them are: flextable (Gohel & Skintzos, 2023) and huxtable (Hugh-Jones, 2022)."
  },
  {
    "objectID": "materials/1-workshop1/5-tableone/index.html#references",
    "href": "materials/1-workshop1/5-tableone/index.html#references",
    "title": "tableone and its Basic Statistics",
    "section": "References",
    "text": "References\nAltman, D. G. (1990). Practical statistics for medical research. Chapman & Hall/CRC.\nMatthews, J. N. (2006). Introduction to randomized controlled clinical trials. CRC Press.\nSchulz, K. F., Altman, D. G., & Moher, D.; CONSORT Group. (2010). CONSORT 2010 statement: updated guidelines for reporting parallel group randomised trials. BMJ, 340, c332.\nTherneau, T. M., & Grambsch, P. M. (2000). Modeling survival data: Extending the Cox model. Springer.\nYoshida, K., & Victorina, L. K. (2021). tableone: An R package for creating ‘Table 1’. R package version 0.12.0."
  },
  {
    "objectID": "materials/1-workshop1/5-tableone/slides.html#learning-outcomes",
    "href": "materials/1-workshop1/5-tableone/slides.html#learning-outcomes",
    "title": "tableone and its Basic Statistics",
    "section": "Learning outcomes",
    "text": "Learning outcomes\n\n\nRefresh on what baseline characteristics are and why they are important.\n\n\n\n\nKnow which descriptive statistics and statistical tests are used to evaluate baseline characteristic.\n\n\n\n\nKnow what is tableone package and how it works.\n\n\n\n\nKnow how to use tableone package with a real data set."
  },
  {
    "objectID": "materials/1-workshop1/5-tableone/slides.html#learning-outcomes-1",
    "href": "materials/1-workshop1/5-tableone/slides.html#learning-outcomes-1",
    "title": "tableone and its Basic Statistics",
    "section": "Learning outcomes",
    "text": "Learning outcomes\n\n\n\nVariablePlaceboTreatmentOverallPn232144Smoker = smoker (%)11 (47.8)6 (28.6)17 (38.6)0.317Age (years); median (IQR)31.0 (30.0, 33.0)31.0 (29.0, 34.0)31.0 (29.0, 33.2)0.897Education (%)0.437   grade 10-12, matriculated7 (30.4)9 (42.9)16 (36.4)   grade 10-12, not matriculated11 (47.8)7 (33.3)18 (40.9)   less than grade 92 (8.7)4 (19.0)6 (13.6)   post-secondary3 (13.0)1 (4.8)4 (9.1)Sex = Female (%)23 (100.0)21 (100.0)44 (100.0)-Nugent Score; median (IQR)7.0 (6.5, 8.0)6.0 (5.0, 6.0)6.5 (5.0, 8.0)0.001CRP Blood; median (IQR)1.2 (0.9, 2.4)1.2 (0.7, 1.8)1.2 (0.8, 2.0)0.724pH; median (IQR)5.2 (4.8, 5.3)4.6 (4.3, 4.9)4.9 (4.6, 5.3)0.002IFN-Y; median (IQR)0.3 (0.3, 0.8)0.3 (0.3, 0.3)0.3 (0.3, 0.5)0.159IL-10; median (IQR)0.8 (0.8, 2.0)0.8 (0.8, 1.8)0.8 (0.8, 1.9)0.820"
  },
  {
    "objectID": "materials/1-workshop1/5-tableone/slides.html#introduction",
    "href": "materials/1-workshop1/5-tableone/slides.html#introduction",
    "title": "tableone and its Basic Statistics",
    "section": "Introduction",
    "text": "Introduction\nWhat are baseline characteristics and why are they important?\n\n\nBaseline characteristics describe the participants at the start of a study, for example\n\n\n\nage, sex, disease severity, etc.*\n\n\n\nThey help readers assess the validity and applicability of the study results (Schulz, Altman, and Moher 2010; Altman 1985).\n\n\n\n\nThey allow researchers to explore the treatment effect across different subgroups (Matthews 2006).\n\n\n\n\nExplain what validity and applicability mean in the context of research.\nGive examples of subgroups and how they can influence the treatment effect."
  },
  {
    "objectID": "materials/1-workshop1/5-tableone/slides.html#methods",
    "href": "materials/1-workshop1/5-tableone/slides.html#methods",
    "title": "tableone and its Basic Statistics",
    "section": "Methods",
    "text": "Methods\nWhich descriptive statistics and statistical tests?\n\n\nDescriptive statistics summarize the distribution and characteristics of a variable, such as\n\n\n\nmeans (standard deviations), medians (interquartile range), count (percentage)\n\n\n\nStatistical tests evaluate whether there is a significant difference or association between groups or variables, such as\n\n\n\nt-tests, anova, rank sum tests, chi-squared tests\n\n\n\nStandardized mean difference (SMD) is a measure of the effect size that can compare different variables or combine results from different studies (Schulz, Altman, and Moher 2010).\n\n\n\n\nExplain what distribution and characteristics mean in the context of statistics.\nGive examples of when to use different statistical tests and how to interpret them.\nExplain what effect size means and why it is important."
  },
  {
    "objectID": "materials/1-workshop1/5-tableone/slides.html#r-package-tableone",
    "href": "materials/1-workshop1/5-tableone/slides.html#r-package-tableone",
    "title": "tableone and its Basic Statistics",
    "section": "R package tableone",
    "text": "R package tableone\nWhat is tableone package and how does it work?\n\n\ntableone is a package that simplifies the creation of “Table 1: Baseline demographics and clinical characteristics” (Yoshida and Bartel 2022).\n\n\n\n\nIt can handle both continuous and categorical variables, and provide descriptive statistics, statistical tests, and SMDs.\n\n\n\n\nIt can handle weighted data using the survey package, which allows researchers to account for complex sampling designs and adjust for confounding factors.\n\n\n\n\nIt has a simple and flexible syntax, and can produce nice-looking tables using the print or kableone function (together with flextable you get nice tables).\n\n\n\n\nExplain what Table 1 is and why it is important in research reports.\nExplain what continuous and categorical variables are and how to handle them differently.\nExplain what weighted data, complex sampling designs, and confounding factors are and how they affect the analysis.\nShow an example of the syntax and output of tableone."
  },
  {
    "objectID": "materials/1-workshop1/5-tableone/slides.html#load-tableone-package",
    "href": "materials/1-workshop1/5-tableone/slides.html#load-tableone-package",
    "title": "tableone and its Basic Statistics",
    "section": "Load tableone package",
    "text": "Load tableone package\ntableone Github Site\n\nlibrary(tableone) # Loading/Attaching and Listing of Packages\n\n\nCreateTableOne function\nsvyCreateTableOne function (not in the scope)\n\n\n?CreateTableOne"
  },
  {
    "objectID": "materials/1-workshop1/5-tableone/slides.html#createtableone-function",
    "href": "materials/1-workshop1/5-tableone/slides.html#createtableone-function",
    "title": "tableone and its Basic Statistics",
    "section": "CreateTableOne Function",
    "text": "CreateTableOne Function\n\nDataTesting…category vars…continuous varsTotal\n\n\n\n\ndata: A data frame in which these variables exist. All variables (both vars and strata) must be in this data frame.\nvars: Variables to be summarized given as a character vector. Factors are handled as categorical variables, whereas numeric variables are handled as continuous variables. If empty, all variables in the data frame specified in the data argument are used.\nstrata: Stratifying (grouping) variable name(s) given as a character vector. If omitted, the overall results are returned.\nfactorVars: Numerically coded variables that should be handled as categorical variables given as a character vector. Do not include factors, unless you need to relevel them by removing empty levels. If omitted, only factors are considered categorical variables. The variables specified here must also be specified in the vars argument.\nincludeNA = FALSE: If TRUE, NA is handled as a regular factor level rather than missing. NA is shown as the last factor level in the table. Only effective for categorical variables.\n\n\n\n\n\n\ntest = TRUE: If TRUE, as in the default and there are more than two groups, groupwise comparisons are performed.\n\n\n\n\n\n\ntestApprox = chisq.test: A function used to perform the large sample approximation based tests. The default is chisq.test. This is not recommended when some of the cell have small counts like fewer than 5.\nargsApprox = list(correct = TRUE): A named list of arguments passed to the function specified in testApprox. The default is list (correct = TRUE), which turns on the continuity correction for chisq.test.\ntestExact = fisher.test: A function used to perform the exact tests. The default is fisher.test. If the cells have large numbers, it will fail because of memory limitation. In this situation, the large sample approximation based should suffice.\n\n\n\n\n\n\ntestNormal = oneway.test: A function used to perform the normal assumption based tests. The default is oneway.test. This is equivalent of the t-test when there are only two groups.\nargsNormal = list(var.equal = TRUE): A named list of arguments passed to the function specified in testNormal.\ntestNonNormal = kruskal.test: A function used to perform non-normal assumption based tests.\nargsNonNormal = list(NULL): A named list of arguments passed to the function specified in testNonNormal.\nsmd = TRUE: If set to TRUE, standardized mean differences are calculated.\n\n\n\n\n\n\naddOverall = FALSE: If set to TRUE, an overall column is added to the table."
  },
  {
    "objectID": "materials/1-workshop1/5-tableone/slides.html#print-function-for-createtableone-object",
    "href": "materials/1-workshop1/5-tableone/slides.html#print-function-for-createtableone-object",
    "title": "tableone and its Basic Statistics",
    "section": "print function for CreateTableOne object",
    "text": "print function for CreateTableOne object\n\nObjectSimple lookDecimalsVariablesTest\n\n\n\n\nx: object that you want to print.\n\n\n\n\n\n\nprintToggle = TRUE: If set to TRUE, the function will print the table.\nquote = FALSE: If set to FALSE, the function will not quote character strings.\nvarLabels = FALSE: If set to TRUE, variable labels (if available) are used instead of variable names.\nexplain = TRUE: If set to TRUE, explanations for the statistics are printed.\nnoSpaces = FALSE: If set to TRUE, spaces are removed from variable names.\npadColnames = FALSE: If set to TRUE, column names are padded with spaces for alignment.\ndropEqual = FALSE: If set to TRUE, the equal sign is dropped from p-values.\nshowAllLevels = FALSE: If set to TRUE, all levels of factors are shown even if some levels have zero count.\n\n\n\n\n\n\ncatDigits = 1: The number of digits after the decimal point for categorical variables.\ncontDigits = 2: The number of digits after the decimal point for continuous variables.\npDigits = 3: The number of digits after the decimal point for p-values.\nformatOptions = list(scientific = FALSE): A list of options for formatting numbers.\n\n\n\n\n\n\nmissing = FALSE: If set to TRUE, missing values are included in the table.\nminMax = FALSE: If set to TRUE, minimum and maximum values are included in the table for continuous variables.\nformat = c(\"fp\", \"f\", \"p\", \"pf\")[1]: The format of the table. Options include “fp” (frequency and percentage), “f” (frequency only), “p” (percentage only), and “pf” (percentage and frequency).\nnonnormal = NULL: A character vector of non-normal variables. For these variables, median and IQR are reported instead of mean and SD.\ncramVars = NULL: A character vector of variables for which Cramér’s V is calculated.\n\n\n\n\n\n\ntest = TRUE: If set to TRUE, tests are performed for differences across strata.\nexact = NULL: A character vector of variables for which exact tests are performed instead of chi-squared tests.\nsmd = FALSE: If set to TRUE, standardized mean differences are calculated."
  },
  {
    "objectID": "materials/1-workshop1/5-tableone/slides.html#references",
    "href": "materials/1-workshop1/5-tableone/slides.html#references",
    "title": "tableone and its Basic Statistics",
    "section": "References",
    "text": "References\n\n\nback to module\n\n\n\nAltman, Douglas G. 1985. “Comparability of Randomised Groups.” The Statistician 34 (1): 125. https://doi.org/10.2307/2987510.\n\n\nMatthews, John N. S. 2006. Introduction to Randomized Controlled Clinical Trials. Chapman; Hall/CRC. https://doi.org/10.1201/9781420011302.\n\n\nSchulz, K. F, D. G Altman, and D. Moher. 2010. “CONSORT 2010 Statement: Updated Guidelines for Reporting Parallel Group Randomised Trials.” BMJ 340 (mar23 1): c332–32. https://doi.org/10.1136/bmj.c332.\n\n\nYoshida, Kazuki, and Alexander Bartel. 2022. “Tableone: Create ’Table 1’ to Describe Baseline Characteristics with or Without Propensity Score Weights.” https://CRAN.R-project.org/package=tableone."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/index.html",
    "href": "materials/1-workshop1/6-hypothesis-testing/index.html",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "",
    "text": "Make slides full screen\n\n\n\n\nlibrary(tidyverse) # loads the packages from the tidyverse suite\nlibrary(pander) # allows to display pretty tables \nlibrary(patchwork) # allows to combine ggplot (see Module 7)\ntheme_set(theme_light())\nset.seed(123) # set the \"random seed\" for reproducibility"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/index.html#slides",
    "href": "materials/1-workshop1/6-hypothesis-testing/index.html#slides",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "",
    "text": "Make slides full screen\n\n\n\n\nlibrary(tidyverse) # loads the packages from the tidyverse suite\nlibrary(pander) # allows to display pretty tables \nlibrary(patchwork) # allows to combine ggplot (see Module 7)\ntheme_set(theme_light())\nset.seed(123) # set the \"random seed\" for reproducibility"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/index.html#hypothesis-testing",
    "href": "materials/1-workshop1/6-hypothesis-testing/index.html#hypothesis-testing",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Hypothesis testing",
    "text": "Hypothesis testing\nBefore testing hypotheses on real data, let’s develop our intuition on data we simulate ourselves.\nFor this first example, let’s simulate 3 datasets by sampling 50 values from 2 normal populations with different means but same variance (So two datasets are drawn from population 1 and one is drawn from population 2). Let’s use \\(\\mu_1 = 0\\), \\(\\mu_2 = 2\\), and \\(\\sigma^2 = 4\\).\n\n\n\n\n\n\nTo simulate normally distributed data, check the rnorm function by typing ?rnorm in the console.\nWe put the results of our simulations in a variable X that will be a “long” tibble with the following two columns: dataset, value.\n\n\n\n\nn_samples &lt;- 50\ncommon_sd &lt;- 2 # square root of 4 (we said)\n\nsample_1 &lt;- rnorm(n_samples, mean = 0, sd = common_sd) \nsample_2 &lt;- rnorm(n_samples, mean = 0, sd = common_sd) \nsample_3 &lt;- rnorm(n_samples, mean = 2, sd = common_sd)\n\nX &lt;- \n  bind_rows(\n    tibble(dataset = 1, value = sample_1),\n    tibble(dataset = 2, value = sample_2),\n    tibble(dataset = 3, value = sample_3)\n  ) |&gt; \n  mutate(dataset = dataset |&gt; factor())\n\nIf we display the top 6 raws, we have:\n\n# the head function takes the top x rows of a table\n# by default, the first 6 rows\n# pander just prints the result in a pretty way\nX |&gt; head() |&gt; pander()\n\n\n\n\n\n\n\n\ndataset\nvalue\n\n\n\n\n1\n-1.121\n\n\n1\n-0.4604\n\n\n1\n3.117\n\n\n1\n0.141\n\n\n1\n0.2586\n\n\n1\n3.43\n\n\n\n\n\nand the bottom 6 raws are:\n\n# tail prints the last 6 rows\nX |&gt; tail() |&gt; pander()\n\n\n\n\n\n\n\n\ndataset\nvalue\n\n\n\n\n3\n-1.203\n\n\n3\n0.9382\n\n\n3\n-0.9235\n\n\n3\n3.376\n\n\n3\n6.2\n\n\n3\n-0.5741\n\n\n\n\n\nTo validate that we’ve simulated our data properly, let’s compute the mean and variance of our data and display a histogram for each dataset.\n\nX %&gt;% \n  group_by(dataset) %&gt;% \n  summarize(mean = mean(value), var = var(value)) |&gt; \n  pander()\n\n\n\n\n\n\n\n\n\ndataset\nmean\nvar\n\n\n\n\n1\n0.06881\n3.429\n\n\n2\n0.2928\n3.279\n\n\n3\n1.492\n3.915\n\n\n\n\n\nDo these values make sense?\nWe can display the distributions we just simulated using ggplot and geom_histogram.\n\nggplot(X, aes(x = value, fill = dataset)) +\n  geom_histogram(bins = 50) +\n  facet_grid(dataset ~ ., labeller = label_both) +\n  guides(fill = \"none\") + # we don't really need a fill legend \n  theme(strip.text.y = element_text(angle = 0, hjust = 0)) # sometimes it is nicer to rotate the panel labels so they are horizontal and more easily readable\n\n\n\n\nVisually, it looks like the means of datasets 1 and 2 are similar, but the mean of dataset 3 is larger (expected based on how we simulated the data). However, because there is large variability in the data and a lot of overlap between the values of these datasets, we want to make sure that what we think we observe is not due to chance.\nThis what statistical tests help us do. Feel free to review the workshop slides if you need a reminder of what statistical tests are.\nHere, we want to do a test on the means of the datasets and test if the means of datasets 2 or 3 are different from the mean of dataset 1.\n\n\\(t\\)-tests\nBecause we have more than 40 samples in each dataset, we can use a \\(t\\)-test.\nIn R, \\(t\\)-tests can be done with the t.test function. Note that there are several ways to use the t.test function and several options we need to be careful about. To read more about these options, type ?t.test in your console.\nSpecifically, we need to be careful about specifying what our Null and alternative hypotheses are.\nThis is specified using the alternative option of the t.test function.\nThe option corresponding to\n\\[\\begin{align*}\nH_0:& \\ \\mu_1 = \\mu_2 \\\\\nH_a:& \\ \\mu_1 \\neq \\mu_2\n\\end{align*}\\]\nis alternative = \"two-sided\" which is the default option of t.test (that is, if we don’t specify the alternative, the function automatically assumes that we want to perform a “two-sided” test). It is \"two-sided\" because \\(\\mu_2\\) can be smaller OR larger in the alternative hypothesis.\nLet’s say that we do not have any a priori on the alternative and perform a two-sided test on the means of datasets 1 and 2.\n\n\nt.test(value ~ dataset, data = X |&gt; filter(dataset %in% 1:2))\n\n\n    Welch Two Sample t-test\n\ndata:  value by dataset\nt = -0.61157, df = 97.951, p-value = 0.5422\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -0.9508970  0.5028781\nsample estimates:\nmean in group 1 mean in group 2 \n      0.0688071       0.2928165 \n\n# this is the same as :\n# t.test(x = X$value[X$dataset == 1], y = X$value[X$dataset == 2])\n\nWe see that the probability to observe the \\(t\\) value is quite large. So, we do NOT reject the null hypothesis that the two means are the same.\nNow, if we do this test comparing the means of datasets 1 and 3, what do we get? What do you conclude?\n\nt.test(value ~ dataset, data = X |&gt; filter(dataset %in% c(1,3)))\n\n\n    Welch Two Sample t-test\n\ndata:  value by dataset\nt = -3.714, df = 97.572, p-value = 0.0003399\nalternative hypothesis: true difference in means between group 1 and group 3 is not equal to 0\n95 percent confidence interval:\n -2.1839829 -0.6628012\nsample estimates:\nmean in group 1 mean in group 3 \n      0.0688071       1.4921991 \n\n\nAs explained above, the tests we have done so far are “two-sided”. That means that the null hypothesis is that the two means are the same, and the alternative is that they are different.\n\\[\nH_0: \\mu_1 = \\mu_2\n\\]\n\\[\nH_a: \\mu_1 \\neq \\mu_2\n\\]\nBut sometimes, we have an a priori that the alternative is that one of the two means is larger. This is where we need a “one-sided” test.\nWe do this in R with the alternative option of the t.test function.\nRemember: to obtain the documentation about the t.test function, you can type ?t.test in the console.\nHow do we need to change the alternative option to perform the test corresponding to this pair of hypotheses ?\n\\[\\begin{align*}\nH_0:&\\  \\mu_1 \\geq \\mu_3 \\\\\nH_a:&\\  \\mu_1 &lt; \\mu_3 ( \\iff \\mu_1 - \\mu_3 &lt; 0 )\n\\end{align*}\\]\n\nt.test(value ~ dataset, data = X |&gt; filter(dataset %in% c(1,3)),\n       alternative = \"less\")\n\n\n    Welch Two Sample t-test\n\ndata:  value by dataset\nt = -3.714, df = 97.572, p-value = 0.0001699\nalternative hypothesis: true difference in means between group 1 and group 3 is less than 0\n95 percent confidence interval:\n       -Inf -0.7869575\nsample estimates:\nmean in group 1 mean in group 3 \n      0.0688071       1.4921991 \n\n\nHow do the \\(t\\) and \\(p\\) values compare in the two-sided vs one-sided test?\nWhy?\n\nQQ-plots: checking compatibility with a (normal) distribution\nRemember that the \\(t\\)-test requires, for small sample sizes, for the data to be drawn from a normal distribution. Usually, with real data, we don’t always know what distribution the data are samples from.\nWe can always check that our data is compatible with a normal distribution by performing a QQ-plot:\n\nexample_data &lt;- \n  tibble(norm = rnorm(20), lnorm = rlnorm(20))\n# just like `rnorm` samples from a normal distribution, \n# `runif` samples from a uniform distribution\n\ng_norm &lt;- \n  ggplot(example_data, aes(sample = norm)) +\n  geom_qq() +\n  geom_qq_line() +\n  ggtitle(\"Sampled from a\\nnormal distribution\")\n\n\ng_lnorm &lt;- \n  ggplot(example_data, aes(sample = lnorm)) +\n  geom_qq() +\n  geom_qq_line() +\n  ggtitle(\"Sampled from a\\n*log*normal distribution\")\n\ng_norm + g_lnorm\n\n\n\n\nWe see that, on the left plot, the dots are close to the line, and on the right plot, some dots are very far from the line. These dots far from the line are a warning that the distribution is probably not normal.\n\n\n\nImpact of sample size on p-values\n\nSmall dataset\nLet’s re-do our analysis but decrease the sample size to 10 samples per dataset.\n\n# another way to simulate data is to do the following\n# check what the expand_grid and rowwise function do\nX_small_sample &lt;- \n  expand_grid(\n    dataset = (1:3) |&gt; factor(), \n    sample = 1:10\n  ) %&gt;% \n  mutate(\n    pop_true_mean = ifelse(dataset == 3, 2, 0),\n    pop_true_var = 2\n  ) %&gt;% \n  rowwise() %&gt;% \n  mutate(\n    value = \n      rnorm(1, mean = pop_true_mean, sd = sqrt(pop_true_var))\n  ) %&gt;% \n  ungroup()\n\nX_small_sample |&gt; head() |&gt; pander()\n\n\n\n\n\n\n\n\n\n\n\ndataset\nsample\npop_true_mean\npop_true_var\nvalue\n\n\n\n\n1\n1\n0\n2\n0.3033\n\n\n1\n2\n0\n2\n-0.4592\n\n\n1\n3\n0\n2\n0.1338\n\n\n1\n4\n0\n2\n-1.266\n\n\n1\n5\n0\n2\n-1.854\n\n\n1\n6\n0\n2\n2.824\n\n\n\n\n\n\n\nCode\nggplot(X_small_sample, aes(x = value, fill = dataset)) +\n  geom_histogram(bins = 50) +\n  facet_grid(dataset ~ ., labeller = label_both) +\n  guides(fill = \"none\") + \n  theme(strip.text.y = element_text(angle = 0, hjust = 0)) \n\n\n\n\n\nWe can still use a \\(t\\)-test because we know that our samples are drawn from a Normal distribution.\n\nt.test(value ~ dataset, \n       data = X_small_sample |&gt; filter(dataset %in% c(1,3)))\n\n\n    Welch Two Sample t-test\n\ndata:  value by dataset\nt = -3.2548, df = 17.988, p-value = 0.004402\nalternative hypothesis: true difference in means between group 1 and group 3 is not equal to 0\n95 percent confidence interval:\n -3.4653702 -0.7465168\nsample estimates:\nmean in group 1 mean in group 3 \n      -0.377852        1.728091 \n\n\nWe see that the \\(p\\)-value is now much larger because, with the small datasets, we have a lot more uncertainty on the true means of the populations.\n\n\nLarge datasets\nLet’s now redo the same again but with a very large sample size for each dataset. For example N = 1000.\n\nX_large_sample &lt;- \n  expand_grid(\n    dataset = (1:3) |&gt; factor(), \n    sample = 1:1000\n    ) %&gt;% \n  mutate(\n    pop_true_mean = ifelse(dataset == 3, 2, 0),\n    pop_true_var = 2\n  ) %&gt;% \n  rowwise() %&gt;% \n  mutate(\n    value = \n      rnorm(1, mean = pop_true_mean, sd = sqrt(pop_true_var))\n  ) %&gt;% \n  ungroup()\n\nX_large_sample |&gt; head() |&gt; pander()\n\n\n\n\n\n\n\n\n\n\n\ndataset\nsample\npop_true_mean\npop_true_var\nvalue\n\n\n\n\n1\n1\n0\n2\n-0.8117\n\n\n1\n2\n0\n2\n0.874\n\n\n1\n3\n0\n2\n1.57\n\n\n1\n4\n0\n2\n1.001\n\n\n1\n5\n0\n2\n-0.5143\n\n\n1\n6\n0\n2\n0.0845\n\n\n\n\n\n\n\nCode\nggplot(X_large_sample, aes(x = value, fill = dataset)) +\n  geom_histogram(bins = 50) +\n  facet_grid(dataset ~ ., labeller = label_both) +\n  guides(fill = \"none\") + \n  theme(strip.text.y = element_text(angle = 0, hjust = 0)) \n\n\n\n\n\n\nt.test(value ~ dataset, \n       data = X_large_sample |&gt; filter(dataset %in% c(1,3)))\n\n\n    Welch Two Sample t-test\n\ndata:  value by dataset\nt = -30.732, df = 1997.9, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group 1 and group 3 is not equal to 0\n95 percent confidence interval:\n -2.075287 -1.826308\nsample estimates:\nmean in group 1 mean in group 3 \n     0.03031352      1.98111096 \n\n\nThe \\(p\\)-value is as small as it can be.\nLet’s also re-do the test comparing datasets 1 and 2\n\nt.test(value ~ dataset, \n       data = X_large_sample |&gt; filter(dataset %in% c(1,2)))\n\n\n    Welch Two Sample t-test\n\ndata:  value by dataset\nt = 0.075717, df = 1996.9, p-value = 0.9397\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -0.1186693  0.1282006\nsample estimates:\nmean in group 1 mean in group 2 \n     0.03031352      0.02554787 \n\n\nWe still don’t reject the null hypothesis, which is what we expect.\n\n\nClinical vs Statistical significance\nHowever, sometimes, we need to be careful with large sample sizes because tiny effects can still lead to very small p-values. However, these tiny effects don’t have much but these do not have much clinical relevance.\nLet’s verify that with a difference in means of 0.2\n\nt.test(\n  x = rnorm(1000, mean = 0.0, sd = 2),\n  y = rnorm(1000, mean = 0.2, sd = 2)\n)\n\n\n    Welch Two Sample t-test\n\ndata:  rnorm(1000, mean = 0, sd = 2) and rnorm(1000, mean = 0.2, sd = 2)\nt = -2.18, df = 1998, p-value = 0.02937\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.36547886 -0.01931448\nsample estimates:\n  mean of x   mean of y \n-0.02210611  0.17029056 \n\n\nThe \\(p\\)-value is lower than 1/20, but the effect (i.e., the mean in differences), compared to the standard deviations is very small.\nThis is what we are talking about when discussing the “clinical” vs “statistical” significance."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/index.html#data-transformation",
    "href": "materials/1-workshop1/6-hypothesis-testing/index.html#data-transformation",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Data transformation",
    "text": "Data transformation\nNow, let’s play with the datasets provided on the workshop website. Specifically, we are interested in analyzing the cytokines data.\n\nCytokine data exploration\nOur first task will be to display the distribution of the “IL-1\\(\\beta\\)” cytokine.\nTo do so, we load the cytokine data and filter for the cytokine of interest.\n\n# notice where I had stored my files.\n# Make sure to modify the path to your files\n\nelisa &lt;- \n  read_csv(\n    file = \"data/03_elisa_cytokines_UKZN_workshop_2023.csv\",\n    show_col_types = FALSE\n  )\n\nIL1b &lt;- elisa |&gt; filter(cytokine == \"IL-1b\") \n\nWe display its distribution with the geom_histogram function, and we can use the color (fill) option to flag whether the concentration value was within or out of the limits of detection.\n\ncytokine_lim_cols &lt;-\n  c(\"within limits\" = \"navy\", \"out of range\" = \"indianred1\")\n\nggplot(IL1b, aes(x = conc, fill = limits)) +\n  geom_histogram(bins = 30) +\n  ggtitle(\"IL-1b concentrations\") +\n  scale_fill_manual(values = cytokine_lim_cols)\n\n\n\n\nWhat do we observe?\nDo we think that the distribution of IL-1\\(\\beta\\) concentations follow a normal distribution?\nLet’s still check with a QQ-plot:\n\nggplot(\n  IL1b, \n  aes(sample = conc)\n) +\n  geom_qq_line() +\n  geom_qq(size = 0.75, alpha = 0.5)\n\n\n\n\nLook back at the QQ-plots we did earlier on simulated data. Does this QQ-plot look like one of the simulated one?\n\n\nLog-transformation\nLet’s now repeat the last two displays, using the log of the concentration instead of the concentration itself. Remember, we can use the mutate function to add a new variable to our data.frame.\n\nIL1b &lt;- IL1b |&gt; mutate(logconc = log10(conc))\n\n\nggplot(IL1b, aes(x = logconc, fill = limits)) +\n  geom_histogram(bins = 30) +\n  ggtitle(\"IL-1b concentrations (log 10)\") +\n  xlab(\"log10(conc)\") +\n  scale_fill_manual(values = cytokine_lim_cols)\n\n\n\n\nNow, the “within-range” data is more compatible with a Normal distribution.\nLet’s check with a QQ-plot:\n\nggplot(\n  IL1b, \n  aes(sample = logconc)\n) +\n  geom_qq_line() +\n  geom_qq(size = 0.75, alpha = 0.5) \n\n\n\n\nIt is not perfect, but it is much better.\n\n\nAssociation with BV\nNow, we are interested in testing whether a BV (Bacterial Vaginosis) diagnosis is associated with different mean concentrations of IL-1\\(\\beta\\).\nRemember, the BV diagnosis is contained in the Clinical Measurements table. So we first need to load that table in R.\n\nclin &lt;- \n  read_csv(\n    \"data/02_visit_clinical_measurements_UKZN_workshop_2023.csv\",\n    show_col_types = FALSE\n  )\n\nThe first 6 rows of the clinical data are:\n\nclin |&gt; head() |&gt; pander()\n\n\n\n\n\n\n\n\n\n\n\n\npid\ntime_point\narm\nnugent_score\ncrp_blood\nph\n\n\n\n\npid_01\nbaseline\nplacebo\n8\n0.44\n5.7\n\n\npid_01\nweek_1\nplacebo\n7\n1.66\n5.2\n\n\npid_01\nweek_7\nplacebo\n7\n1.44\n5.4\n\n\npid_02\nbaseline\nplacebo\n7\n1.55\n5.2\n\n\npid_02\nweek_1\nplacebo\n7\n0.75\n4.8\n\n\npid_02\nweek_7\nplacebo\n4\n1.17\n4.2\n\n\n\n\n\nThere are several ways to diagnose BV. One of them is to check whether a person has a Nugent score of 7 or more.\nLet’s create a new BV variable that says whether a person was diagnosed with BV at each visit.\n\nclin &lt;- \n  clin |&gt; \n  mutate(BV = ifelse(nugent_score &gt;= 7, \"BV\", \"Healthy\")) \n\nSince we want to compare the IL-1\\(\\beta\\) concentrations of individuals with or without BV, we need to join the clinical data with the IL-1\\(\\beta\\) concentration data.\nHint: to do so, we need a table describing how the sample IDs and participant x visit IDs are linked together - this info is in the “Sample ID” table.\n\nsample_info &lt;- \n  read_csv(\n    file = \"data/00_sample_ids_UKZN_workshop_2023.csv\",\n    show_col_types = FALSE\n  )\n\nThe first 6 rows of the sample info table are:\n\nsample_info |&gt; head() |&gt; pander()\n\n\n\n\n\n\n\n\n\n\npid\ntime_point\narm\nsample_id\n\n\n\n\npid_17\nbaseline\ntreatment\nSAMP001\n\n\npid_22\nweek_1\ntreatment\nSAMP002\n\n\npid_25\nweek_1\ntreatment\nSAMP003\n\n\npid_41\nweek_1\ntreatment\nSAMP004\n\n\npid_44\nweek_7\ntreatment\nSAMP005\n\n\npid_16\nweek_1\ntreatment\nSAMP006\n\n\n\n\n\nWe see that we can use the sample_id column to bind the cytokine concentrations with the sample_info table, then bind on the participant and visit ID with the clinical data.\n\nIL1b &lt;- \n  IL1b |&gt; \n  left_join(sample_info, by = join_by(sample_id)) |&gt; \n  left_join(clin, by = join_by(pid, time_point, arm))\n\nNow that our data are joined, let’s display the histogram of IL-1\\(\\beta\\) concentrations, including those out-of-range, colored by BV diagnosis.\n\nBV_colors &lt;- \n  c(\"BV\" = \"darkgoldenrod1\", \"Healthy\" = \"cornflowerblue\")\n\nggplot(\n  IL1b, #|&gt; filter(limits == \"within limits\"),\n  aes(x = logconc, fill = BV)\n) +\n  geom_histogram(bins = 30, alpha = 0.5, position = \"identity\") +\n  xlab(\"log10(conc)\") +\n  ggtitle(\"IL-1b concentration by BV diagnosis\") +\n  scale_fill_manual(values = BV_colors)\n\n\n\n\nFrom this visualization, it looks like the distribution is lower in healthy participants than in participants with BV.\nWhat do we think of the “out-of-range” values? Should we include them in our analysis?\nLet’s do a statistical test to see if these differences in concentrations could have happened by chance.\nSince our data, once log-transformed, look normal, (with the exclusion of the out-of-range samples) it makes sense to use a \\(t\\)-test. We can also check how many samples we have in each group to check if, regardless of the underlying distribution, there are enough samples to use a \\(t\\)-test.\n\nIL1b |&gt; \n  select(BV) |&gt; \n  table()\n\nBV\n     BV Healthy \n     46      86 \n\n\nWe have many samples, so we could, regardless of the underlying distribution, use a \\(t\\)-test.\n\nt.test(logconc ~ BV, data = IL1b)\n\n\n    Welch Two Sample t-test\n\ndata:  logconc by BV\nt = 6.5449, df = 116.4, p-value = 1.672e-09\nalternative hypothesis: true difference in means between group BV and group Healthy is not equal to 0\n95 percent confidence interval:\n 0.5332052 0.9959381\nsample estimates:\n     mean in group BV mean in group Healthy \n            1.1245273             0.3599557 \n\n\nWhat do you conclude?"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/index.html#non-parametric-tests",
    "href": "materials/1-workshop1/6-hypothesis-testing/index.html#non-parametric-tests",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Non-parametric tests",
    "text": "Non-parametric tests\nSo far, we could use the \\(t\\)-test to make inference on the means of different populations because we either had more than 40 samples in each group or we observed or knew that the samples were drawn from a normal distribution.\nSo, when our data is small and does not appear to be drawn from a normal distribution, we cannot use the \\(t\\)-test that assumes normality of the underlying data or requires large enough sample sizes.\nThe \\(t\\)-test is part of the family of parametric tests because they assume that the underlying data follows a specific distribution which can be characterized by parameters. For example, the parameters of a normal distribution are the mean and the variance.\nThere are also non-parametric tests which makes no assumption on the distribution of the data.\n\nThe Wilcoxon rank-sum test\nThe Wilcoxon rank-sum test is a non-parametric test to compare two independent datasets. The null hypothesis is that, for randomly selected values \\(X\\) and \\(Y\\) from two populations, the probability of \\(X\\) being greater than \\(Y\\) is equal to the probability of \\(Y\\) being greater than \\(X\\) (see Wikipedia), regardless of the distribution \\(X\\) and \\(Y\\) are drawn from.\nLet’s try the test on our small dataset:\n\nwilcox.test(value ~ dataset, \n            data = X_small_sample |&gt; filter(dataset %in% c(1,3)))\n\n\n    Wilcoxon rank sum exact test\n\ndata:  value by dataset\nW = 13, p-value = 0.003886\nalternative hypothesis: true location shift is not equal to 0\n\n\nAnd compare it to the \\(t\\)-test (we can because we know this data is drawn from a Normal).\n\nt.test(value ~ dataset, \n       data = X_small_sample |&gt; filter(dataset %in% c(1,3)))\n\n\n    Welch Two Sample t-test\n\ndata:  value by dataset\nt = -3.2548, df = 17.988, p-value = 0.004402\nalternative hypothesis: true difference in means between group 1 and group 3 is not equal to 0\n95 percent confidence interval:\n -3.4653702 -0.7465168\nsample estimates:\nmean in group 1 mean in group 3 \n      -0.377852        1.728091 \n\n\nWe see that both provides small probabilites to observe the data under the null hypothesis.\nSo, why not always using a non-parametric test if they work in all situations and not worry about normality of the data?\nBecause, non-parametric tests have less power to detect small effects.\nTo check that, we can rely on simulations.\nHere, we simulate 1000 times two small datasets of 10 samples with a relatively small difference between their means (relative to the standard deviation) and perform both a \\(t\\) test and a Wilcoxon rank sum test.\nWe then count how many times each test rejected the null (as they should) and see if one of the two tests reject more often.\n\nset.seed(123)\nsimulate_and_run_both_test &lt;- function(){\n  x1 &lt;- rnorm(10, mean = 0, sd = 2)\n  x2 &lt;- rnorm(10, mean = 1.5, sd = 2)\n  \n  ttest &lt;- t.test(x1, x2)\n  wtest &lt;- wilcox.test(x1, x2)\n  tibble(ttest_pvalue = ttest$p.value, wtest_pvalue = wtest$p.value)\n}\n\nsimulation_results &lt;- replicate(1000, simulate_and_run_both_test())\n\napply(simulation_results &lt;= 0.05, 2, mean)\n\nttest_pvalue wtest_pvalue \n       0.354        0.319 \n\n\nWe see that the \\(t\\)-test more frequently detected that the two samples were drawn from distribution with different means/locations."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/index.html#multiple-testing",
    "href": "materials/1-workshop1/6-hypothesis-testing/index.html#multiple-testing",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Multiple testing",
    "text": "Multiple testing\n\nSimulations\nAs we discussed above, the \\(p\\)-value of a test is the probability, under the null hypothesis, to observe a value of the test statistics as extreme as the one we observe. Usually, if that probability is less than 0.05 (we have less than one/20 chances to observe that value), we reject the null hypothesis.\nSo, if we repeat a test many many times on data generated under the null hypothesis (so we should not reject it), we will obtain a small \\(p\\)-value a few times.\nTo verify this, let’s do a simulation experiment and repeat the following procedure a 1000 times: we draw two small datasets from that same population (= the null hypothesis is true) and perform a \\(t\\)-test. In theory, we should get 0.05 x 1000 = 50 experiments with a \\(p\\)-value smaller than 0.05.\n\nsimulate_and_test &lt;- function(){\n  x1 &lt;- rnorm(10)\n  x2 &lt;- rnorm(10) # same mean\n  ttest &lt;- t.test(x1, x2)\n  ttest$p.value # we return the p-value\n}\n\nnull_p.values &lt;- replicate(1000, simulate_and_test())\n\nLet’s count how many times we have a p-value smaller than 0.05 under the null hypothesis:\n\nsum(null_p.values &lt; 0.05)\n\n[1] 52\n\n\nWhich corresponds to a rate of\n\nmean(null_p.values &lt; 0.05)\n\n[1] 0.052\n\n\nwhich is, indeed, very close to the \\(p\\)-value threshold that we’ve selected.\nThis is because, under the null hypothesis, the distribution of \\(p\\)-values is uniform:\n\nnull_p.values_tbl &lt;- tibble(p_values = null_p.values)\n\nggplot(null_p.values_tbl, aes(x = p_values)) +\n  geom_histogram(bins = 20)\n\n\n\n\nThis is a good opportunity to learn how to perform a QQ-plot for another distribution than the Normal distribution. Here, to check that the p-values follow a uniform distribution, we can use the distribution argument from the geom_qq functions and do the following QQ-plot:\n\nggplot(null_p.values_tbl, aes(sample = p_values)) +\n  geom_qq_line(distribution = qunif) +\n  geom_qq(distribution = qunif, size = 0.5, alpha = 0.5)\n\n\n\n\nThis is very convincing that the \\(p\\)-values under the null follow a uniform distribution.\nNow, let’s come back to the interpretation/consequences of this uniform distribution: if the distribution of \\(p\\)-values under the Null is uniform, this means that we will reject the null hypothesis with a rate of \\(\\alpha\\) if \\(\\alpha\\) is the rejection threshold.\nThis will also apply to real data if we perform the same test several times.\nFor example, let’s say that we were interested in not just IL-1\\(\\beta\\) but all cytokines and are to repeat the \\(t\\)-test we did above for all cytokines, since we have 10 of them, it’s not unlikely that we’d have small \\(p\\)-values just by chance.\nSo, whenever we do “multiple testing”, we need to adjust for that multiple testing.\nThere are several ways to do “multiple testing adjustments” but the explanations of these methods are outside the scope of this class. Many of these methods have conveniently been implemented in the p.adjust function.\nOne of these methods that “controls for the”false discovery rate” is the Benjamini-Hochberg adjustment.\nLet’s apply it to our simulated \\(p\\)-values and check now how many samples are still considered to have a significant adjusted \\(p\\)-value:\n\nnull_p.values_tbl &lt;- \n  null_p.values_tbl |&gt; \n  mutate(q_values = p.adjust(p_values, method = \"BH\"))\n\n\nmean(null_p.values_tbl$q_values &lt;= 0.05)\n\n[1] 0\n\n\nNone of them!\nWhich is what it should be as we simulated our data under the null hypothesis, we should never reject the Null.\n\nggplot(null_p.values_tbl, aes(x = q_values)) +\n  geom_histogram(bins = 20) +\n  expand_limits(x = 0) +\n  xlab(\"BH adjusted p-values\")\n\n\n\n\n\n\nCytokines\nLet’s now test which cytokines have different means in BV and non-BV study participants.\nFirst, we need to take the log-concentration of all cytokines and join with the clinical data via the “sample info”.\n\nelisa &lt;- \n  elisa |&gt; \n  mutate(logconc = log10(conc)) |&gt; \n  left_join(sample_info, by = join_by(sample_id)) |&gt; \n  left_join(clin, by = join_by(pid, time_point, arm))\n\nWe can also display concentration by BV status for each cytokine:\n\nelisa |&gt; \n  ggplot(aes(x = logconc, fill = BV)) +\n  geom_histogram(bins = 30, position = \"identity\", alpha = 0.5) +\n  facet_wrap(cytokine ~ .) +\n  xlab('log10(concentrations)') +\n  scale_fill_manual(values = BV_colors)\n\n\n\n\nAnother way to look at this is to display the data as “boxplot”:\n\nelisa |&gt; \n  ggplot(aes(y = logconc, fill = BV, col = BV, x = cytokine)) +\n  geom_boxplot(varwidth = TRUE, outlier.size = 0.5, alpha = 0.5) +\n  scale_fill_manual(values = BV_colors) +\n  scale_color_manual(values = BV_colors)\n\n\n\n\nLooking at these visual displays of the data. Do you think it makes sense to do the test for all cytokines? What about cytokines that have a lot of samples with concentrations lower than the limit of detection?\nShould we exclude these cytokines? Remove the out-of-range values? Or keep them?\nIdeally, we would only want to do the test for variables where we are confident that we have representative samples.\nThere is a little bit of subjectivity in terms of what we deem representative, but, for now, let’s say that we want the 1st and 3rd quartile to be within the range of detection for each cytokine and each group.\nLet’s thus compute the 1st and 3rd quartiles (or, equivalently the 25th and 75th percentiles) for each cytokines and each group:\n\ninterquartiles &lt;- \n  elisa |&gt; \n  # we also need to compute the LLOQ and ULOQ for each cytokine\n  group_by(cytokine) |&gt; \n  mutate(LLOQ = min(logconc), ULOQ = max(logconc)) |&gt;\n  group_by(cytokine, LLOQ, ULOQ, BV) |&gt; \n  summarize(\n    `1st quartile` = quantile(logconc, 0.25),\n    `3rd quartile` = quantile(logconc, 0.75)\n  ) \n\n`summarise()` has grouped output by 'cytokine', 'LLOQ', 'ULOQ'. You can\noverride using the `.groups` argument.\n\ninterquartiles |&gt; \n  pander()\n\n\n\n\n\n\n\n\n\n\n\n\ncytokine\nLLOQ\nULOQ\nBV\n1st quartile\n3rd quartile\n\n\n\n\nIFN-Y\n-0.4641\n1.369\nBV\n-0.4641\n-0.1024\n\n\nIFN-Y\n-0.4641\n1.369\nHealthy\n-0.4641\n-0.4641\n\n\nIL-10\n-0.1152\n1.482\nBV\n-0.1152\n0.3345\n\n\nIL-10\n-0.1152\n1.482\nHealthy\n-0.1152\n-0.1152\n\n\nIL-1a\n0.143\n3.011\nBV\n1.681\n2.238\n\n\nIL-1a\n0.143\n3.011\nHealthy\n1.067\n1.976\n\n\nIL-1b\n-0.6012\n2.347\nBV\n0.8021\n1.334\n\n\nIL-1b\n-0.6012\n2.347\nHealthy\n-0.2347\n0.9864\n\n\nIL-6\n-1.029\n2.238\nBV\n0.08762\n0.7945\n\n\nIL-6\n-1.029\n2.238\nHealthy\n-0.364\n0.6946\n\n\nIL-8\n-0.3279\n3.398\nBV\n2.164\n2.916\n\n\nIL-8\n-0.3279\n3.398\nHealthy\n1.575\n2.71\n\n\nIP-10\n-0.5157\n3.699\nBV\n-0.5157\n0.06446\n\n\nIP-10\n-0.5157\n3.699\nHealthy\n-0.1079\n1.945\n\n\nMIG\n0.1872\n4.398\nBV\n0.1872\n1.07\n\n\nMIG\n0.1872\n4.398\nHealthy\n0.6586\n2.023\n\n\nMIP-3a\n0.7137\n2.516\nBV\n0.7137\n0.7137\n\n\nMIP-3a\n0.7137\n2.516\nHealthy\n0.7137\n1.168\n\n\nTNFa\n-0.327\n1.631\nBV\n-0.327\n0.5051\n\n\nTNFa\n-0.327\n1.631\nHealthy\n-0.327\n0.1446\n\n\n\n\n\nLet’s filter for cytokines with an interquartile range within the limits of quantification for both groups:\n\ninterquartiles |&gt; \n  filter(\n    `1st quartile` &gt; LLOQ,\n    `3rd quartile` &lt; ULOQ\n  ) |&gt; \n  group_by(cytokine) |&gt;\n  summarize(n = n(), .groups = \"drop\") |&gt; \n  filter(n == 2) |&gt;\n  pander()\n\n\n\n\n\n\n\n\ncytokine\nn\n\n\n\n\nIL-1a\n2\n\n\nIL-1b\n2\n\n\nIL-6\n2\n\n\nIL-8\n2\n\n\n\n\n\nThat only leaves us with 4 cytokines. Our criteria might be a little too stringent, and, as long as you justify it properly, you could loosen these criteria. We just want to make sure that you always take a critical look at your data before running a test.\nWe will now filter our data to only keep these 4 cytokines and perform a statistical test for each of theses.\n\nttest_res &lt;- \n  elisa |&gt; \n  group_by(cytokine) |&gt; \n  filter(\n    cytokine %in% c(\"IL-1a\",\"IL-1b\", \"IL-6\", \"IL-8\")\n  ) |&gt;\n  summarize(\n    `p-value` = t.test(logconc ~ BV)$p.value,\n    `p &lt; 0.05` = ifelse(`p-value` &lt; 0.05, \"yes\", \"\")\n  ) \n\nttest_res |&gt; pander()\n\n\n\n\n\n\n\n\n\ncytokine\np-value\np &lt; 0.05\n\n\n\n\nIL-1a\n8.492e-08\nyes\n\n\nIL-1b\n1.672e-09\nyes\n\n\nIL-6\n0.08282\n\n\n\nIL-8\n0.00825\nyes\n\n\n\n\n\nWe see that 3/4 cytokines have p-values smaller than 0.05. But remember, we need to adjust for multiple testing.\n\nttest_res &lt;- \n  ttest_res |&gt; \n  mutate(\n    `adj. p-value` = p.adjust(`p-value`, method = \"BH\"),\n    `statistical\\nsignificance` = \n      ifelse(`adj. p-value` &lt; 0.05, \"yes\",\"\")\n  )\n\n\nttest_res |&gt; pander()\n\n\n\n\n\n\n\n\n\n\n\ncytokine\np-value\np &lt; 0.05\nadj. p-value\nstatistical significance\n\n\n\n\nIL-1a\n8.492e-08\nyes\n1.698e-07\nyes\n\n\nIL-1b\n1.672e-09\nyes\n6.689e-09\nyes\n\n\nIL-6\n0.08282\n\n0.08282\n\n\n\nIL-8\n0.00825\nyes\n0.011\nyes\n\n\n\n\n\nThe three cytokines that had a p-value smaller than 0.05 are still significant after adjusting for multiple testing.\nRedo this analysis, but with a less stringent criteria for representativeness. For example, let’s only request from our cytokines that their 1st and 3rd quartiles are different.\n\nselected_cytokines &lt;- \n  interquartiles |&gt; \n  filter(\n    `1st quartile` &lt; `3rd quartile`\n  ) |&gt; \n  group_by(cytokine) |&gt;\n  summarize(n = n(), .groups = \"drop\") |&gt; \n  filter(n == 2) |&gt;\n  select(cytokine) |&gt; unlist()\n\nselected_cytokines\n\ncytokine1 cytokine2 cytokine3 cytokine4 cytokine5 cytokine6 cytokine7 \n  \"IL-1a\"   \"IL-1b\"    \"IL-6\"    \"IL-8\"   \"IP-10\"     \"MIG\"    \"TNFa\" \n\n\n\nttest_res &lt;- \n  elisa |&gt; \n  filter(cytokine %in% selected_cytokines) |&gt; \n  group_by(cytokine) |&gt;\n  summarize(\n    `p-value` = t.test(logconc ~ BV)$p.value,\n    `p &lt; 0.05` = ifelse(`p-value` &lt; 0.05, \"yes\", \"\")\n  )  |&gt; \n  mutate(\n    `adj. p-value` = p.adjust(`p-value`, method = \"BH\"),\n    `statistical\\nsignificance` = \n      ifelse(`adj. p-value` &lt; 0.05, \"yes\",\"\")\n  )\n\n\nttest_res |&gt; pander()\n\n\n\n\n\n\n\n\n\n\n\ncytokine\np-value\np &lt; 0.05\nadj. p-value\nstatistical significance\n\n\n\n\nIL-1a\n8.492e-08\nyes\n1.486e-07\nyes\n\n\nIL-1b\n1.672e-09\nyes\n5.853e-09\nyes\n\n\nIL-6\n0.08282\n\n0.08282\n\n\n\nIL-8\n0.00825\nyes\n0.01155\nyes\n\n\nIP-10\n1.974e-12\nyes\n1.381e-11\nyes\n\n\nMIG\n4.902e-08\nyes\n1.144e-07\nyes\n\n\nTNFa\n0.02701\nyes\n0.03151\nyes\n\n\n\n\n\nWhat do you conclude from this analysis?\nAs an exercise, you can also re-do the analyses using a non-parametric test and discuss the differences in the results."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/index.html#displaying-longitudinal-data",
    "href": "materials/1-workshop1/6-hypothesis-testing/index.html#displaying-longitudinal-data",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Displaying longitudinal data",
    "text": "Displaying longitudinal data\nSo far, we have ignore the fact that we have longitudinal data.\nRemember the study design:\n\n\n\n\n\nWe have 3 time points for each patient. We can thus look at the evolution of the cytokine concentrations over time.\nWe have already joined the elisa data with the sample_info data so we already have the participant id and the visit id for all cytokine samples:\n\nelisa |&gt;  head() |&gt; pander()\n\n\nTable continues below\n\n\n\n\n\n\n\n\n\n\n\nsample_id\ncytokine\nconc\nlimits\nlogconc\npid\ntime_point\n\n\n\n\nSAMP094\nIL-1a\n173.9\nwithin limits\n2.24\npid_01\nbaseline\n\n\nSAMP094\nIL-10\n0.767\nout of range\n-0.1152\npid_01\nbaseline\n\n\nSAMP094\nIL-1b\n5.39\nwithin limits\n0.7316\npid_01\nbaseline\n\n\nSAMP094\nIL-8\n48.29\nwithin limits\n1.684\npid_01\nbaseline\n\n\nSAMP094\nIL-6\n5.07\nwithin limits\n0.705\npid_01\nbaseline\n\n\nSAMP094\nTNFa\n0.471\nout of range\n-0.327\npid_01\nbaseline\n\n\n\n\n\n\n\n\n\n\n\n\n\narm\nnugent_score\ncrp_blood\nph\nBV\n\n\n\n\nplacebo\n8\n0.44\n5.7\nBV\n\n\nplacebo\n8\n0.44\n5.7\nBV\n\n\nplacebo\n8\n0.44\n5.7\nBV\n\n\nplacebo\n8\n0.44\n5.7\nBV\n\n\nplacebo\n8\n0.44\n5.7\nBV\n\n\nplacebo\n8\n0.44\n5.7\nBV\n\n\n\n\n\nBefore jumping into the visualization, let’s do some data wrangling.\nFirst, let’s do some cosmetic changes to the time_point column so that the visits labels print nicely when using ggplot.\nTo replace the “_” with a space, we can use the str_replace function from the stringr package.\nBefore:\n\nelisa$time_point |&gt; unique()\n\n[1] \"baseline\" \"week_1\"   \"week_7\"  \n\n\n\nelisa &lt;- \n  elisa |&gt; \n  mutate(time_point = time_point |&gt; str_replace(\"_\", \" \"))\n\nAfter:\n\n# let's check that it worked\nelisa$time_point |&gt; unique()\n\n[1] \"baseline\" \"week 1\"   \"week 7\"  \n\n\nThen, let’s transform all the variables that are character but should be factors to … factor.\n\nelisa &lt;- \n  elisa |&gt; \n  mutate(\n    sample_id = sample_id |&gt; factor(),\n    cytokine = cytokine |&gt; factor(),\n    pid = pid |&gt; factor(),\n    time_point =time_point |&gt; factor(),\n    arm = arm |&gt; factor(),\n    limits = limits |&gt; factor()\n    )\n\nNow, we can display the IL-1\\(\\beta\\) log-concentrations over-time, connecting the concentrations of a given participant by a line.\nNote the use of the group aesthetic in geom_line to tell ggplot to connect the points of the same participant.\nCheck what happens if you remove aes(group = pid) from geom_line.\n\narm_color &lt;- \n  c(\"placebo\" = \"deeppink\", \"treatment\" = \"steelblue1\")\n\nelisa |&gt; \n  filter(cytokine == \"IL-1b\") |&gt; \n  ggplot(aes(x = time_point, y = logconc, color = arm)) +\n  geom_line(aes(group = pid), alpha = 0.75) +\n  geom_point(alpha = 0.5) +\n  xlab(\"Visits\") +\n  ylab(\"log10(IL-1b concentration)\") +\n  scale_color_manual(\"Arm\", values = arm_color)\n\n\n\n\n\nPaired tests\nOne question that this study may have aimed to answer is whether treatment altered how the cytokine concentrations changed over time.\nSpecifically, we may have been interested in comparing the changes between the baseline visit and the week 7 visit.\nLet’s do the same visualization, but excluding week 1:\n\nelisa |&gt; \n  filter(cytokine == \"IL-1b\", time_point != \"week 1\") |&gt; \n  ggplot(aes(x = time_point, y = logconc, color = arm)) +\n  geom_line(aes(group = pid), alpha = 0.75) +\n  geom_point(alpha = 0.5) +\n  xlab(\"Visits\") +\n  ylab(\"log10(IL-1b concentration)\") +\n  scale_color_manual(\"Arm\", values = arm_color)\n\n\n\n\nWe see that everyone starts with a different level of IL-1b and the ranking in the baseline visit is somewhat similar to the ranking in the week 7 visit, especially in the treatment arm.\nTo test this specifically, we can do a “paired test”.\nIt is “paired” because for each observation at the baseline visit, there is a “sister” observation at the week 7 visit (= the sample from the same participant).\nHere, because we have many samples, we can use a paired \\(t\\)-test, but if we had only one sample per participant, we would have to use a paired Wilcoxon test.\nIn a “real” analysis, we would only do one of the two tests, but for demonstration purposes, let’s do both (without adjusting for multiple testing because it’s just illustrative).\n\nelisa |&gt; \n  filter(cytokine == \"IL-1b\", time_point != \"week 1\") |&gt; \n  select(cytokine, arm, pid, time_point, logconc) |&gt;\n  pivot_wider(names_from = time_point, values_from = logconc) |&gt;\n  group_by(arm) |&gt; \n  summarize(\n    `p (t-test)` = \n      t.test(x = baseline, y = `week 7`, paired = TRUE)$p.value,\n    `p (signed rank)` = \n      wilcox.test(x = baseline, y = `week 7`, paired = TRUE)$p.value\n  ) |&gt; \n  mutate(\n    `p &lt; 0.05 (t)` = ifelse(`p (t-test)` &lt; 0.05, \"yes\", \"\"),\n    `p &lt; 0.05 (w)` = ifelse(`p (signed rank)` &lt; 0.05, \"yes\", \"\")\n  ) |&gt; \n  pander()\n\nWarning: There was 1 warning in `summarize()`.\nℹ In argument: `p (signed rank) = wilcox.test(x = baseline, y = `week 7`,\n  paired = TRUE)$p.value`.\nℹ In group 2: `arm = treatment`.\nCaused by warning in `wilcox.test.default()`:\n! cannot compute exact p-value with ties\n\n\n\n\n\n\n\n\n\n\n\n\narm\np (t-test)\np (signed rank)\np &lt; 0.05 (t)\np &lt; 0.05 (w)\n\n\n\n\nplacebo\n0.3998\n0.41\n\n\n\n\ntreatment\n0.0007528\n0.001226\nyes\nyes\n\n\n\n\n\nWe see that the two tests agree in this case (as they should because the effects are quite large in the treatment arm).\nExercise: repeat the same visualization and analysis for IL-6 and IL-8. Do you need to adjust for multiple testing?"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/index.html#compositional-data",
    "href": "materials/1-workshop1/6-hypothesis-testing/index.html#compositional-data",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Compositional data",
    "text": "Compositional data\nMultivariate data are said to be “compositional” when they are expressed in terms of proportion of a sample.\nThe problem with compositional data is that they are constrained to sum to 1, so that the values of the different variables are not independent.\nWhich means that if only one variable changes in absolute value (unknown), in relative values (known), the others will change too.\nFor example, if we have 3 cell sub-types: A, B, and C.\nIn one sample, we have 102 cells A, 72 cells B, and 147 cell C.\nIn code, we would write:\n\nsample_1 &lt;- c(\"A\" = 102, \"B\" = 72, \"C\" = 147)\nsample_1\n\n  A   B   C \n102  72 147 \n\n# note: usually we define vectors with just their values, like this: c(102, 72, 147), but we can also give names to each element of the vector as we did above\n\nIn another sample, we have the same number of cells A and B, but we have 62 additional cells C.\n\nsample_2 &lt;- sample_1 \nsample_2[\"C\"] &lt;- sample_2[\"C\"] + 62\n\n# the two lines above do the following: we create sample_2 as a copy of sample_1. Then, we only modify the \"C\" element of sample_2 and we add 62 to the value that was already there.\n\nNow, we can compute the proportions of each cell type in each sample:\n\nprop_1 &lt;- sample_1 / sum(sample_1)\n\nprop_2 &lt;- sample_2 / sum(sample_2)\n\nAnd display them:\n\nprop_1 |&gt; round(digits = 2) # the `round` function rounds the number. The `digit` argument specifies the number of digits to keep after the decimal point. Try with digits = 0 or digits = 4 to see the difference in output.\n\n   A    B    C \n0.32 0.22 0.46 \n\nprop_2 |&gt; round(digits = 2)\n\n   A    B    C \n0.27 0.19 0.55 \n\n\nWe see that the proportion of C has increased (because there are more cells) and consequently, the proportions of A and B have decreased (even though there were the same number of cells).\n\nFlow cytometry data\nFor now, let’s explore the flow cytometry data.\n\nflow &lt;- \n  read_csv(\n    \"data/04_flow_cytometry_UKZN_workshop_2023.csv\"\n    )\n\nRows: 132 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): sample_id\ndbl (9): live_cd19_negative, cd45_negative, cd45_positive, neutrophils, non_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe have one row per sample. And remember, we have three sample per patient (one for each visit).\nOne of the first things we observe is that all columns (except sample_id) are (large) integer numbers. We say that we have “count data”.\nRemember, that these are the number of cells observed in each “gating” categories. Also, remember that some cell categories are subset of other categories.\nFor example, “live CD19-” cells are roughly divided into “CD45+” and “CD45-” cells.\n\nggplot(flow, \n       aes(y = live_cd19_negative, \n           x = cd45_positive + cd45_negative)\n       ) +\n  geom_abline(intercept = 0, slope = 1, col = \"purple1\") +\n  geom_point(alpha = 0.5) +\n  scale_x_log10() +\n  scale_y_log10()\n\n\n\n\nAnd “CD3+” are roughly divided into “CD4 T” and “CD8 T” cells.\n\nggplot(flow, \n       aes(x = cd3_positive, \n           y = cd4_t_cells + cd8_t_cells)\n       ) +\n  geom_abline(intercept = 0, slope = 1, col = \"purple1\") +\n  geom_point(alpha = 0.5) +\n  scale_x_log10() +\n  scale_y_log10()\n\n\n\n\nSo, if we show the fraction of “CD4 T” cells against that of “CD8 T” cells among all T cells (the “CD3+” cells).\n\nggplot(flow, \n       aes(x = cd4_t_cells/cd3_positive, \n           y = cd8_t_cells/cd3_positive )\n       ) +\n  geom_point(alpha = 0.5) +\n  xlab(\"CD4 T cells (fraction of all T cells)\") +\n  ylab(\"CD8 T cells (fraction of all T cells)\")\n\n\n\n\nWe see that we have a negative correlation: when the proportion of CD8 T cells increases, the proportion of CD4 T cells decreases.\nWhat are the consequences of that?\nLet’s say that we are interested in looking at the treatment effect on the proportion of different T cell sub-types. If we were to forget that these were compositional data, we could do the same as what we did for the cytokines, and perform a test for each cell sub-type.\nBut since we know that they are anti-correlated, if there is an effect on one sub-type, there might be an opposite effect on the other sub-type.\nLet’s see if that’s the case.\nFirst, let’s create a simplified flow cytometry table with just the T cell data and compute the proportion of the CD4 and CD8 T cells.\n\nflow_T &lt;- \n  flow |&gt; \n  select(sample_id, cd4_t_cells, cd8_t_cells, cd3_positive) |&gt;\n  mutate(\n    cd4_t_cells_f = cd4_t_cells/cd3_positive,\n    cd8_t_cells_f = cd8_t_cells/cd3_positive,\n    sum = cd4_t_cells_f + cd8_t_cells_f,\n    remaining_t_cells_f = 1 - sum\n    ) \n\nhead(flow_T) |&gt; pander()\n\n\nTable continues below\n\n\n\n\n\n\n\n\n\nsample_id\ncd4_t_cells\ncd8_t_cells\ncd3_positive\ncd4_t_cells_f\n\n\n\n\nSAMP094\n409\n444\n988\n0.414\n\n\nSAMP052\n7126\n6009\n15078\n0.4726\n\n\nSAMP017\n36212\n13434\n53758\n0.6736\n\n\nSAMP046\n2872\n2629\n6254\n0.4592\n\n\nSAMP025\n6384\n3039\n11355\n0.5622\n\n\nSAMP050\n2405\n1310\n4076\n0.59\n\n\n\n\n\n\n\n\n\n\n\ncd8_t_cells_f\nsum\nremaining_t_cells_f\n\n\n\n\n0.4494\n0.8634\n0.1366\n\n\n0.3985\n0.8711\n0.1289\n\n\n0.2499\n0.9235\n0.07649\n\n\n0.4204\n0.8796\n0.1204\n\n\n0.2676\n0.8299\n0.1701\n\n\n0.3214\n0.9114\n0.08857\n\n\n\n\n\nWe also computed the sum of the fractions of the CD4 and CD8 T cells and see that this sum is not always 1. That means that some cells are not CD4 or CD8 T cells. The distribution of the sum of their fraction goes as:\n\nggplot(flow_T, aes(x = sum)) +\n  geom_histogram(bins = 30) +\n  geom_vline(xintercept = 1, col = \"red\", linetype = 2) +\n  xlab(\"sum of the fractions of CD4 and CD8 T cells\") \n\n\n\n\nAs said above, one question we may have is whether the proportions of CD4 and CD8 T cells are different between the two arms at the end of the intervention.\nTo be able to answer this question, we first need to join the flow cytometry data with the sample information (the sample_info table) so we know which sample is from which visit and which participant and their arm.\n\nflow_T_with_info &lt;- \n  flow_T |&gt; \n  left_join(sample_info, by = \"sample_id\")\n\nflow_T_with_info |&gt; head() |&gt; pander()\n\n\nTable continues below\n\n\n\n\n\n\n\n\n\nsample_id\ncd4_t_cells\ncd8_t_cells\ncd3_positive\ncd4_t_cells_f\n\n\n\n\nSAMP094\n409\n444\n988\n0.414\n\n\nSAMP052\n7126\n6009\n15078\n0.4726\n\n\nSAMP017\n36212\n13434\n53758\n0.6736\n\n\nSAMP046\n2872\n2629\n6254\n0.4592\n\n\nSAMP025\n6384\n3039\n11355\n0.5622\n\n\nSAMP050\n2405\n1310\n4076\n0.59\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncd8_t_cells_f\nsum\nremaining_t_cells_f\npid\ntime_point\narm\n\n\n\n\n0.4494\n0.8634\n0.1366\npid_01\nbaseline\nplacebo\n\n\n0.3985\n0.8711\n0.1289\npid_01\nweek_1\nplacebo\n\n\n0.2499\n0.9235\n0.07649\npid_01\nweek_7\nplacebo\n\n\n0.4204\n0.8796\n0.1204\npid_02\nbaseline\nplacebo\n\n\n0.2676\n0.8299\n0.1701\npid_02\nweek_1\nplacebo\n\n\n0.3214\n0.9114\n0.08857\npid_02\nweek_7\nplacebo\n\n\n\n\n\nLet’s now display the proportions of these cells at the week 7 visit:\n\nflow_T_with_info_long &lt;- \n  flow_T_with_info |&gt; \n  select(sample_id, pid, time_point, arm, ends_with(\"_f\")) |&gt; \n  pivot_longer(\n    cols = ends_with(\"_f\"),\n    names_to = \"cell_type\",\n    values_to = \"fraction of T cells\"\n    )\n  \nflow_T_with_info_long |&gt; \n  ggplot(aes(x = cell_type, y = `fraction of T cells`,\n             fill = arm)) +\n  geom_boxplot() +\n  scale_fill_manual(values = arm_color) \n\n\n\n\nIt looks like there might be some differences: a lower proportion of CD4 T cells in the intervention arm than in the placebo arm and and slightly higher proportions in the two others.\nBut from these compositional data, it is impossible to know if one of the cell type is driving these effects or if it is a combination of several changes in each cell types.\nOne could still do a test to see if the proportions are different in the two arms, but this is outside the scope of this workshop. Come back to the next ones for more :)"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/module-6-hands-on.html",
    "href": "materials/1-workshop1/6-hypothesis-testing/module-6-hands-on.html",
    "title": "Data Science for Biology Workshop Series",
    "section": "",
    "text": "Code\nlibrary(tidyverse) # loads the packages from the tidyverse suite\nlibrary(pander) # allows to display pretty tables \nlibrary(patchwork) # allows to combine ggplot (see Module 7)\ntheme_set(theme_light())\nset.seed(123) # set the \"random seed\" for reproducibility"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/module-6-hands-on.html#hypothesis-testing",
    "href": "materials/1-workshop1/6-hypothesis-testing/module-6-hands-on.html#hypothesis-testing",
    "title": "Data Science for Biology Workshop Series",
    "section": "Hypothesis testing",
    "text": "Hypothesis testing\nBefore testing hypotheses on real data, let’s develop our intuition on data we simulate ourselves.\nFor this first example, let’s simulate 3 datasets by sampling 50 values from 2 normal populations with different means but same variance (So two datasets are drawn from population 1 and one is drawn from population 2). Let’s use \\(\\mu_1 = 0\\), \\(\\mu_2 = 2\\), and \\(\\sigma^2 = 4\\).\n\n\n\n\n\n\nTo simulate normally distributed data, check the rnorm function by typing ?rnorm in the console.\nWe put the results of our simulations in a variable X that will be a “long” tibble with the following two columns: dataset, value.\n\n\n\n\n\nCode\nn_samples &lt;- 50\ncommon_sd &lt;- 2 # square root of 4 (we said)\n\nsample_1 &lt;- rnorm(n_samples, mean = 0, sd = common_sd) \nsample_2 &lt;- rnorm(n_samples, mean = 0, sd = common_sd) \nsample_3 &lt;- rnorm(n_samples, mean = 2, sd = common_sd)\n\nX &lt;- \n  bind_rows(\n    tibble(dataset = 1, value = sample_1),\n    tibble(dataset = 2, value = sample_2),\n    tibble(dataset = 3, value = sample_3)\n  ) |&gt; \n  mutate(dataset = dataset |&gt; factor())\n\n\nIf we display the top 6 raws, we have:\n\n\nCode\n# the head function takes the top x rows of a table\n# by default, the first 6 rows\n# pander just prints the result in a pretty way\nX |&gt; head() |&gt; pander()\n\n\n\n\n\n\n\n\n\ndataset\nvalue\n\n\n\n\n1\n-1.121\n\n\n1\n-0.4604\n\n\n1\n3.117\n\n\n1\n0.141\n\n\n1\n0.2586\n\n\n1\n3.43\n\n\n\n\n\nand the bottom 6 raws are:\n\n\nCode\n# tail prints the last 6 rows\nX |&gt; tail() |&gt; pander()\n\n\n\n\n\n\n\n\n\ndataset\nvalue\n\n\n\n\n3\n-1.203\n\n\n3\n0.9382\n\n\n3\n-0.9235\n\n\n3\n3.376\n\n\n3\n6.2\n\n\n3\n-0.5741\n\n\n\n\n\nTo validate that we’ve simulated our data properly, let’s compute the mean and variance of our data and display a histogram for each dataset.\n\n\nCode\nX %&gt;% \n  group_by(dataset) %&gt;% \n  summarize(mean = mean(value), var = var(value)) |&gt; \n  pander()\n\n\n\n\n\n\n\n\n\n\ndataset\nmean\nvar\n\n\n\n\n1\n0.06881\n3.429\n\n\n2\n0.2928\n3.279\n\n\n3\n1.492\n3.915\n\n\n\n\n\nDo these values make sense?\nWe can display the distributions we just simulated using ggplot and geom_histogram.\n\n\nCode\nggplot(X, aes(x = value, fill = dataset)) +\n  geom_histogram(bins = 50) +\n  facet_grid(dataset ~ ., labeller = label_both) +\n  guides(fill = \"none\") + # we don't really need a fill legend \n  theme(strip.text.y = element_text(angle = 0, hjust = 0)) # sometimes it is nicer to rotate the panel labels so they are horizontal and more easily readable\n\n\n\n\n\nVisually, it looks like the means of datasets 1 and 2 are similar, but the mean of dataset 3 is larger (expected based on how we simulated the data). However, because there is large variability in the data and a lot of overlap between the values of these datasets, we want to make sure that what we think we observe is not due to chance.\nThis what statistical tests help us do. Feel free to review the workshop slides if you need a reminder of what statistical tests are.\nHere, we want to do a test on the means of the datasets and test if the means of datasets 2 or 3 are different from the mean of dataset 1.\n\n\\(t\\)-tests\nBecause we have more than 40 samples in each dataset, we can use a \\(t\\)-test.\nIn R, \\(t\\)-tests can be done with the t.test function. Note that there are several ways to use the t.test function and several options we need to be careful about. To read more about these options, type ?t.test in your console.\nSpecifically, we need to be careful about specifying what our Null and alternative hypotheses are.\nThis is specified using the alternative option of the t.test function.\nThe option corresponding to\n\\[\\begin{align*}\nH_0:& \\ \\mu_1 = \\mu_2 \\\\\nH_a:& \\ \\mu_1 \\neq \\mu_2\n\\end{align*}\\]\nis alternative = \"two-sided\" which is the default option of t.test (that is, if we don’t specify the alternative, the function automatically assumes that we want to perform a “two-sided” test). It is \"two-sided\" because \\(\\mu_2\\) can be smaller OR larger in the alternative hypothesis.\nLet’s say that we do not have any a priori on the alternative and perform a two-sided test on the means of datasets 1 and 2.\n\n\n\nCode\nt.test(value ~ dataset, data = X |&gt; filter(dataset %in% 1:2))\n\n\n\n    Welch Two Sample t-test\n\ndata:  value by dataset\nt = -0.61157, df = 97.951, p-value = 0.5422\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -0.9508970  0.5028781\nsample estimates:\nmean in group 1 mean in group 2 \n      0.0688071       0.2928165 \n\n\nCode\n# this is the same as :\n# t.test(x = X$value[X$dataset == 1], y = X$value[X$dataset == 2])\n\n\nWe see that the probability to observe the \\(t\\) value is quite large. So, we do NOT reject the null hypothesis that the two means are the same.\nNow, if we do this test comparing the means of datasets 1 and 3, what do we get? What do you conclude?\n\n\nCode\nt.test(value ~ dataset, data = X |&gt; filter(dataset %in% c(1,3)))\n\n\n\n    Welch Two Sample t-test\n\ndata:  value by dataset\nt = -3.714, df = 97.572, p-value = 0.0003399\nalternative hypothesis: true difference in means between group 1 and group 3 is not equal to 0\n95 percent confidence interval:\n -2.1839829 -0.6628012\nsample estimates:\nmean in group 1 mean in group 3 \n      0.0688071       1.4921991 \n\n\nAs explained above, the tests we have done so far are “two-sided”. That means that the null hypothesis is that the two means are the same, and the alternative is that they are different.\n\\[\nH_0: \\mu_1 = \\mu_2\n\\]\n\\[\nH_a: \\mu_1 \\neq \\mu_2\n\\]\nBut sometimes, we have an a priori that the alternative is that one of the two means is larger. This is where we need a “one-sided” test.\nWe do this in R with the alternative option of the t.test function.\nRemember: to obtain the documentation about the t.test function, you can type ?t.test in the console.\nHow do we need to change the alternative option to perform the test corresponding to this pair of hypotheses ?\n\\[\\begin{align*}\nH_0:&\\  \\mu_1 \\geq \\mu_3 \\\\\nH_a:&\\  \\mu_1 &lt; \\mu_3 ( \\iff \\mu_1 - \\mu_3 &lt; 0 )\n\\end{align*}\\]\n\n\nCode\nt.test(value ~ dataset, data = X |&gt; filter(dataset %in% c(1,3)),\n       alternative = \"less\")\n\n\n\n    Welch Two Sample t-test\n\ndata:  value by dataset\nt = -3.714, df = 97.572, p-value = 0.0001699\nalternative hypothesis: true difference in means between group 1 and group 3 is less than 0\n95 percent confidence interval:\n       -Inf -0.7869575\nsample estimates:\nmean in group 1 mean in group 3 \n      0.0688071       1.4921991 \n\n\nHow do the \\(t\\) and \\(p\\) values compare in the two-sided vs one-sided test?\nWhy?\n\nQQ-plots: checking compatibility with a (normal) distribution\nRemember that the \\(t\\)-test requires, for small sample sizes, for the data to be drawn from a normal distribution. Usually, with real data, we don’t always know what distribution the data are samples from.\nWe can always check that our data is compatible with a normal distribution by performing a QQ-plot:\n\n\nCode\nexample_data &lt;- \n  tibble(norm = rnorm(20), lnorm = rlnorm(20))\n# just like `rnorm` samples from a normal distribution, \n# `runif` samples from a uniform distribution\n\ng_norm &lt;- \n  ggplot(example_data, aes(sample = norm)) +\n  geom_qq() +\n  geom_qq_line() +\n  ggtitle(\"Sampled from a\\nnormal distribution\")\n\n\ng_lnorm &lt;- \n  ggplot(example_data, aes(sample = lnorm)) +\n  geom_qq() +\n  geom_qq_line() +\n  ggtitle(\"Sampled from a\\n*log*normal distribution\")\n\ng_norm + g_lnorm\n\n\n\n\n\nWe see that, on the left plot, the dots are close to the line, and on the right plot, some dots are very far from the line. These dots far from the line are a warning that the distribution is probably not normal.\n\n\n\nImpact of sample size on p-values\n\nSmall dataset\nLet’s re-do our analysis but decrease the sample size to 10 samples per dataset.\n\n\nCode\n# another way to simulate data is to do the following\n# check what the expand_grid and rowwise function do\nX_small_sample &lt;- \n  expand_grid(\n    dataset = (1:3) |&gt; factor(), \n    sample = 1:10\n  ) %&gt;% \n  mutate(\n    pop_true_mean = ifelse(dataset == 3, 2, 0),\n    pop_true_var = 2\n  ) %&gt;% \n  rowwise() %&gt;% \n  mutate(\n    value = \n      rnorm(1, mean = pop_true_mean, sd = sqrt(pop_true_var))\n  ) %&gt;% \n  ungroup()\n\nX_small_sample |&gt; head() |&gt; pander()\n\n\n\n\n\n\n\n\n\n\n\n\ndataset\nsample\npop_true_mean\npop_true_var\nvalue\n\n\n\n\n1\n1\n0\n2\n0.3033\n\n\n1\n2\n0\n2\n-0.4592\n\n\n1\n3\n0\n2\n0.1338\n\n\n1\n4\n0\n2\n-1.266\n\n\n1\n5\n0\n2\n-1.854\n\n\n1\n6\n0\n2\n2.824\n\n\n\n\n\n\n\nCode\nggplot(X_small_sample, aes(x = value, fill = dataset)) +\n  geom_histogram(bins = 50) +\n  facet_grid(dataset ~ ., labeller = label_both) +\n  guides(fill = \"none\") + \n  theme(strip.text.y = element_text(angle = 0, hjust = 0)) \n\n\n\n\n\nWe can still use a \\(t\\)-test because we know that our samples are drawn from a Normal distribution.\n\n\nCode\nt.test(value ~ dataset, \n       data = X_small_sample |&gt; filter(dataset %in% c(1,3)))\n\n\n\n    Welch Two Sample t-test\n\ndata:  value by dataset\nt = -3.2548, df = 17.988, p-value = 0.004402\nalternative hypothesis: true difference in means between group 1 and group 3 is not equal to 0\n95 percent confidence interval:\n -3.4653702 -0.7465168\nsample estimates:\nmean in group 1 mean in group 3 \n      -0.377852        1.728091 \n\n\nWe see that the \\(p\\)-value is now much larger because, with the small datasets, we have a lot more uncertainty on the true means of the populations.\n\n\nLarge datasets\nLet’s now redo the same again but with a very large sample size for each dataset. For example N = 1000.\n\n\nCode\nX_large_sample &lt;- \n  expand_grid(\n    dataset = (1:3) |&gt; factor(), \n    sample = 1:1000\n    ) %&gt;% \n  mutate(\n    pop_true_mean = ifelse(dataset == 3, 2, 0),\n    pop_true_var = 2\n  ) %&gt;% \n  rowwise() %&gt;% \n  mutate(\n    value = \n      rnorm(1, mean = pop_true_mean, sd = sqrt(pop_true_var))\n  ) %&gt;% \n  ungroup()\n\nX_large_sample |&gt; head() |&gt; pander()\n\n\n\n\n\n\n\n\n\n\n\n\ndataset\nsample\npop_true_mean\npop_true_var\nvalue\n\n\n\n\n1\n1\n0\n2\n-0.8117\n\n\n1\n2\n0\n2\n0.874\n\n\n1\n3\n0\n2\n1.57\n\n\n1\n4\n0\n2\n1.001\n\n\n1\n5\n0\n2\n-0.5143\n\n\n1\n6\n0\n2\n0.0845\n\n\n\n\n\n\n\nCode\nggplot(X_large_sample, aes(x = value, fill = dataset)) +\n  geom_histogram(bins = 50) +\n  facet_grid(dataset ~ ., labeller = label_both) +\n  guides(fill = \"none\") + \n  theme(strip.text.y = element_text(angle = 0, hjust = 0)) \n\n\n\n\n\n\n\nCode\nt.test(value ~ dataset, \n       data = X_large_sample |&gt; filter(dataset %in% c(1,3)))\n\n\n\n    Welch Two Sample t-test\n\ndata:  value by dataset\nt = -30.732, df = 1997.9, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group 1 and group 3 is not equal to 0\n95 percent confidence interval:\n -2.075287 -1.826308\nsample estimates:\nmean in group 1 mean in group 3 \n     0.03031352      1.98111096 \n\n\nThe \\(p\\)-value is as small as it can be.\nLet’s also re-do the test comparing datasets 1 and 2\n\n\nCode\nt.test(value ~ dataset, \n       data = X_large_sample |&gt; filter(dataset %in% c(1,2)))\n\n\n\n    Welch Two Sample t-test\n\ndata:  value by dataset\nt = 0.075717, df = 1996.9, p-value = 0.9397\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -0.1186693  0.1282006\nsample estimates:\nmean in group 1 mean in group 2 \n     0.03031352      0.02554787 \n\n\nWe still don’t reject the null hypothesis, which is what we expect.\n\n\nClinical vs Statistical significance\nHowever, sometimes, we need to be careful with large sample sizes because tiny effects can still lead to very small p-values. However, these tiny effects don’t have much but these do not have much clinical relevance.\nLet’s verify that with a difference in means of 0.2\n\n\nCode\nt.test(\n  x = rnorm(1000, mean = 0.0, sd = 2),\n  y = rnorm(1000, mean = 0.2, sd = 2)\n)\n\n\n\n    Welch Two Sample t-test\n\ndata:  rnorm(1000, mean = 0, sd = 2) and rnorm(1000, mean = 0.2, sd = 2)\nt = -2.18, df = 1998, p-value = 0.02937\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.36547886 -0.01931448\nsample estimates:\n  mean of x   mean of y \n-0.02210611  0.17029056 \n\n\nThe \\(p\\)-value is lower than 1/20, but the effect (i.e., the mean in differences), compared to the standard deviations is very small.\nThis is what we are talking about when discussing the “clinical” vs “statistical” significance."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/module-6-hands-on.html#data-transformation",
    "href": "materials/1-workshop1/6-hypothesis-testing/module-6-hands-on.html#data-transformation",
    "title": "Data Science for Biology Workshop Series",
    "section": "Data transformation",
    "text": "Data transformation\nNow, let’s play with the datasets provided on the workshop website. Specifically, we are interested in analyzing the cytokines data.\n\nCytokine data exploration\nOur first task will be to display the distribution of the “IL-1\\(\\beta\\)” cytokine.\nTo do so, we load the cytokine data and filter for the cytokine of interest.\n\n\nCode\n# notice where I had stored my files.\n# Make sure to modify the path to your files\n\nelisa &lt;- \n  read_csv(\n    file = \"data/03_elisa_cytokines_UKZN_workshop_2023.csv\",\n    show_col_types = FALSE\n  )\n\nIL1b &lt;- elisa |&gt; filter(cytokine == \"IL-1b\") \n\n\nWe display its distribution with the geom_histogram function, and we can use the color (fill) option to flag whether the concentration value was within or out of the limits of detection.\n\n\nCode\ncytokine_lim_cols &lt;-\n  c(\"within limits\" = \"navy\", \"out of range\" = \"indianred1\")\n\nggplot(IL1b, aes(x = conc, fill = limits)) +\n  geom_histogram(bins = 30) +\n  ggtitle(\"IL-1b concentrations\") +\n  scale_fill_manual(values = cytokine_lim_cols)\n\n\n\n\n\nWhat do we observe?\nDo we think that the distribution of IL-1\\(\\beta\\) concentations follow a normal distribution?\nLet’s still check with a QQ-plot:\n\n\nCode\nggplot(\n  IL1b, \n  aes(sample = conc)\n) +\n  geom_qq_line() +\n  geom_qq(size = 0.75, alpha = 0.5)\n\n\n\n\n\nLook back at the QQ-plots we did earlier on simulated data. Does this QQ-plot look like one of the simulated one?\n\n\nLog-transformation\nLet’s now repeat the last two displays, using the log of the concentration instead of the concentration itself. Remember, we can use the mutate function to add a new variable to our data.frame.\n\n\nCode\nIL1b &lt;- IL1b |&gt; mutate(logconc = log10(conc))\n\n\n\n\nCode\nggplot(IL1b, aes(x = logconc, fill = limits)) +\n  geom_histogram(bins = 30) +\n  ggtitle(\"IL-1b concentrations (log 10)\") +\n  xlab(\"log10(conc)\") +\n  scale_fill_manual(values = cytokine_lim_cols)\n\n\n\n\n\nNow, the “within-range” data is more compatible with a Normal distribution.\nLet’s check with a QQ-plot:\n\n\nCode\nggplot(\n  IL1b, \n  aes(sample = logconc)\n) +\n  geom_qq_line() +\n  geom_qq(size = 0.75, alpha = 0.5) \n\n\n\n\n\nIt is not perfect, but it is much better.\n\n\nAssociation with BV\nNow, we are interested in testing whether a BV (Bacterial Vaginosis) diagnosis is associated with different mean concentrations of IL-1\\(\\beta\\).\nRemember, the BV diagnosis is contained in the Clinical Measurements table. So we first need to load that table in R.\n\n\nCode\nclin &lt;- \n  read_csv(\n    \"data/02_visit_clinical_measurements_UKZN_workshop_2023.csv\",\n    show_col_types = FALSE\n  )\n\n\nThe first 6 rows of the clinical data are:\n\n\nCode\nclin |&gt; head() |&gt; pander()\n\n\n\n\n\n\n\n\n\n\n\n\n\npid\ntime_point\narm\nnugent_score\ncrp_blood\nph\n\n\n\n\npid_01\nbaseline\nplacebo\n8\n0.44\n5.7\n\n\npid_01\nweek_1\nplacebo\n7\n1.66\n5.2\n\n\npid_01\nweek_7\nplacebo\n7\n1.44\n5.4\n\n\npid_02\nbaseline\nplacebo\n7\n1.55\n5.2\n\n\npid_02\nweek_1\nplacebo\n7\n0.75\n4.8\n\n\npid_02\nweek_7\nplacebo\n4\n1.17\n4.2\n\n\n\n\n\nThere are several ways to diagnose BV. One of them is to check whether a person has a Nugent score of 7 or more.\nLet’s create a new BV variable that says whether a person was diagnosed with BV at each visit.\n\n\nCode\nclin &lt;- \n  clin |&gt; \n  mutate(BV = ifelse(nugent_score &gt;= 7, \"BV\", \"Healthy\")) \n\n\nSince we want to compare the IL-1\\(\\beta\\) concentrations of individuals with or without BV, we need to join the clinical data with the IL-1\\(\\beta\\) concentration data.\nHint: to do so, we need a table describing how the sample IDs and participant x visit IDs are linked together - this info is in the “Sample ID” table.\n\n\nCode\nsample_info &lt;- \n  read_csv(\n    file = \"data/00_sample_ids_UKZN_workshop_2023.csv\",\n    show_col_types = FALSE\n  )\n\n\nThe first 6 rows of the sample info table are:\n\n\nCode\nsample_info |&gt; head() |&gt; pander()\n\n\n\n\n\n\n\n\n\n\n\npid\ntime_point\narm\nsample_id\n\n\n\n\npid_17\nbaseline\ntreatment\nSAMP001\n\n\npid_22\nweek_1\ntreatment\nSAMP002\n\n\npid_25\nweek_1\ntreatment\nSAMP003\n\n\npid_41\nweek_1\ntreatment\nSAMP004\n\n\npid_44\nweek_7\ntreatment\nSAMP005\n\n\npid_16\nweek_1\ntreatment\nSAMP006\n\n\n\n\n\nWe see that we can use the sample_id column to bind the cytokine concentrations with the sample_info table, then bind on the participant and visit ID with the clinical data.\n\n\nCode\nIL1b &lt;- \n  IL1b |&gt; \n  left_join(sample_info, by = join_by(sample_id)) |&gt; \n  left_join(clin, by = join_by(pid, time_point, arm))\n\n\nNow that our data are joined, let’s display the histogram of IL-1\\(\\beta\\) concentrations, including those out-of-range, colored by BV diagnosis.\n\n\nCode\nBV_colors &lt;- \n  c(\"BV\" = \"darkgoldenrod1\", \"Healthy\" = \"cornflowerblue\")\n\nggplot(\n  IL1b, #|&gt; filter(limits == \"within limits\"),\n  aes(x = logconc, fill = BV)\n) +\n  geom_histogram(bins = 30, alpha = 0.5, position = \"identity\") +\n  xlab(\"log10(conc)\") +\n  ggtitle(\"IL-1b concentration by BV diagnosis\") +\n  scale_fill_manual(values = BV_colors)\n\n\n\n\n\nFrom this visualization, it looks like the distribution is lower in healthy participants than in participants with BV.\nWhat do we think of the “out-of-range” values? Should we include them in our analysis?\nLet’s do a statistical test to see if these differences in concentrations could have happened by chance.\nSince our data, once log-transformed, look normal, (with the exclusion of the out-of-range samples) it makes sense to use a \\(t\\)-test. We can also check how many samples we have in each group to check if, regardless of the underlying distribution, there are enough samples to use a \\(t\\)-test.\n\n\nCode\nIL1b |&gt; \n  select(BV) |&gt; \n  table()\n\n\nBV\n     BV Healthy \n     46      86 \n\n\nWe have many samples, so we could, regardless of the underlying distribution, use a \\(t\\)-test.\n\n\nCode\nt.test(logconc ~ BV, data = IL1b)\n\n\n\n    Welch Two Sample t-test\n\ndata:  logconc by BV\nt = 6.5449, df = 116.4, p-value = 1.672e-09\nalternative hypothesis: true difference in means between group BV and group Healthy is not equal to 0\n95 percent confidence interval:\n 0.5332052 0.9959381\nsample estimates:\n     mean in group BV mean in group Healthy \n            1.1245273             0.3599557 \n\n\nWhat do you conclude?"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/module-6-hands-on.html#non-parametric-tests",
    "href": "materials/1-workshop1/6-hypothesis-testing/module-6-hands-on.html#non-parametric-tests",
    "title": "Data Science for Biology Workshop Series",
    "section": "Non-parametric tests",
    "text": "Non-parametric tests\nSo far, we could use the \\(t\\)-test to make inference on the means of different populations because we either had more than 40 samples in each group or we observed or knew that the samples were drawn from a normal distribution.\nSo, when our data is small and does not appear to be drawn from a normal distribution, we cannot use the \\(t\\)-test that assumes normality of the underlying data or requires large enough sample sizes.\nThe \\(t\\)-test is part of the family of parametric tests because they assume that the underlying data follows a specific distribution which can be characterized by parameters. For example, the parameters of a normal distribution are the mean and the variance.\nThere are also non-parametric tests which makes no assumption on the distribution of the data.\n\nThe Wilcoxon rank-sum test\nThe Wilcoxon rank-sum test is a non-parametric test to compare two independent datasets. The null hypothesis is that, for randomly selected values \\(X\\) and \\(Y\\) from two populations, the probability of \\(X\\) being greater than \\(Y\\) is equal to the probability of \\(Y\\) being greater than \\(X\\) (see Wikipedia), regardless of the distribution \\(X\\) and \\(Y\\) are drawn from.\nLet’s try the test on our small dataset:\n\n\nCode\nwilcox.test(value ~ dataset, \n            data = X_small_sample |&gt; filter(dataset %in% c(1,3)))\n\n\n\n    Wilcoxon rank sum exact test\n\ndata:  value by dataset\nW = 13, p-value = 0.003886\nalternative hypothesis: true location shift is not equal to 0\n\n\nAnd compare it to the \\(t\\)-test (we can because we know this data is drawn from a Normal).\n\n\nCode\nt.test(value ~ dataset, \n       data = X_small_sample |&gt; filter(dataset %in% c(1,3)))\n\n\n\n    Welch Two Sample t-test\n\ndata:  value by dataset\nt = -3.2548, df = 17.988, p-value = 0.004402\nalternative hypothesis: true difference in means between group 1 and group 3 is not equal to 0\n95 percent confidence interval:\n -3.4653702 -0.7465168\nsample estimates:\nmean in group 1 mean in group 3 \n      -0.377852        1.728091 \n\n\nWe see that both provides small probabilites to observe the data under the null hypothesis.\nSo, why not always using a non-parametric test if they work in all situations and not worry about normality of the data?\nBecause, non-parametric tests have less power to detect small effects.\nTo check that, we can rely on simulations.\nHere, we simulate 1000 times two small datasets of 10 samples with a relatively small difference between their means (relative to the standard deviation) and perform both a \\(t\\) test and a Wilcoxon rank sum test.\nWe then count how many times each test rejected the null (as they should) and see if one of the two tests reject more often.\n\n\nCode\nset.seed(123)\nsimulate_and_run_both_test &lt;- function(){\n  x1 &lt;- rnorm(10, mean = 0, sd = 2)\n  x2 &lt;- rnorm(10, mean = 1.5, sd = 2)\n  \n  ttest &lt;- t.test(x1, x2)\n  wtest &lt;- wilcox.test(x1, x2)\n  tibble(ttest_pvalue = ttest$p.value, wtest_pvalue = wtest$p.value)\n}\n\nsimulation_results &lt;- replicate(1000, simulate_and_run_both_test())\n\napply(simulation_results &lt;= 0.05, 2, mean)\n\n\nttest_pvalue wtest_pvalue \n       0.354        0.319 \n\n\nWe see that the \\(t\\)-test more frequently detected that the two samples were drawn from distribution with different means/locations."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/module-6-hands-on.html#multiple-testing",
    "href": "materials/1-workshop1/6-hypothesis-testing/module-6-hands-on.html#multiple-testing",
    "title": "Data Science for Biology Workshop Series",
    "section": "Multiple testing",
    "text": "Multiple testing\n\nSimulations\nAs we discussed above, the \\(p\\)-value of a test is the probability, under the null hypothesis, to observe a value of the test statistics as extreme as the one we observe. Usually, if that probability is less than 0.05 (we have less than one/20 chances to observe that value), we reject the null hypothesis.\nSo, if we repeat a test many many times on data generated under the null hypothesis (so we should not reject it), we will obtain a small \\(p\\)-value a few times.\nTo verify this, let’s do a simulation experiment and repeat the following procedure a 1000 times: we draw two small datasets from that same population (= the null hypothesis is true) and perform a \\(t\\)-test. In theory, we should get 0.05 x 1000 = 50 experiments with a \\(p\\)-value smaller than 0.05.\n\n\nCode\nsimulate_and_test &lt;- function(){\n  x1 &lt;- rnorm(10)\n  x2 &lt;- rnorm(10) # same mean\n  ttest &lt;- t.test(x1, x2)\n  ttest$p.value # we return the p-value\n}\n\nnull_p.values &lt;- replicate(1000, simulate_and_test())\n\n\nLet’s count how many times we have a p-value smaller than 0.05 under the null hypothesis:\n\n\nCode\nsum(null_p.values &lt; 0.05)\n\n\n[1] 52\n\n\nWhich corresponds to a rate of\n\n\nCode\nmean(null_p.values &lt; 0.05)\n\n\n[1] 0.052\n\n\nwhich is, indeed, very close to the \\(p\\)-value threshold that we’ve selected.\nThis is because, under the null hypothesis, the distribution of \\(p\\)-values is uniform:\n\n\nCode\nnull_p.values_tbl &lt;- tibble(p_values = null_p.values)\n\nggplot(null_p.values_tbl, aes(x = p_values)) +\n  geom_histogram(bins = 20)\n\n\n\n\n\nThis is a good opportunity to learn how to perform a QQ-plot for another distribution than the Normal distribution. Here, to check that the p-values follow a uniform distribution, we can use the distribution argument from the geom_qq functions and do the following QQ-plot:\n\n\nCode\nggplot(null_p.values_tbl, aes(sample = p_values)) +\n  geom_qq_line(distribution = qunif) +\n  geom_qq(distribution = qunif, size = 0.5, alpha = 0.5)\n\n\n\n\n\nThis is very convincing that the \\(p\\)-values under the null follow a uniform distribution.\nNow, let’s come back to the interpretation/consequences of this uniform distribution: if the distribution of \\(p\\)-values under the Null is uniform, this means that we will reject the null hypothesis with a rate of \\(\\alpha\\) if \\(\\alpha\\) is the rejection threshold.\nThis will also apply to real data if we perform the same test several times.\nFor example, let’s say that we were interested in not just IL-1\\(\\beta\\) but all cytokines and are to repeat the \\(t\\)-test we did above for all cytokines, since we have 10 of them, it’s not unlikely that we’d have small \\(p\\)-values just by chance.\nSo, whenever we do “multiple testing”, we need to adjust for that multiple testing.\nThere are several ways to do “multiple testing adjustments” but the explanations of these methods are outside the scope of this class. Many of these methods have conveniently been implemented in the p.adjust function.\nOne of these methods that “controls for the”false discovery rate” is the Benjamini-Hochberg adjustment.\nLet’s apply it to our simulated \\(p\\)-values and check now how many samples are still considered to have a significant adjusted \\(p\\)-value:\n\n\nCode\nnull_p.values_tbl &lt;- \n  null_p.values_tbl |&gt; \n  mutate(q_values = p.adjust(p_values, method = \"BH\"))\n\n\nmean(null_p.values_tbl$q_values &lt;= 0.05)\n\n\n[1] 0\n\n\nNone of them!\nWhich is what it should be as we simulated our data under the null hypothesis, we should never reject the Null.\n\n\nCode\nggplot(null_p.values_tbl, aes(x = q_values)) +\n  geom_histogram(bins = 20) +\n  expand_limits(x = 0) +\n  xlab(\"BH adjusted p-values\")\n\n\n\n\n\n\n\nCytokines\nLet’s now test which cytokines have different means in BV and non-BV study participants.\nFirst, we need to take the log-concentration of all cytokines and join with the clinical data via the “sample info”.\n\n\nCode\nelisa &lt;- \n  elisa |&gt; \n  mutate(logconc = log10(conc)) |&gt; \n  left_join(sample_info, by = join_by(sample_id)) |&gt; \n  left_join(clin, by = join_by(pid, time_point, arm))\n\n\nWe can also display concentration by BV status for each cytokine:\n\n\nCode\nelisa |&gt; \n  ggplot(aes(x = logconc, fill = BV)) +\n  geom_histogram(bins = 30, position = \"identity\", alpha = 0.5) +\n  facet_wrap(cytokine ~ .) +\n  xlab('log10(concentrations)') +\n  scale_fill_manual(values = BV_colors)\n\n\n\n\n\nAnother way to look at this is to display the data as “boxplot”:\n\n\nCode\nelisa |&gt; \n  ggplot(aes(y = logconc, fill = BV, col = BV, x = cytokine)) +\n  geom_boxplot(varwidth = TRUE, outlier.size = 0.5, alpha = 0.5) +\n  scale_fill_manual(values = BV_colors) +\n  scale_color_manual(values = BV_colors)\n\n\n\n\n\nLooking at these visual displays of the data. Do you think it makes sense to do the test for all cytokines? What about cytokines that have a lot of samples with concentrations lower than the limit of detection?\nShould we exclude these cytokines? Remove the out-of-range values? Or keep them?\nIdeally, we would only want to do the test for variables where we are confident that we have representative samples.\nThere is a little bit of subjectivity in terms of what we deem representative, but, for now, let’s say that we want the 1st and 3rd quartile to be within the range of detection for each cytokine and each group.\nLet’s thus compute the 1st and 3rd quartiles (or, equivalently the 25th and 75th percentiles) for each cytokines and each group:\n\n\nCode\ninterquartiles &lt;- \n  elisa |&gt; \n  # we also need to compute the LLOQ and ULOQ for each cytokine\n  group_by(cytokine) |&gt; \n  mutate(LLOQ = min(logconc), ULOQ = max(logconc)) |&gt;\n  group_by(cytokine, LLOQ, ULOQ, BV) |&gt; \n  summarize(\n    `1st quartile` = quantile(logconc, 0.25),\n    `3rd quartile` = quantile(logconc, 0.75)\n  ) \n\n\n`summarise()` has grouped output by 'cytokine', 'LLOQ', 'ULOQ'. You can\noverride using the `.groups` argument.\n\n\nCode\ninterquartiles |&gt; \n  pander()\n\n\n\n\n\n\n\n\n\n\n\n\n\ncytokine\nLLOQ\nULOQ\nBV\n1st quartile\n3rd quartile\n\n\n\n\nIFN-Y\n-0.4641\n1.369\nBV\n-0.4641\n-0.1024\n\n\nIFN-Y\n-0.4641\n1.369\nHealthy\n-0.4641\n-0.4641\n\n\nIL-10\n-0.1152\n1.482\nBV\n-0.1152\n0.3345\n\n\nIL-10\n-0.1152\n1.482\nHealthy\n-0.1152\n-0.1152\n\n\nIL-1a\n0.143\n3.011\nBV\n1.681\n2.238\n\n\nIL-1a\n0.143\n3.011\nHealthy\n1.067\n1.976\n\n\nIL-1b\n-0.6012\n2.347\nBV\n0.8021\n1.334\n\n\nIL-1b\n-0.6012\n2.347\nHealthy\n-0.2347\n0.9864\n\n\nIL-6\n-1.029\n2.238\nBV\n0.08762\n0.7945\n\n\nIL-6\n-1.029\n2.238\nHealthy\n-0.364\n0.6946\n\n\nIL-8\n-0.3279\n3.398\nBV\n2.164\n2.916\n\n\nIL-8\n-0.3279\n3.398\nHealthy\n1.575\n2.71\n\n\nIP-10\n-0.5157\n3.699\nBV\n-0.5157\n0.06446\n\n\nIP-10\n-0.5157\n3.699\nHealthy\n-0.1079\n1.945\n\n\nMIG\n0.1872\n4.398\nBV\n0.1872\n1.07\n\n\nMIG\n0.1872\n4.398\nHealthy\n0.6586\n2.023\n\n\nMIP-3a\n0.7137\n2.516\nBV\n0.7137\n0.7137\n\n\nMIP-3a\n0.7137\n2.516\nHealthy\n0.7137\n1.168\n\n\nTNFa\n-0.327\n1.631\nBV\n-0.327\n0.5051\n\n\nTNFa\n-0.327\n1.631\nHealthy\n-0.327\n0.1446\n\n\n\n\n\nLet’s filter for cytokines with an interquartile range within the limits of quantification for both groups:\n\n\nCode\ninterquartiles |&gt; \n  filter(\n    `1st quartile` &gt; LLOQ,\n    `3rd quartile` &lt; ULOQ\n  ) |&gt; \n  group_by(cytokine) |&gt;\n  summarize(n = n(), .groups = \"drop\") |&gt; \n  filter(n == 2) |&gt;\n  pander()\n\n\n\n\n\n\n\n\n\ncytokine\nn\n\n\n\n\nIL-1a\n2\n\n\nIL-1b\n2\n\n\nIL-6\n2\n\n\nIL-8\n2\n\n\n\n\n\nThat only leaves us with 4 cytokines. Our criteria might be a little too stringent, and, as long as you justify it properly, you could loosen these criteria. We just want to make sure that you always take a critical look at your data before running a test.\nWe will now filter our data to only keep these 4 cytokines and perform a statistical test for each of theses.\n\n\nCode\nttest_res &lt;- \n  elisa |&gt; \n  group_by(cytokine) |&gt; \n  filter(\n    cytokine %in% c(\"IL-1a\",\"IL-1b\", \"IL-6\", \"IL-8\")\n  ) |&gt;\n  summarize(\n    `p-value` = t.test(logconc ~ BV)$p.value,\n    `p &lt; 0.05` = ifelse(`p-value` &lt; 0.05, \"yes\", \"\")\n  ) \n\nttest_res |&gt; pander()\n\n\n\n\n\n\n\n\n\n\ncytokine\np-value\np &lt; 0.05\n\n\n\n\nIL-1a\n8.492e-08\nyes\n\n\nIL-1b\n1.672e-09\nyes\n\n\nIL-6\n0.08282\n\n\n\nIL-8\n0.00825\nyes\n\n\n\n\n\nWe see that 3/4 cytokines have p-values smaller than 0.05. But remember, we need to adjust for multiple testing.\n\n\nCode\nttest_res &lt;- \n  ttest_res |&gt; \n  mutate(\n    `adj. p-value` = p.adjust(`p-value`, method = \"BH\"),\n    `statistical\\nsignificance` = \n      ifelse(`adj. p-value` &lt; 0.05, \"yes\",\"\")\n  )\n\n\nttest_res |&gt; pander()\n\n\n\n\n\n\n\n\n\n\n\n\ncytokine\np-value\np &lt; 0.05\nadj. p-value\nstatistical significance\n\n\n\n\nIL-1a\n8.492e-08\nyes\n1.698e-07\nyes\n\n\nIL-1b\n1.672e-09\nyes\n6.689e-09\nyes\n\n\nIL-6\n0.08282\n\n0.08282\n\n\n\nIL-8\n0.00825\nyes\n0.011\nyes\n\n\n\n\n\nThe three cytokines that had a p-value smaller than 0.05 are still significant after adjusting for multiple testing.\nRedo this analysis, but with a less stringent criteria for representativeness. For example, let’s only request from our cytokines that their 1st and 3rd quartiles are different.\n\n\nCode\nselected_cytokines &lt;- \n  interquartiles |&gt; \n  filter(\n    `1st quartile` &lt; `3rd quartile`\n  ) |&gt; \n  group_by(cytokine) |&gt;\n  summarize(n = n(), .groups = \"drop\") |&gt; \n  filter(n == 2) |&gt;\n  select(cytokine) |&gt; unlist()\n\nselected_cytokines\n\n\ncytokine1 cytokine2 cytokine3 cytokine4 cytokine5 cytokine6 cytokine7 \n  \"IL-1a\"   \"IL-1b\"    \"IL-6\"    \"IL-8\"   \"IP-10\"     \"MIG\"    \"TNFa\" \n\n\n\n\nCode\nttest_res &lt;- \n  elisa |&gt; \n  filter(cytokine %in% selected_cytokines) |&gt; \n  group_by(cytokine) |&gt;\n  summarize(\n    `p-value` = t.test(logconc ~ BV)$p.value,\n    `p &lt; 0.05` = ifelse(`p-value` &lt; 0.05, \"yes\", \"\")\n  )  |&gt; \n  mutate(\n    `adj. p-value` = p.adjust(`p-value`, method = \"BH\"),\n    `statistical\\nsignificance` = \n      ifelse(`adj. p-value` &lt; 0.05, \"yes\",\"\")\n  )\n\n\nttest_res |&gt; pander()\n\n\n\n\n\n\n\n\n\n\n\n\ncytokine\np-value\np &lt; 0.05\nadj. p-value\nstatistical significance\n\n\n\n\nIL-1a\n8.492e-08\nyes\n1.486e-07\nyes\n\n\nIL-1b\n1.672e-09\nyes\n5.853e-09\nyes\n\n\nIL-6\n0.08282\n\n0.08282\n\n\n\nIL-8\n0.00825\nyes\n0.01155\nyes\n\n\nIP-10\n1.974e-12\nyes\n1.381e-11\nyes\n\n\nMIG\n4.902e-08\nyes\n1.144e-07\nyes\n\n\nTNFa\n0.02701\nyes\n0.03151\nyes\n\n\n\n\n\nWhat do you conclude from this analysis?\nAs an exercise, you can also re-do the analyses using a non-parametric test and discuss the differences in the results."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/module-6-hands-on.html#displaying-longitudinal-data",
    "href": "materials/1-workshop1/6-hypothesis-testing/module-6-hands-on.html#displaying-longitudinal-data",
    "title": "Data Science for Biology Workshop Series",
    "section": "Displaying longitudinal data",
    "text": "Displaying longitudinal data\nSo far, we have ignore the fact that we have longitudinal data.\nRemember the study design:\n\n\n\n\n\nWe have 3 time points for each patient. We can thus look at the evolution of the cytokine concentrations over time.\nWe have already joined the elisa data with the sample_info data so we already have the participant id and the visit id for all cytokine samples:\n\n\nCode\nelisa |&gt;  head() |&gt; pander()\n\n\n\nTable continues below\n\n\n\n\n\n\n\n\n\n\n\nsample_id\ncytokine\nconc\nlimits\nlogconc\npid\ntime_point\n\n\n\n\nSAMP094\nIL-1a\n173.9\nwithin limits\n2.24\npid_01\nbaseline\n\n\nSAMP094\nIL-10\n0.767\nout of range\n-0.1152\npid_01\nbaseline\n\n\nSAMP094\nIL-1b\n5.39\nwithin limits\n0.7316\npid_01\nbaseline\n\n\nSAMP094\nIL-8\n48.29\nwithin limits\n1.684\npid_01\nbaseline\n\n\nSAMP094\nIL-6\n5.07\nwithin limits\n0.705\npid_01\nbaseline\n\n\nSAMP094\nTNFa\n0.471\nout of range\n-0.327\npid_01\nbaseline\n\n\n\n\n\n\n\n\n\n\n\n\n\narm\nnugent_score\ncrp_blood\nph\nBV\n\n\n\n\nplacebo\n8\n0.44\n5.7\nBV\n\n\nplacebo\n8\n0.44\n5.7\nBV\n\n\nplacebo\n8\n0.44\n5.7\nBV\n\n\nplacebo\n8\n0.44\n5.7\nBV\n\n\nplacebo\n8\n0.44\n5.7\nBV\n\n\nplacebo\n8\n0.44\n5.7\nBV\n\n\n\n\n\nBefore jumping into the visualization, let’s do some data wrangling.\nFirst, let’s do some cosmetic changes to the time_point column so that the visits labels print nicely when using ggplot.\nTo replace the “_” with a space, we can use the str_replace function from the stringr package.\nBefore:\n\n\nCode\nelisa$time_point |&gt; unique()\n\n\n[1] \"baseline\" \"week_1\"   \"week_7\"  \n\n\n\n\nCode\nelisa &lt;- \n  elisa |&gt; \n  mutate(time_point = time_point |&gt; str_replace(\"_\", \" \"))\n\n\nAfter:\n\n\nCode\n# let's check that it worked\nelisa$time_point |&gt; unique()\n\n\n[1] \"baseline\" \"week 1\"   \"week 7\"  \n\n\nThen, let’s transform all the variables that are character but should be factors to … factor.\n\n\nCode\nelisa &lt;- \n  elisa |&gt; \n  mutate(\n    sample_id = sample_id |&gt; factor(),\n    cytokine = cytokine |&gt; factor(),\n    pid = pid |&gt; factor(),\n    time_point =time_point |&gt; factor(),\n    arm = arm |&gt; factor(),\n    limits = limits |&gt; factor()\n    )\n\n\nNow, we can display the IL-1\\(\\beta\\) log-concentrations over-time, connecting the concentrations of a given participant by a line.\nNote the use of the group aesthetic in geom_line to tell ggplot to connect the points of the same participant.\nCheck what happens if you remove aes(group = pid) from geom_line.\n\n\nCode\narm_color &lt;- \n  c(\"placebo\" = \"deeppink\", \"treatment\" = \"steelblue1\")\n\nelisa |&gt; \n  filter(cytokine == \"IL-1b\") |&gt; \n  ggplot(aes(x = time_point, y = logconc, color = arm)) +\n  geom_line(aes(group = pid), alpha = 0.75) +\n  geom_point(alpha = 0.5) +\n  xlab(\"Visits\") +\n  ylab(\"log10(IL-1b concentration)\") +\n  scale_color_manual(\"Arm\", values = arm_color)\n\n\n\n\n\n\nPaired tests\nOne question that this study may have aimed to answer is whether treatment altered how the cytokine concentrations changed over time.\nSpecifically, we may have been interested in comparing the changes between the baseline visit and the week 7 visit.\nLet’s do the same visualization, but excluding week 1:\n\n\nCode\nelisa |&gt; \n  filter(cytokine == \"IL-1b\", time_point != \"week 1\") |&gt; \n  ggplot(aes(x = time_point, y = logconc, color = arm)) +\n  geom_line(aes(group = pid), alpha = 0.75) +\n  geom_point(alpha = 0.5) +\n  xlab(\"Visits\") +\n  ylab(\"log10(IL-1b concentration)\") +\n  scale_color_manual(\"Arm\", values = arm_color)\n\n\n\n\n\nWe see that everyone starts with a different level of IL-1b and the ranking in the baseline visit is somewhat similar to the ranking in the week 7 visit, especially in the treatment arm.\nTo test this specifically, we can do a “paired test”.\nIt is “paired” because for each observation at the baseline visit, there is a “sister” observation at the week 7 visit (= the sample from the same participant).\nHere, because we have many samples, we can use a paired \\(t\\)-test, but if we had only one sample per participant, we would have to use a paired Wilcoxon test.\nIn a “real” analysis, we would only do one of the two tests, but for demonstration purposes, let’s do both (without adjusting for multiple testing because it’s just illustrative).\n\n\nCode\nelisa |&gt; \n  filter(cytokine == \"IL-1b\", time_point != \"week 1\") |&gt; \n  select(cytokine, arm, pid, time_point, logconc) |&gt;\n  pivot_wider(names_from = time_point, values_from = logconc) |&gt;\n  group_by(arm) |&gt; \n  summarize(\n    `p (t-test)` = \n      t.test(x = baseline, y = `week 7`, paired = TRUE)$p.value,\n    `p (signed rank)` = \n      wilcox.test(x = baseline, y = `week 7`, paired = TRUE)$p.value\n  ) |&gt; \n  mutate(\n    `p &lt; 0.05 (t)` = ifelse(`p (t-test)` &lt; 0.05, \"yes\", \"\"),\n    `p &lt; 0.05 (w)` = ifelse(`p (signed rank)` &lt; 0.05, \"yes\", \"\")\n  ) |&gt; \n  pander()\n\n\nWarning: There was 1 warning in `summarize()`.\nℹ In argument: `p (signed rank) = wilcox.test(x = baseline, y = `week 7`,\n  paired = TRUE)$p.value`.\nℹ In group 2: `arm = treatment`.\nCaused by warning in `wilcox.test.default()`:\n! cannot compute exact p-value with ties\n\n\n\n\n\n\n\n\n\n\n\n\narm\np (t-test)\np (signed rank)\np &lt; 0.05 (t)\np &lt; 0.05 (w)\n\n\n\n\nplacebo\n0.3998\n0.41\n\n\n\n\ntreatment\n0.0007528\n0.001226\nyes\nyes\n\n\n\n\n\nWe see that the two tests agree in this case (as they should because the effects are quite large in the treatment arm).\nExercise: repeat the same visualization and analysis for IL-6 and IL-8. Do you need to adjust for multiple testing?"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/module-6-hands-on.html#compositional-data",
    "href": "materials/1-workshop1/6-hypothesis-testing/module-6-hands-on.html#compositional-data",
    "title": "Data Science for Biology Workshop Series",
    "section": "Compositional data",
    "text": "Compositional data\nMultivariate data are said to be “compositional” when they are expressed in terms of proportion of a sample.\nThe problem with compositional data is that they are constrained to sum to 1, so that the values of the different variables are not independent.\nWhich means that if only one variable changes in absolute value (unknown), in relative values (known), the others will change too.\nFor example, if we have 3 cell sub-types: A, B, and C.\nIn one sample, we have 102 cells A, 72 cells B, and 147 cell C.\nIn code, we would write:\n\n\nCode\nsample_1 &lt;- c(\"A\" = 102, \"B\" = 72, \"C\" = 147)\nsample_1\n\n\n  A   B   C \n102  72 147 \n\n\nCode\n# note: usually we define vectors with just their values, like this: c(102, 72, 147), but we can also give names to each element of the vector as we did above\n\n\nIn another sample, we have the same number of cells A and B, but we have 62 additional cells C.\n\n\nCode\nsample_2 &lt;- sample_1 \nsample_2[\"C\"] &lt;- sample_2[\"C\"] + 62\n\n# the two lines above do the following: we create sample_2 as a copy of sample_1. Then, we only modify the \"C\" element of sample_2 and we add 62 to the value that was already there.\n\n\nNow, we can compute the proportions of each cell type in each sample:\n\n\nCode\nprop_1 &lt;- sample_1 / sum(sample_1)\n\nprop_2 &lt;- sample_2 / sum(sample_2)\n\n\nAnd display them:\n\n\nCode\nprop_1 |&gt; round(digits = 2) # the `round` function rounds the number. The `digit` argument specifies the number of digits to keep after the decimal point. Try with digits = 0 or digits = 4 to see the difference in output.\n\n\n   A    B    C \n0.32 0.22 0.46 \n\n\nCode\nprop_2 |&gt; round(digits = 2)\n\n\n   A    B    C \n0.27 0.19 0.55 \n\n\nWe see that the proportion of C has increased (because there are more cells) and consequently, the proportions of A and B have decreased (even though there were the same number of cells).\n\nFlow cytometry data\nFor now, let’s explore the flow cytometry data.\n\n\nCode\nflow &lt;- \n  read_csv(\n    \"data/04_flow_cytometry_UKZN_workshop_2023.csv\"\n    )\n\n\nRows: 132 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): sample_id\ndbl (9): live_cd19_negative, cd45_negative, cd45_positive, neutrophils, non_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe have one row per sample. And remember, we have three sample per patient (one for each visit).\nOne of the first things we observe is that all columns (except sample_id) are (large) integer numbers. We say that we have “count data”.\nRemember, that these are the number of cells observed in each “gating” categories. Also, remember that some cell categories are subset of other categories.\nFor example, “live CD19-” cells are roughly divided into “CD45+” and “CD45-” cells.\n\n\nCode\nggplot(flow, \n       aes(y = live_cd19_negative, \n           x = cd45_positive + cd45_negative)\n       ) +\n  geom_abline(intercept = 0, slope = 1, col = \"purple1\") +\n  geom_point(alpha = 0.5) +\n  scale_x_log10() +\n  scale_y_log10()\n\n\n\n\n\nAnd “CD3+” are roughly divided into “CD4 T” and “CD8 T” cells.\n\n\nCode\nggplot(flow, \n       aes(x = cd3_positive, \n           y = cd4_t_cells + cd8_t_cells)\n       ) +\n  geom_abline(intercept = 0, slope = 1, col = \"purple1\") +\n  geom_point(alpha = 0.5) +\n  scale_x_log10() +\n  scale_y_log10()\n\n\n\n\n\nSo, if we show the fraction of “CD4 T” cells against that of “CD8 T” cells among all T cells (the “CD3+” cells).\n\n\nCode\nggplot(flow, \n       aes(x = cd4_t_cells/cd3_positive, \n           y = cd8_t_cells/cd3_positive )\n       ) +\n  geom_point(alpha = 0.5) +\n  xlab(\"CD4 T cells (fraction of all T cells)\") +\n  ylab(\"CD8 T cells (fraction of all T cells)\")\n\n\n\n\n\nWe see that we have a negative correlation: when the proportion of CD8 T cells increases, the proportion of CD4 T cells decreases.\nWhat are the consequences of that?\nLet’s say that we are interested in looking at the treatment effect on the proportion of different T cell sub-types. If we were to forget that these were compositional data, we could do the same as what we did for the cytokines, and perform a test for each cell sub-type.\nBut since we know that they are anti-correlated, if there is an effect on one sub-type, there might be an opposite effect on the other sub-type.\nLet’s see if that’s the case.\nFirst, let’s create a simplified flow cytometry table with just the T cell data and compute the proportion of the CD4 and CD8 T cells.\n\n\nCode\nflow_T &lt;- \n  flow |&gt; \n  select(sample_id, cd4_t_cells, cd8_t_cells, cd3_positive) |&gt;\n  mutate(\n    cd4_t_cells_f = cd4_t_cells/cd3_positive,\n    cd8_t_cells_f = cd8_t_cells/cd3_positive,\n    sum = cd4_t_cells_f + cd8_t_cells_f,\n    remaining_t_cells_f = 1 - sum\n    ) \n\nhead(flow_T) |&gt; pander()\n\n\n\nTable continues below\n\n\n\n\n\n\n\n\n\nsample_id\ncd4_t_cells\ncd8_t_cells\ncd3_positive\ncd4_t_cells_f\n\n\n\n\nSAMP094\n409\n444\n988\n0.414\n\n\nSAMP052\n7126\n6009\n15078\n0.4726\n\n\nSAMP017\n36212\n13434\n53758\n0.6736\n\n\nSAMP046\n2872\n2629\n6254\n0.4592\n\n\nSAMP025\n6384\n3039\n11355\n0.5622\n\n\nSAMP050\n2405\n1310\n4076\n0.59\n\n\n\n\n\n\n\n\n\n\n\ncd8_t_cells_f\nsum\nremaining_t_cells_f\n\n\n\n\n0.4494\n0.8634\n0.1366\n\n\n0.3985\n0.8711\n0.1289\n\n\n0.2499\n0.9235\n0.07649\n\n\n0.4204\n0.8796\n0.1204\n\n\n0.2676\n0.8299\n0.1701\n\n\n0.3214\n0.9114\n0.08857\n\n\n\n\n\nWe also computed the sum of the fractions of the CD4 and CD8 T cells and see that this sum is not always 1. That means that some cells are not CD4 or CD8 T cells. The distribution of the sum of their fraction goes as:\n\n\nCode\nggplot(flow_T, aes(x = sum)) +\n  geom_histogram(bins = 30) +\n  geom_vline(xintercept = 1, col = \"red\", linetype = 2) +\n  xlab(\"sum of the fractions of CD4 and CD8 T cells\") \n\n\n\n\n\nAs said above, one question we may have is whether the proportions of CD4 and CD8 T cells are different between the two arms at the end of the intervention.\nTo be able to answer this question, we first need to join the flow cytometry data with the sample information (the sample_info table) so we know which sample is from which visit and which participant and their arm.\n\n\nCode\nflow_T_with_info &lt;- \n  flow_T |&gt; \n  left_join(sample_info, by = \"sample_id\")\n\nflow_T_with_info |&gt; head() |&gt; pander()\n\n\n\nTable continues below\n\n\n\n\n\n\n\n\n\nsample_id\ncd4_t_cells\ncd8_t_cells\ncd3_positive\ncd4_t_cells_f\n\n\n\n\nSAMP094\n409\n444\n988\n0.414\n\n\nSAMP052\n7126\n6009\n15078\n0.4726\n\n\nSAMP017\n36212\n13434\n53758\n0.6736\n\n\nSAMP046\n2872\n2629\n6254\n0.4592\n\n\nSAMP025\n6384\n3039\n11355\n0.5622\n\n\nSAMP050\n2405\n1310\n4076\n0.59\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncd8_t_cells_f\nsum\nremaining_t_cells_f\npid\ntime_point\narm\n\n\n\n\n0.4494\n0.8634\n0.1366\npid_01\nbaseline\nplacebo\n\n\n0.3985\n0.8711\n0.1289\npid_01\nweek_1\nplacebo\n\n\n0.2499\n0.9235\n0.07649\npid_01\nweek_7\nplacebo\n\n\n0.4204\n0.8796\n0.1204\npid_02\nbaseline\nplacebo\n\n\n0.2676\n0.8299\n0.1701\npid_02\nweek_1\nplacebo\n\n\n0.3214\n0.9114\n0.08857\npid_02\nweek_7\nplacebo\n\n\n\n\n\nLet’s now display the proportions of these cells at the week 7 visit:\n\n\nCode\nflow_T_with_info_long &lt;- \n  flow_T_with_info |&gt; \n  select(sample_id, pid, time_point, arm, ends_with(\"_f\")) |&gt; \n  pivot_longer(\n    cols = ends_with(\"_f\"),\n    names_to = \"cell_type\",\n    values_to = \"fraction of T cells\"\n    )\n  \nflow_T_with_info_long |&gt; \n  ggplot(aes(x = cell_type, y = `fraction of T cells`,\n             fill = arm)) +\n  geom_boxplot() +\n  scale_fill_manual(values = arm_color) \n\n\n\n\n\nIt looks like there might be some differences: a lower proportion of CD4 T cells in the intervention arm than in the placebo arm and and slightly higher proportions in the two others.\nBut from these compositional data, it is impossible to know if one of the cell type is driving these effects or if it is a combination of several changes in each cell types.\nOne could still do a test to see if the proportions are different in the two arms, but this is outside the scope of this workshop. Come back to the next ones for more :)"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#section",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#section",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "",
    "text": "Workshop materials are at:\nhttps://elsherbini.github.io/durban-data-science-for-biology/"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#hello",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#hello",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Hello! 👋👋",
    "text": "Hello! 👋👋\nMy name is Laura Symul.\n🎓 I am an assistant professor in non-clinical biostatistics at the University of Louvain in Belgium.\n💙 I love statistics AND climbing, hiking, and painting."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#section-1",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#section-1",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "",
    "text": "🎯 Goals for this module\n\n\nUnderstand what hypothesis testing is\n\nLearn about parametric and non-parametric tests\nLearn how to perform (t-)tests in R\n\nUnderstand when and why to transform data\nUnderstand what is “multiple testing” & how to adjust for it.\nLearn how to display longitudinal data\nUnderstand the limitations inherent to compositional data"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#discussions-discord",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#discussions-discord",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "💬 Discussions: discord",
    "text": "💬 Discussions: discord\nAsk questions at #workshop-questions on https://discord.gg/UDAsYTzZE."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#wooclap",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#wooclap",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Wooclap",
    "text": "Wooclap\nGo to the event on wooclap"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#malva-pudding",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#malva-pudding",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Malva pudding",
    "text": "Malva pudding\n\n\nMy friend told me that Malva puddings in Durban are usually much sweeter than those sold in Cape Town.\n\n\nIs this true?"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#is-my-friend-right",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#is-my-friend-right",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Is my friend right?",
    "text": "Is my friend right?\nAre Malva puddings in Durban sweeter than those in Cape Town?\n\nHow do we find out?"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#malva-pudding-and-hypothesis-testing",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#malva-pudding-and-hypothesis-testing",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Malva pudding and hypothesis testing",
    "text": "Malva pudding and hypothesis testing\nWe have a claim:\n“Malva puddings in Durban are sweeter than those in Cape Town”.\n\nWe need to design and plan an experiment to collect data to test this claim.\n\n\nStatistically, this is hypothesis testing."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#hypothesis-testing",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#hypothesis-testing",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Hypothesis testing 🤔",
    "text": "Hypothesis testing 🤔\nWhat is hypothesis testing? 🤔\n\n\nHypothesis testing is a method for making decisions about the value of a population parameter.\n\n\n\n\nA population is not necessarily a group of humans. In statistics, a population is a group of individuals, objects, or measurements that are of interest to us. For example: the population of Malva puddings in Durban.\n\n\n\n\nA population parameter is a numerical value that describes a population. For example: the average sugar content of Malva puddings in Durban."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#hypothesis-testing-is-a-critical-step-of-the-scientific-method",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#hypothesis-testing-is-a-critical-step-of-the-scientific-method",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Hypothesis testing is a critical step of the scientific method",
    "text": "Hypothesis testing is a critical step of the scientific method\n\nState a claim that we want to verify (or disprove) 🤓\n\n\n\nDesign an experiment to test the claim 📝\n\n\n\n\nPlan and execute the experiment (= collect the data) 🔎🔎\n\n\n\n\nExploratory analysis of the data and visualization 📈📈\n\n\n\n\nHypothesis testing\n\n\n\n\nInterpretation (and predictions) 💁"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#how-many-samples-do-we-need",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#how-many-samples-do-we-need",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "How many samples do we need?",
    "text": "How many samples do we need?\nDo we need to measure the sugar content of ALL Malva puddings in Durban and Cape Town?\n🥮🥮🥮🥮🥮🥮🥮🥮🥮🥮🥮🥮🥮🥮🥮🥮🥮🥮🥮🥮🥮\n\n❌ No, we can to collect a representative sample from both populations.\n\n\n💡 The number of samples we need to collect depends on the variability of sugar content in both populations and the minimum difference in sugar we want to detect.\n\n\n🤓 Formally, we would need to do a power analysis to estimate the number of samples needed."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#malva-pudding-data",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#malva-pudding-data",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Malva pudding data",
    "text": "Malva pudding data\nLet’s pretend we have done a power analysis. 🤫\n\n→ We need to collect 20 samples from each “population”\n\n\nWe go to the lab and measure the sugar content of all 40 puddings. Let’s display this data."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#malva-puddings-conclusions",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#malva-puddings-conclusions",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Malva puddings: conclusions?",
    "text": "Malva puddings: conclusions?\nLet’s compute the mean and standard deviation for both groups.\n\n\n\n\n\n\n\n\n\n\n\n\n\ntown\nmean sugar (%)\nsd\n\n\n\n\nDurban\n35.85\n3.92\n\n\nCape Town\n30.35\n4.78\n\n\n\n\n\n\n\n\n\n\nDo we think my friend was right?\n\n\n🤔 Could it not be just by chance that the average sugar content in Durban is higher than in Cape Town?"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#the-null-and-alternative-hypotheses.",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#the-null-and-alternative-hypotheses.",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "The Null and Alternative hypotheses.",
    "text": "The Null and Alternative hypotheses.\nFormally, in statistics, to do a test, we need to define a pair of hypotheses: the Null and the Alternative hypotheses.\n\n⚖️ The Null hypothesis (\\(H_0\\)) is the “status quo” claim: usually, it assumes no effect, or no differences between groups.\nFor example, the average sugar content in Malva puddings is the same in both towns:\n\\[H_0: \\mu_{C} = \\mu_{D}\\]"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#the-null-and-alternative-hypotheses.-1",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#the-null-and-alternative-hypotheses.-1",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "The Null and Alternative hypotheses.",
    "text": "The Null and Alternative hypotheses.\nThe alternative hypothesis (\\(H_a\\)) is the complement of the Null hypothesis. It is usually the hypothesis we want to prove.\n\nHere:\n\\[H_a: \\mu_C \\neq \\mu_D\\]"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#the-null-and-alternative-hypotheses.-2",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#the-null-and-alternative-hypotheses.-2",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "The Null and Alternative hypotheses.",
    "text": "The Null and Alternative hypotheses.\nWe can do “two-sided” tests, like above, or “one-sided” tests.\n\nIn “one-sided” tests, the Null and Alternative hypotheses are of the form:\n\\[H_0: \\mu_{C} \\geq \\mu_{D}\\] and\n\\[H_a: \\mu_C &lt; \\mu_D\\]\n\n\n(or the reverse)."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#the-null-and-alternative-hypothesis-for-malva-puddings",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#the-null-and-alternative-hypothesis-for-malva-puddings",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "The Null and alternative hypothesis for Malva puddings",
    "text": "The Null and alternative hypothesis for Malva puddings\n\n\\[H_0: \\mu_{D} \\leq \\mu_{C}\\] and\n\\[H_a: \\mu_D &gt; \\mu_C\\]\nThe alternative is my friend’s claim (Malva puddings in Durban are sweeter than those in Cape Town)."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#is-it-enough-to-just-compute-the-means",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#is-it-enough-to-just-compute-the-means",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Is it enough to just compute the means?",
    "text": "Is it enough to just compute the means?\n\n\n\n\n\ntown\nmean sugar (%)\nsd\n\n\n\n\nDurban\n35.85\n3.92\n\n\nCape Town\n30.35\n4.78\n\n\n\n\n\n\n\nWould it be possible to observe these values if the Null hypothesis was true?"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#the-p-value",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#the-p-value",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "The \\(p\\)-value",
    "text": "The \\(p\\)-value\n✨The \\(p\\)-value is the probability of observing a test statistic as extreme as the one we observed, under the Null hypothesis.\n\nThe \\(p\\)-value is a number between 0 and 1.\n\n\n0 = impossible / never\n1 = always"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#hypothesis-testing-the-test-statistic",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#hypothesis-testing-the-test-statistic",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Hypothesis testing: the test statistic",
    "text": "Hypothesis testing: the test statistic\nRemember:\nThe \\(p\\)-value is the probability of observing a test statistic as extreme as the one we observed, under the Null hypothesis.\n\n🤔 What is a test statistics?\nA test statistic is a numerical value that we compute from our data, and that we will use to make a decision about the Null hypothesis."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#hypothesis-testing-the-test-statistic-1",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#hypothesis-testing-the-test-statistic-1",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Hypothesis testing: the test statistic",
    "text": "Hypothesis testing: the test statistic\nA naive test statistic for comparing means of two populations could be simply to compute the difference in means.\n\nUnder the Null (= assuming the Null is true and \\(\\mu_D \\leq \\mu_C\\)), this difference should be small or below zero.\n\n\nSo a large positive value would be quite unlikely under the Null and have a small \\(p\\)-value."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#a-less-naive-test-statistic",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#a-less-naive-test-statistic",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "A less naive test statistic",
    "text": "A less naive test statistic\nA more sophisticated test statistic is the \\(t\\)-statistic which takes into account the variability in the data.\n\n\\[😱😱😱\\ \\ \\ \\  T  = \\frac{\\bar{x}_D - \\bar{x}_C}{\\sqrt{\\frac{S^2_D}{n_D} + \\frac{S^2_C}{n_C}}} \\ \\ \\ \\ 😱😱😱\\]\n\n\nIF\n\nthe two populations follow a normal distribution OR\nthe number of samples is larger than ~40 in each group\n\nTHEN this \\(T\\) test statistics follows a \\(t\\) distribution."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#back-to-the-pudding-data",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#back-to-the-pudding-data",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Back to the pudding data",
    "text": "Back to the pudding data\nLet’s compute the \\(t\\)-statistic for the Malva pudding data.\n\n\n\n\n\n\n\n\n\n\n\n\n\ntown\nmean sugar (%)\nsd\n\n\n\n\nDurban\n35.85\n3.92\n\n\nCape Town\n30.35\n4.78\n\n\n\n\n\n\n\n\n\nDifference in means: 5.5\n\\(t\\)-statistics: 3.976"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#the-t-distribution-under-the-null",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#the-t-distribution-under-the-null",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "The \\(t\\)-distribution under the Null",
    "text": "The \\(t\\)-distribution under the Null\nUnder the Null, the distribution of \\(t\\)-statistics is the \\(t\\) distribution (looks like a “narrower” normal distribution):\n\n\nIt is VERY unlikely to observe such a large \\(t\\) statistics assuming that the two average sugar contents are the same between the two towns."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#the-p-value-1",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#the-p-value-1",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "The \\(p\\)-value",
    "text": "The \\(p\\)-value\nRemember: The \\(p\\)-value is the probability of observing a test statistic as extreme as the one we observed, under the Null hypothesis."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#the-t-test",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#the-t-test",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "The \\(t\\)-test",
    "text": "The \\(t\\)-test\nWhat we just did is called a \\(t\\)-test.\n\nThe assumptions for a \\(t\\)-test are:\n\nthe two populations follow a normal distribution OR\nthe sample sizes are larger than ~40 in each group\n\n\n\n⚠️ Were we allowed to do a \\(t\\)-test for the pudding data?"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#normal-malva",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#normal-malva",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Normal Malva?",
    "text": "Normal Malva?\nDid we have more than 40 samples in each group?\n. . . Were our data normally distributed?"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#qq-what",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#qq-what",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "QQ-what?",
    "text": "QQ-what?\n\nA more formal way to check that data are normally distributed is to make a QQ-plot.\n\n\n\n\n\n\n\nIf the dots are close to the line, that indicates that the data is compatible with a normal distribution.\n\\(\\rightarrow\\) We can use the \\(t\\)-test ✅"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#the-t-test-in-r",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#the-t-test-in-r",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "The \\(t\\)-test in R",
    "text": "The \\(t\\)-test in R\nIn R, we can do a \\(t\\)-test using the function t.test.\n\nt.test(sugar ~ town, data = malva, alternative = \"greater\")\n\n\n    Welch Two Sample t-test\n\ndata:  sugar by town\nt = 3.9761, df = 36.604, p-value = 0.0001584\nalternative hypothesis: true difference in means between group Durban and group Cape Town is greater than 0\n95 percent confidence interval:\n 3.165654      Inf\nsample estimates:\n   mean in group Durban mean in group Cape Town \n                  35.85                   30.35"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#hands-on-exercises",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#hands-on-exercises",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "🫵 Hands-on exercises",
    "text": "🫵 Hands-on exercises\nRead the Module 6 Quarto document and execute all chunks until the “data transformation” section."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#enough-pudding-lets-science",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#enough-pudding-lets-science",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "🙅 Enough Pudding! Let’s science 🧪",
    "text": "🙅 Enough Pudding! Let’s science 🧪\nOur 1st scientific question is:\n“Does IL-1\\(\\beta\\)” (a cytokine) have a different concentration in samples from individuals diagnosed with BV (bacterial vaginosis) or not?”\n\nWhat is the Null and Alternative hypothesis?\n\n\n\\[H_0: \\mu_{BV} = \\mu_{H} \\]\n\\[H_a: \\mu_{BV} \\neq \\mu_{H}\\]"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#lets-display-the-data",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#lets-display-the-data",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Let’s display the data",
    "text": "Let’s display the data\n\nDoes this look normal?\n\nWhat should we do?"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#data-transformation",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#data-transformation",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Data transformation",
    "text": "Data transformation\n\nIL1b &lt;- IL1b |&gt; mutate(logconc = log10(conc))\n\n\nDoes this look normal?"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#qq-plot",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#qq-plot",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "QQ-plot",
    "text": "QQ-plot\n\nNot perfect, but not too bad."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#il-1beta-by-bv-status",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#il-1beta-by-bv-status",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "IL-1\\(\\beta\\) by BV status",
    "text": "IL-1\\(\\beta\\) by BV status"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#t-test",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#t-test",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "\\(t\\)-test?",
    "text": "\\(t\\)-test?\n\nIL1b |&gt; count(BV) |&gt; pivot_wider(names_from = BV, values_from = n)\n\n# A tibble: 1 × 2\n     BV Healthy\n  &lt;int&gt;   &lt;int&gt;\n1    46      86\n\n\n\nThe data roughly follow a normal distribution AND we have more than 40 samples in each group, so we can use a \\(t\\)-test:\n\n\n\nt.test(logconc ~ BV, data = IL1b)\n\n\n    Welch Two Sample t-test\n\ndata:  logconc by BV\nt = 6.5449, df = 116.4, p-value = 1.672e-09\nalternative hypothesis: true difference in means between group BV and group Healthy is not equal to 0\n95 percent confidence interval:\n 0.5332052 0.9959381\nsample estimates:\n     mean in group BV mean in group Healthy \n            1.1245273             0.3599557"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#hands-on-exercises-1",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#hands-on-exercises-1",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "🫵 Hands-on exercises",
    "text": "🫵 Hands-on exercises\nContinue on the Module 6 Quarto document and execute all chunks until the “Non-parametric tests” section."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#what-if",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#what-if",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "What if?",
    "text": "What if?\n😬 What if the \\(t\\)-test assumptions weren’t met?\n\n✅ We can use another test such as the Wilcoxon rank sum test"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#parametric-vs-non-parametric-tests",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#parametric-vs-non-parametric-tests",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Parametric vs non-parametric tests",
    "text": "Parametric vs non-parametric tests\nThe \\(t\\)-test is a parametric test.\n\n🤔 What does it mean?\n\n\nIt assumes that the populations can be described by a distribution characterized by a few parameters (e.g., mean and standard deviation).\nFor example: the Normal distribution: \\(N(\\mu, \\sigma^2)\\)"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#non-parametric-tests",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#non-parametric-tests",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Non-parametric tests",
    "text": "Non-parametric tests\nNon-parametric tests do not make any assumption about the distribution of the data.\n\nThe “equivalent” of the \\(t\\)-test is the Mann-Whitney U test or the Wilcoxon rank sum test.\n\n\nIn R, we can use the wilcox.test function to run this test."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#why-not-always-use-non-parametric-tests",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#why-not-always-use-non-parametric-tests",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Why not always use non-parametric tests?",
    "text": "Why not always use non-parametric tests?\nBecause these tests have less power than parametric tests.\n\nThe power of a test is the probability of rejecting the Null hypothesis when it is false.\n\n\nIt is the ability of a test to detect small but real effects."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#hands-on-exercises-2",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#hands-on-exercises-2",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "🫵 Hands-on exercises",
    "text": "🫵 Hands-on exercises\nContinue on the Module 6 Quarto document and execute all chunks until the “Multiple testing” section."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#break",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#break",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "☕️ BREAK",
    "text": "☕️ BREAK"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#hypothesis-testing-summary",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#hypothesis-testing-summary",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Hypothesis testing: summary",
    "text": "Hypothesis testing: summary\n\n\n☝️ The first and most important step is to have a clear and testable scientific question.\n⚖️ Then, one can define the null and alternative hypotheses.\n❓Depending on the question and the hypotheses, one must pick an appropriate statistical test or model.\n\n🙋 For complex questions/models, it might be necessary to consult a statistician.\n\n🧑‍💻 Most common tests have been implemented in R. Read their documentation carefully and check their assumptions."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#what-about-other-cytokines",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#what-about-other-cytokines",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "What about other cytokines?",
    "text": "What about other cytokines?\n🤔 Can we repeat the same test we did for IL-1\\(\\beta\\) for all the other cytokines?\n\n🚨 Yes, but be careful about multiple testing!"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#multiple-testing",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#multiple-testing",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Multiple testing",
    "text": "Multiple testing\nRemember the \\(p\\)-value definition:\nThe \\(p\\)-value is the probability of observing a test statistic as extreme as the one we observed, under the Null hypothesis.\n\nIf this probability is smaller than, let’s say 1/20 (0.05), we reject the Null hypothesis. But we still have 1 chance / 20 to be wrong!\n\n\nSo, as we perform many tests, we are more likely to obtain small \\(p\\)-values by chance."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#hands-on-exercises-3",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#hands-on-exercises-3",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "🫵 Hands-on exercises",
    "text": "🫵 Hands-on exercises\nExplore the effects of multiple testing using simulations and check the p.adjust function and the p.adjust.methods.\nContinue on the Module 6 Quarto document and execute all chunks until the “Displaying longitudinal data” section."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#longitudinal-design",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#longitudinal-design",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "➡️➡️➡️ Longitudinal design",
    "text": "➡️➡️➡️ Longitudinal design\nRemember the study design of the data we are analyzing:\n\n\nShould we try to display the data in a way that highlights the “trajectories” of participants along the study?"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#remember-left_join",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#remember-left_join",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "🧠 Remember: left_join",
    "text": "🧠 Remember: left_join\nFirst, we need to join the cytokine data with the sample data so we have the study arm and the time-point for each sample:\n\nelisa &lt;- \n  elisa |&gt; \n  mutate(logconc = log10(conc)) |&gt; \n  left_join(sample_info, by = join_by(sample_id))\n\nelisa |&gt; head() \n\n# A tibble: 6 × 8\n  sample_id cytokine    conc limits        logconc pid    time_point arm    \n  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;  \n1 SAMP094   IL-1a    174.    within limits   2.24  pid_01 baseline   placebo\n2 SAMP094   IL-10      0.767 out of range   -0.115 pid_01 baseline   placebo\n3 SAMP094   IL-1b      5.39  within limits   0.732 pid_01 baseline   placebo\n4 SAMP094   IL-8      48.3   within limits   1.68  pid_01 baseline   placebo\n5 SAMP094   IL-6       5.07  within limits   0.705 pid_01 baseline   placebo\n6 SAMP094   TNFa       0.471 out of range   -0.327 pid_01 baseline   placebo"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#bonus-character-string-manipulation",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#bonus-character-string-manipulation",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "🎁 Bonus: character string manipulation",
    "text": "🎁 Bonus: character string manipulation\nSince we’ll want to display the visit data, we can “polish” the labels of the time-point column so that they read nicely.\nRight now, the visit labels are:\n\n\n[1] \"baseline\" \"week_1\"   \"week_7\"  \n\n\n\nWe can use the str_replace function from the stringr package to replace the underscores with spaces:\n\nelisa &lt;- \n  elisa |&gt; \n  mutate(time_point = time_point |&gt; str_replace(\"_\", \" \"))\n\nelisa$time_point |&gt; unique()\n\n[1] \"baseline\" \"week 1\"   \"week 7\""
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#remember-factor",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#remember-factor",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "🧠 Remember: factor",
    "text": "🧠 Remember: factor\n\n\n# A tibble: 6 × 8\n  sample_id cytokine    conc limits        logconc pid    time_point arm    \n  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;  \n1 SAMP094   IL-1a    174.    within limits   2.24  pid_01 baseline   placebo\n2 SAMP094   IL-10      0.767 out of range   -0.115 pid_01 baseline   placebo\n3 SAMP094   IL-1b      5.39  within limits   0.732 pid_01 baseline   placebo\n4 SAMP094   IL-8      48.3   within limits   1.68  pid_01 baseline   placebo\n5 SAMP094   IL-6       5.07  within limits   0.705 pid_01 baseline   placebo\n6 SAMP094   TNFa       0.471 out of range   -0.327 pid_01 baseline   placebo\n\n\nWhich columns should be converted to factors?\n\n\nelisa &lt;- \n  elisa |&gt; \n  mutate(\n    sample_id = sample_id |&gt; factor(),\n    cytokine = cytokine |&gt; factor(),\n    pid = pid |&gt; factor(),\n    time_point =time_point |&gt; factor(),\n    arm = arm |&gt; factor(),\n    limits = limits |&gt; factor()\n    )"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#il-1beta-longitudinal-patterns",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#il-1beta-longitudinal-patterns",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "IL-1\\(\\beta\\) longitudinal patterns",
    "text": "IL-1\\(\\beta\\) longitudinal patterns\n\nelisa |&gt; \n  filter(cytokine == \"IL-1b\") |&gt; \n  ggplot(aes(x = time_point, y = logconc, color = arm)) +\n  geom_line(aes(group = pid), alpha = 0.75) +\n  geom_point(alpha = 0.5) +\n  xlab(\"Visits\") +\n  ylab(\"log10(IL-1b concentration)\") +\n  scale_color_manual(\"Arm\", values = c(\"deeppink\",\"steelblue1\"))"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#hands-on-exercises-4",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#hands-on-exercises-4",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "🫵 Hands-on exercises",
    "text": "🫵 Hands-on exercises\nContinue on the Module 6 Quarto document and execute all chunks until the “Compositional data” section.\n🎁 Bonus: there is a section on “paired tests” that you can read if you want to learn more about the paired \\(t\\)-test and the Wilcoxon signed rank test."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#compositional-data",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#compositional-data",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "☯ Compositional data",
    "text": "☯ Compositional data\nWhat are compositional data?\n\nMultivariate data are compositional when the variables are expressed as proportions of a whole.\n\n\nRemember the flow cytometry data?\nSometimes, data are expressed as “proportions of cells X among all cells”."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#whats-the-problem-with-compositional-data",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#whats-the-problem-with-compositional-data",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "⚠️ What’s the problem with compositional data?",
    "text": "⚠️ What’s the problem with compositional data?\n\nThe proportions are not independent.\n\n\nIf we have 3 cell types (A, B, and C) and in one condition, only cells A increase in number, when expressed “compositionally”, it may look like cells B and C are decreasing.\n\n\n\ncondition_1 &lt;- c(\"A\" = 102, \"B\" = 239, \"C\" = 163)\ncondition_2 &lt;- condition_1\ncondition_2[\"A\"] &lt;- condition_2[\"A\"] + 78 # we only increase A\n\n(condition_1/sum(condition_1)) |&gt; round(digits = 2)\n\n   A    B    C \n0.20 0.47 0.32 \n\n(condition_2/sum(condition_2)) |&gt; round(digits = 2) # but the % of B and C decrease!\n\n   A    B    C \n0.31 0.41 0.28"
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#potential-solutions",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#potential-solutions",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Potential solutions",
    "text": "Potential solutions\nThere is no “one-size-fits-all” for compositional data.\n\nIn some cases, some smart solutions have been proposed.\n\n\nFor example, for RNA-seq data, the DESeq2 package uses a “regularized log” transformation that allows to use standard statistical tests.\nThat transformation assumes that most genes are not differentially expressed but that only works for datasets with a large number of features."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#see-you-at-the-next-workshop",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#see-you-at-the-next-workshop",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "📆 See you at the next workshop!",
    "text": "📆 See you at the next workshop!\nIf you are interested in analysing compositional data such as gene expression data or microbiome data, register for the next workshop!\n\n🫵 In the meanwhile, there are some examples and exercises in the Module 6 Quarto document that you can try."
  },
  {
    "objectID": "materials/1-workshop1/6-hypothesis-testing/slides.html#module-6-summary",
    "href": "materials/1-workshop1/6-hypothesis-testing/slides.html#module-6-summary",
    "title": "Hypothesis testing, data transformation, longitudinal displays",
    "section": "Module 6 Summary",
    "text": "Module 6 Summary\n☝️ Be clear with the scientific questions you have\n\n📆 Plan your experiments and collect your data so you can answer your questions\n\n\n☝️ Get to know your data\n\n\n📊 Make your \"table 1\", check for confounders\n\n\n📈 Do exploratory visualizations\n\n\n🤓 Answer your questions\n\n\n📈 Display your data in a way that highlights the answer to your questions\n\n\n📊 Use the appropriate statistical tests (and consult a statistician *before* and after collecting your data if your question requires something more complex than a two-sample test)\n\n\nback to module"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_exercise_solutions.html",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_exercise_solutions.html",
    "title": "Color Scales Exercise Solutions",
    "section": "",
    "text": "Coding exercise 7.1\nIn this worksheet, we will discuss how to change and customize color scales.\nWe will be using the R package tidyverse, which includes ggplot() and related functions. We will also be using the R package colorspace for the scale functions it provides.\n\n# load required library\nlibrary(tidyverse)\nlibrary(colorspace)\n\ntemperatures &lt;- read_csv(\"https://wilkelab.org/SDS375/datasets/tempnormals.csv\") %&gt;%\n  mutate(\n    location = factor(\n      location, levels = c(\"Death Valley\", \"Houston\", \"San Diego\", \"Chicago\")\n    )\n  ) %&gt;%\n  select(location, day_of_year, month, temperature)\n\ntemps_months &lt;- read_csv(\"https://wilkelab.org/SDS375/datasets/tempnormals.csv\") %&gt;%\n  group_by(location, month_name) %&gt;%\n  summarize(mean = mean(temperature)) %&gt;%\n  mutate(\n    month = factor(\n      month_name,\n      levels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\")\n    ),\n    location = factor(\n      location, levels = c(\"Death Valley\", \"Houston\", \"San Diego\", \"Chicago\")\n    )\n  ) %&gt;%\n  select(-month_name)\n\nWe will be working with the dataset temperatures that we have used in previous worksheets. This dataset contains the average temperature for each day of the year for four different locations.\n\ntemperatures\n\n# A tibble: 1,464 × 4\n   location     day_of_year month temperature\n   &lt;fct&gt;              &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;\n 1 Death Valley           1 01           51  \n 2 Death Valley           2 01           51.2\n 3 Death Valley           3 01           51.3\n 4 Death Valley           4 01           51.4\n 5 Death Valley           5 01           51.6\n 6 Death Valley           6 01           51.7\n 7 Death Valley           7 01           51.9\n 8 Death Valley           8 01           52  \n 9 Death Valley           9 01           52.2\n10 Death Valley          10 01           52.3\n# ℹ 1,454 more rows\n\n\nWe will also be working with an aggregated version of this dataset called temps_months, which contains the mean temperature for each month for the same locations.\n\ntemps_months\n\n# A tibble: 48 × 3\n# Groups:   location [4]\n   location  mean month\n   &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;\n 1 Chicago   50.4 Apr  \n 2 Chicago   74.1 Aug  \n 3 Chicago   29   Dec  \n 4 Chicago   28.9 Feb  \n 5 Chicago   24.8 Jan  \n 6 Chicago   75.8 Jul  \n 7 Chicago   71.0 Jun  \n 8 Chicago   38.8 Mar  \n 9 Chicago   60.9 May  \n10 Chicago   41.6 Nov  \n# ℹ 38 more rows\n\n\nAs a challenge, try to create this above table yourself using group_by() and summarize() like we learned about Wednesday., and then make a month column which is a factor with levels froing from “Jan” to “Dec”, and make the location column a factor with levels “Death Valley”, “Houston”, “San Diego”, “Chicago”. If you are having trouble, the solution is at the end of this page, make sure you copy it into your code so the rest of the exercise works.\n\n# check solution at the end before moving on!\ntemps_months &lt;- read_csv(\"https://wilkelab.org/SDS375/datasets/tempnormals.csv\") %&gt;%\n  group_by(___) %&gt;%\n  summarize(___) %&gt;%\n  mutate(\n    month = factor(\n      month_name,\n      ___\n    ),\n    location = factor(\n      location, ___\n    )\n  ) %&gt;%\n  select(-month_name)\n\n\n# solution\ntemps_months &lt;- read_csv(\"https://wilkelab.org/SDS375/datasets/tempnormals.csv\") %&gt;%\n  group_by(location, month_name) %&gt;%\n  summarize(mean = mean(temperature)) %&gt;%\n  mutate(\n    month = factor(\n      month_name,\n      levels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\")\n    ),\n    location = factor(\n      location, levels = c(\"Death Valley\", \"Houston\", \"San Diego\", \"Chicago\")\n    )\n  ) %&gt;%\n  select(-month_name)\n\n\nBuilt in ggplot2 color scales\nWe will start with built-in ggplot2 color scales, which require no additional packages. The scale functions are always named scale_color_*() or scale_fill_*(), depending on whether they apply to the color or fill aesthetic. The * indicates some other words specifying the type of the scale, for example scale_color_brewer() or scale_color_distiller() for discrete or continuous scales from the ColorBrewer project, respectively. You can find all available built-in scales here: https://ggplot2.tidyverse.org/reference/index.html#section-scales\nNow consider the following plot.\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE)\n\n\n\n\nIf you wanted to change the color scale to one from the ColorBrewer project, which scale function would you have to add? scale_color_brewer(), scale_color_distiller(), scale_fill_brewer(), scale_fill_distiller()?\n\n # answer the question above to yourself\n\n #solution: \n scale_fill_distiller()\n\nNow try this out.\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  ___\n\n\n # solution\n  ggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_distiller()\n\n\n\n\nMost color scale functions have additional customizations. How to use them depends on the specific scale function. For the ColorBrewer scales you can set direction = 1 or direction = -1 to set the direction of the scale (light to dark or dark to light). You can also set the palette via a numeric argument, e.g. palette = 1, palette = 2, palette = 3 etc.\nTry this out by setting the direction of the scale from light to dark and using palette #4.\n\n # build all the code for this exercise\n\n# solution \nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_distiller(direction = 1, palette = 4)\n\n\n\n\nA popular set of scales are the viridis scales, which are provided by scale_*_viridis_c() for continuous data and scale_*_viridis_d() for discrete data. Change the above plot to use a viridis scale.\n\n # build all the code for this exercise\n\n  # solution \n    ggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_viridis_c()\n\n\n\n\nThe viridis scales can be customized with direction (as before), option (which can be \"A\", \"B\", \"C\", \"D\", or \"E\"), and begin and end which are numerical values between 0 and 1 indicating where in the color scale the data should begin or end. For example, begin = 0.2 means that the lowest data value is mapped to the 20th percentile in the scale.\nTry different choices for option, begin, and end to see how they change the plot.\n\n # build all the code for this exercise\n\n  # solution\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_viridis_c(option = \"B\", begin = 0.15)\n\n\n\n\n\n\nCustomizing scale title and labels\nIn a previous worksheet, we used arguments such as name, breaks, labels, and limits to customize the axis. For color scales, instead of an axis we have a legend, and we can use the same arguments inside the scale function to customize how the legend looks.\nTry this out. Set the scale limits from 10 to 110 and set the name of the scale and the breaks as you wish.\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_viridis_c(\n    name = ___,\n    breaks = ___,\n    limits = ___\n  )\n\n\n# solution\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_viridis_c(\n    name = \"temperature (F)\",\n    breaks = c(25, 50, 75, 100),\n    limits = c(10, 110)\n  )\n\n\n\n\nNote: Color scales ignore the expand argument, so you cannot use it to expand the scale beyond the data values as you can for position scales.\n\n\nBinned scales\nResearch into human perception has shown that continuous coloring can be difficult to interpret. Therefore, it is often preferable to use a small number of discrete colors to indicate ranges of data values. You can do this in ggplot with binned scales. For example, scale_fill_viridis_b() provides a binned version of the viridis scale. Try this out.\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  ___\n\n\n# solution\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_viridis_b()\n\n\n\n\nYou can change the number of bins by providing the n.breaks argument or alternatively by setting breaks explicitly. Try this out.\n\n # build all the code for this exercise\n \n  # solution\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_viridis_b(\n    n.breaks = 7\n  )\n\n\n\n\n\n\nScales from the colorspace package\nThe color scales provided by the colorspace package follow a simple naming scheme of the form scale_&lt;aesthetic&gt;_&lt;datatype&gt;_&lt;colorscale&gt;(), where &lt;aesthetic&gt; is the name of the aesthetic (fill, color, colour), &lt;datatype&gt; indicates the type of variable plotted (discrete, continuous, binned), and colorscale stands for the type of the color scale (qualitative, sequential, diverging, divergingx).\nFor the mean temperature plot we have been using throughout this worksheet, which 2 color scales from the colorspace package is/are appropriate?\nscale_fill_binned_sequential(), scale_fill_discrete_qualitative(), scale_fill_continuous_sequential(), scale_color_continuous_sequential(), scale_color_continuous_diverging()&gt;\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  ___\n\n\n # solution\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_continuous_sequential()\n\n\n\n\nYou can customize the colorspace scales with the palette argument, which takes the name of a palette (e.g., \"Inferno\", \"BluYl\", \"Lajolla\"). Try this out. Also try reversing the scale direction with rev = TRUE or rev = FALSE. (The colorspace scales use rev instead of direction.) You can find the names of all supported scales here (consider specifically single-hue and multi-hue sequential palettes).\n\n # build all the code for this exercise\n\n  # solution\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_continuous_sequential(\n    palette = \"Lajolla\"\n  )\n\n\n\n\nYou can also use begin and end just like in the viridis scales.\n\n\nManual scales\nFor discrete data with a small number of categories, it’s usually best to set colors manually. This can be done with the scale functions scale_*_manual(). These functions take an argument values that specifies the color values to use.\nTo see how this works, let’s go back to this plot of temperatures over time for four locations.\n\nggplot(temperatures, aes(day_of_year, temperature, color = location)) +\n  geom_line(size = 1.5)\n\n\n\n\nLet’s use the following four colors: \"gold2\", \"firebrick\", \"blue3\", \"springgreen4\". We can visualize this palette using the function swatchplot() from the colorspace package.\n\ncolorspace::swatchplot(c(\"gold2\", \"firebrick\", \"blue3\", \"springgreen4\"))\n\n\n\n\nNow apply this color palette to the temperatures plot, by using the manual color scale. Hint: use the values argument to provide the colors to the manual scale.\n\nggplot(temperatures, aes(day_of_year, temperature, color = location)) +\n  geom_line(size = 1.5) +\n  ___\n\n\n# solution\nggplot(temperatures, aes(day_of_year, temperature, color = location)) +\n  geom_line(size = 1.5) +\n  scale_color_manual(\n    values = c(\"gold2\", \"firebrick\", \"blue3\", \"springgreen4\")\n  )\n\n\n\n\nOne problem with this approach is that we can’t easily control which data value gets assigned to which color. What if we wanted San Diego to be shown in green and Chicago in blue? The simplest way to resolve this issue is to use a named vector. A named vector in R is a vector where each value has a name. Named vectors are created by writing c(name1 = value1, name2 = value2, ...). See the following example.\n\n# regular vector\nc(\"cat\", \"mouse\", \"house\")\n\n[1] \"cat\"   \"mouse\" \"house\"\n\n# named vector\nc(A = \"cat\", B = \"mouse\", C = \"house\")\n\n      A       B       C \n  \"cat\" \"mouse\" \"house\" \n\n\nThe names in the second example are A, B, and C. Notice that the names are not in quotes. However, if you need a name containing a space (such as Death Valley), you need to enclose the name in backticks. Thus, our named vector of colors could be written like so:\n\nc(`Death Valley` = \"gold2\", Houston = \"firebrick\", Chicago = \"blue3\", `San Diego` = \"springgreen4\")\n\n  Death Valley        Houston        Chicago      San Diego \n       \"gold2\"    \"firebrick\"        \"blue3\" \"springgreen4\" \n\n\nNow try to use this color vector in the figure showing temperatures over time.\n\n # build all the code for this exercise\n\n # solution\n\n ggplot(temperatures, aes(day_of_year, temperature, color = location)) +\n  geom_line(size = 1.5) +\n  scale_color_manual(\n    values = c(\n      `Death Valley` = \"gold2\",\n      Houston = \"firebrick\",\n      Chicago = \"blue3\",\n      `San Diego` = \"springgreen4\"\n    )\n  )\n\n\n\n\nTry some other colors also. For example, you could use the Okabe-Ito colors:\n\n# Okabe-Ito colors\ncolorspace::swatchplot(c(\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\", \"#000000\"))\n\n\n\n\nAlternatively, you can find a list of all named colors here. You can also run the command colors() in your R console to get a list of all available color names.\nHint: It’s a good idea to never use the colors \"red\", \"green\", \"blue\", \"cyan\", \"magenta\", \"yellow\". They are extreme points in the RGB color space and tend to look unnatural and too crazy. Try this by making a swatch plot of these colors, and compare for example to the color scale containing the colors \"firebrick\", \"springgreen4\", \"blue3\", \"turquoise3\", \"darkorchid2\", \"gold2\". Do you see the difference?\n\n # build all the code for this exercise\n\nSolution to the challenge to make the summary table of mean temperature by month:\n\n# paste this below the \"temperatures\" code-chunk\ntemps_months &lt;- read_csv(\"https://wilkelab.org/SDS375/datasets/tempnormals.csv\") %&gt;%\n  group_by(location, month_name) %&gt;%\n  summarize(mean = mean(temperature)) %&gt;%\n  mutate(\n    month = factor(\n      month_name,\n      levels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\")\n    ),\n    location = factor(\n      location, levels = c(\"Death Valley\", \"Houston\", \"San Diego\", \"Chicago\")\n    )\n  ) %&gt;%\n  select(-month_name)"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#uses-of-color-in-data-visualization",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#uses-of-color-in-data-visualization",
    "title": "Color Scales",
    "section": "Uses of color in data visualization",
    "text": "Uses of color in data visualization\n\nDistinguish categories (qualitative)"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#qualitative-scale-example",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#qualitative-scale-example",
    "title": "Color Scales",
    "section": "Qualitative scale example",
    "text": "Qualitative scale example\n\nHumans can only distinguish 7 or 8 colors."
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#qualitative-scale-example-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#qualitative-scale-example-1",
    "title": "Color Scales",
    "section": "Qualitative scale example",
    "text": "Qualitative scale example\n\nPalette name: Okabe-Ito"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#qualitative-scale-example-2",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#qualitative-scale-example-2",
    "title": "Color Scales",
    "section": "Qualitative scale example",
    "text": "Qualitative scale example\n\nPalette name: ColorBrewer Set1"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#qualitative-scale-example-3",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#qualitative-scale-example-3",
    "title": "Color Scales",
    "section": "Qualitative scale example",
    "text": "Qualitative scale example\n\nPalette name: ColorBrewer Set3"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#uses-of-color-in-data-visualization-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#uses-of-color-in-data-visualization-1",
    "title": "Color Scales",
    "section": "Uses of color in data visualization",
    "text": "Uses of color in data visualization\n\n\nDistinguish categories (qualitative)\n\n\n\n\n\n\n\nRepresent numeric values (sequential)"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#sequential-scale-example",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#sequential-scale-example",
    "title": "Color Scales",
    "section": "Sequential scale example",
    "text": "Sequential scale example\n\nPalette name: Viridis"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#sequential-scale-example-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#sequential-scale-example-1",
    "title": "Color Scales",
    "section": "Sequential scale example",
    "text": "Sequential scale example\n\nPalette name: Inferno"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#sequential-scale-example-2",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#sequential-scale-example-2",
    "title": "Color Scales",
    "section": "Sequential scale example",
    "text": "Sequential scale example\n\nPalette name: Cividis"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#uses-of-color-in-data-visualization-2",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#uses-of-color-in-data-visualization-2",
    "title": "Color Scales",
    "section": "Uses of color in data visualization",
    "text": "Uses of color in data visualization\n\n\nDistinguish categories (qualitative)\n\n\n\n\n\n\n\nRepresent numeric values (sequential)\n\n\n\n\n\n\n\nRepresent numeric values (diverging)"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#diverging-scale-example",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#diverging-scale-example",
    "title": "Color Scales",
    "section": "Diverging scale example",
    "text": "Diverging scale example\n\nPalette name: ColorBrewer PiYG"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#diverging-scale-example-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#diverging-scale-example-1",
    "title": "Color Scales",
    "section": "Diverging scale example",
    "text": "Diverging scale example\n\nPalette name: Carto Earth"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#diverging-scale-example-2",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#diverging-scale-example-2",
    "title": "Color Scales",
    "section": "Diverging scale example",
    "text": "Diverging scale example\n\nPalette name: Blue-Red"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#uses-of-color-in-data-visualization-3",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#uses-of-color-in-data-visualization-3",
    "title": "Color Scales",
    "section": "Uses of color in data visualization",
    "text": "Uses of color in data visualization\n\n\nDistinguish categories (qualitative)\n\n\n\n\n\n\n\nRepresent numeric values (sequential)\n\n\n\n\n\n\n\nRepresent numeric values (diverging)\n\n\n\n\n\n\n\nHighlight"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#highlight-example",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#highlight-example",
    "title": "Color Scales",
    "section": "Highlight example",
    "text": "Highlight example\n\nPalette name: Grays with accents"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#highlight-example-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#highlight-example-1",
    "title": "Color Scales",
    "section": "Highlight example",
    "text": "Highlight example\n\nPalette name: Okabe-Ito accent"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#highlight-example-2",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#highlight-example-2",
    "title": "Color Scales",
    "section": "Highlight example",
    "text": "Highlight example\n\nPalette name: ColorBrewer accent"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#uses-of-color-in-data-visualization-4",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#uses-of-color-in-data-visualization-4",
    "title": "Color Scales",
    "section": "Uses of color in data visualization",
    "text": "Uses of color in data visualization\n\n\nDistinguish categories (qualitative)\n\n\n\n\n\n\n\nRepresent numeric values (sequential)\n\n\n\n\n\n\n\nRepresent numeric values (diverging)\n\n\n\n\n\n\n\nHighlight"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#ggplot2-color-scale-functions-are-a-bit-of-a-mess",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#ggplot2-color-scale-functions-are-a-bit-of-a-mess",
    "title": "Color Scales",
    "section": "ggplot2 color scale functions are a bit of a mess",
    "text": "ggplot2 color scale functions are a bit of a mess\n\n\n\n\n\n\n\n\n\nScale function\nAesthetic    \nData type\nPalette type\n\n\n\n\nscale_color_hue()\ncolor\ndiscrete\nqualitative"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#ggplot2-color-scale-functions-are-a-bit-of-a-mess-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#ggplot2-color-scale-functions-are-a-bit-of-a-mess-1",
    "title": "Color Scales",
    "section": "ggplot2 color scale functions are a bit of a mess",
    "text": "ggplot2 color scale functions are a bit of a mess\n\n\n\n\n\n\n\n\n\nScale function\nAesthetic    \nData type\nPalette type\n\n\n\n\nscale_color_hue()\ncolor\ndiscrete\nqualitative\n\n\nscale_fill_hue()\nfill\ndiscrete\nqualitative"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#ggplot2-color-scale-functions-are-a-bit-of-a-mess-2",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#ggplot2-color-scale-functions-are-a-bit-of-a-mess-2",
    "title": "Color Scales",
    "section": "ggplot2 color scale functions are a bit of a mess",
    "text": "ggplot2 color scale functions are a bit of a mess\n\n\n\n\n\n\n\n\n\nScale function\nAesthetic    \nData type\nPalette type\n\n\n\n\nscale_color_hue()\ncolor\ndiscrete\nqualitative\n\n\nscale_fill_hue()\nfill\ndiscrete\nqualitative\n\n\nscale_color_gradient()\ncolor\ncontinuous\nsequential"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#ggplot2-color-scale-functions-are-a-bit-of-a-mess-3",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#ggplot2-color-scale-functions-are-a-bit-of-a-mess-3",
    "title": "Color Scales",
    "section": "ggplot2 color scale functions are a bit of a mess",
    "text": "ggplot2 color scale functions are a bit of a mess\n\n\n\n\n\n\n\n\n\nScale function\nAesthetic    \nData type\nPalette type\n\n\n\n\nscale_color_hue()\ncolor\ndiscrete\nqualitative\n\n\nscale_fill_hue()\nfill\ndiscrete\nqualitative\n\n\nscale_color_gradient()\ncolor\ncontinuous\nsequential\n\n\nscale_color_gradient2()\ncolor\ncontinuous\ndiverging"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#ggplot2-color-scale-functions-are-a-bit-of-a-mess-4",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#ggplot2-color-scale-functions-are-a-bit-of-a-mess-4",
    "title": "Color Scales",
    "section": "ggplot2 color scale functions are a bit of a mess",
    "text": "ggplot2 color scale functions are a bit of a mess\n\n\n\n\n\n\n\n\n\nScale function\nAesthetic    \nData type\nPalette type\n\n\n\n\nscale_color_hue()\ncolor\ndiscrete\nqualitative\n\n\nscale_fill_hue()\nfill\ndiscrete\nqualitative\n\n\nscale_color_gradient()\ncolor\ncontinuous\nsequential\n\n\nscale_color_gradient2()\ncolor\ncontinuous\ndiverging\n\n\nscale_fill_viridis_c()\ncolor\ncontinuous\nsequential\n\n\nscale_fill_viridis_d()\nfill\ndiscrete\nsequential\n\n\nscale_color_brewer()\ncolor\ndiscrete\nqualitative, diverging, sequential\n\n\nscale_fill_brewer()\nfill\ndiscrete\nqualitative, diverging, sequential\n\n\nscale_color_distiller()\ncolor\ncontinuous\nqualitative, diverging, sequential\n\n\n\n… and there are many many more"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#examples",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#examples",
    "title": "Color Scales",
    "section": "Examples",
    "text": "Examples\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile(width = 0.95, height = 0.95) + \n  coord_fixed(expand = FALSE) +\n  theme_classic()\n\n  # no fill scale defined, default is scale_fill_gradient()"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#examples-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#examples-1",
    "title": "Color Scales",
    "section": "Examples",
    "text": "Examples\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile(width = 0.95, height = 0.95) + \n  coord_fixed(expand = FALSE) +\n  theme_classic() +\n  scale_fill_gradient()"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#examples-2",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#examples-2",
    "title": "Color Scales",
    "section": "Examples",
    "text": "Examples\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile(width = 0.95, height = 0.95) + \n  coord_fixed(expand = FALSE) +\n  theme_classic() +\n  scale_fill_viridis_c()"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#examples-3",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#examples-3",
    "title": "Color Scales",
    "section": "Examples",
    "text": "Examples\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile(width = 0.95, height = 0.95) + \n  coord_fixed(expand = FALSE) +\n  theme_classic() +\n  scale_fill_viridis_c(option = \"B\", begin = 0.15)"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#examples-4",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#examples-4",
    "title": "Color Scales",
    "section": "Examples",
    "text": "Examples\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile(width = 0.95, height = 0.95) + \n  coord_fixed(expand = FALSE) +\n  theme_classic() +\n  scale_fill_distiller(palette = \"YlGnBu\")"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#the-colorspace-package-creates-some-order",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#the-colorspace-package-creates-some-order",
    "title": "Color Scales",
    "section": "The colorspace package creates some order",
    "text": "The colorspace package creates some order\nScale name: scale_&lt;aesthetic&gt;_&lt;datatype&gt;_&lt;colorscale&gt;()\n\n&lt;aesthetic&gt;: name of the aesthetic (fill, color, colour)\n&lt;datatype&gt;: type of variable plotted (discrete, continuous, binned)\n&lt;colorscale&gt;: type of the color scale (qualitative, sequential, diverging, divergingx)\n\n\n\n\n\n\n\n\n\n\nScale function\nAesthetic    \nData type\nPalette type    \n\n\n\n\nscale_color_discrete_qualitative()\ncolor\ndiscrete\nqualitative\n\n\nscale_fill_continuous_sequential()\nfill\ncontinuous\nsequential\n\n\nscale_colour_continous_divergingx()\ncolour\ncontinuous\ndiverging"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#examples-5",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#examples-5",
    "title": "Color Scales",
    "section": "Examples",
    "text": "Examples\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile(width = 0.95, height = 0.95) + \n  coord_fixed(expand = FALSE) +\n  theme_classic() +\n  scale_fill_continuous_sequential(palette = \"YlGnBu\", rev = FALSE)"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#examples-6",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#examples-6",
    "title": "Color Scales",
    "section": "Examples",
    "text": "Examples\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile(width = 0.95, height = 0.95) + \n  coord_fixed(expand = FALSE) +\n  theme_classic() +\n  scale_fill_continuous_sequential(palette = \"Viridis\", rev = FALSE)"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#examples-7",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#examples-7",
    "title": "Color Scales",
    "section": "Examples",
    "text": "Examples\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile(width = 0.95, height = 0.95) + \n  coord_fixed(expand = FALSE) +\n  theme_classic() +\n  scale_fill_continuous_sequential(palette = \"Inferno\", begin = 0.15, rev = FALSE)"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#section",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#section",
    "title": "Color Scales",
    "section": "",
    "text": "colorspace::hcl_palettes(type = \"sequential\", plot = TRUE) # all sequential palettes"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#section-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#section-1",
    "title": "Color Scales",
    "section": "",
    "text": "colorspace::hcl_palettes(type = \"diverging\", plot = TRUE, n = 9) # all diverging palettes"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#section-2",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#section-2",
    "title": "Color Scales",
    "section": "",
    "text": "colorspace::divergingx_palettes(plot = TRUE, n = 9) # all divergingx palettes"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#discrete-qualitative-scales-are-best-set-manually",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#discrete-qualitative-scales-are-best-set-manually",
    "title": "Color Scales",
    "section": "Discrete, qualitative scales are best set manually",
    "text": "Discrete, qualitative scales are best set manually\n\nggplot(popgrowth, aes(x = pop2000, y = popgrowth, color = region)) +\n  geom_point() +\n  scale_x_log10()\n\n  # no color scale defined, default is scale_color_hue()"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#discrete-qualitative-scales-are-best-set-manually-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#discrete-qualitative-scales-are-best-set-manually-1",
    "title": "Color Scales",
    "section": "Discrete, qualitative scales are best set manually",
    "text": "Discrete, qualitative scales are best set manually\n\nggplot(popgrowth, aes(x = pop2000, y = popgrowth, color = region)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_hue()"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#discrete-qualitative-scales-are-best-set-manually-2",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#discrete-qualitative-scales-are-best-set-manually-2",
    "title": "Color Scales",
    "section": "Discrete, qualitative scales are best set manually",
    "text": "Discrete, qualitative scales are best set manually\n\nlibrary(ggthemes)  # for scale_color_colorblind()\n\nggplot(popgrowth, aes(x = pop2000, y = popgrowth, color = region)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_colorblind()  # uses Okabe-Ito colors"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#discrete-qualitative-scales-are-best-set-manually-3",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#discrete-qualitative-scales-are-best-set-manually-3",
    "title": "Color Scales",
    "section": "Discrete, qualitative scales are best set manually",
    "text": "Discrete, qualitative scales are best set manually\n\nggplot(popgrowth, aes(x = pop2000, y = popgrowth, color = region)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_manual(\n    values = c(West = \"#E69F00\", South = \"#56B4E9\", Midwest = \"#009E73\", Northeast = \"#F0E442\")\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#okabe-ito-rgb-codes",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#okabe-ito-rgb-codes",
    "title": "Color Scales",
    "section": "Okabe-Ito RGB codes",
    "text": "Okabe-Ito RGB codes\n\n\n\n\nName\nHex code   \nR, G, B (0-255)\n\n\n\n\norange\n#E69F00\n230, 159, 0\n\n\nsky blue\n#56B4E9\n86, 180, 233\n\n\nbluish green\n#009E73\n0, 158, 115\n\n\nyellow\n#F0E442\n240, 228, 66\n\n\nblue\n#0072B2\n0, 114, 178\n\n\nvermilion\n#D55E00\n213, 94, 0\n\n\nreddish purple\n#CC79A7\n204, 121, 167\n\n\nblack\n#000000\n0, 0, 0"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#be-aware-of-color-vision-deficiency",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#be-aware-of-color-vision-deficiency",
    "title": "Color Scales",
    "section": "Be aware of color-vision deficiency",
    "text": "Be aware of color-vision deficiency\n5%–8% of men are color blind!\n\nRed-green color-vision deficiency is the most common"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#be-aware-of-color-vision-deficiency-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#be-aware-of-color-vision-deficiency-1",
    "title": "Color Scales",
    "section": "Be aware of color-vision deficiency",
    "text": "Be aware of color-vision deficiency\n5%–8% of men are color blind!\n\nBlue-green color-vision deficiency is rare but does occur"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#be-aware-of-color-vision-deficiency-2",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#be-aware-of-color-vision-deficiency-2",
    "title": "Color Scales",
    "section": "Be aware of color-vision deficiency",
    "text": "Be aware of color-vision deficiency\nChoose colors that can be distinguished with CVD"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#consider-using-the-okabe-ito-scale-as-your-default",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#consider-using-the-okabe-ito-scale-as-your-default",
    "title": "Color Scales",
    "section": "Consider using the Okabe-Ito scale as your default",
    "text": "Consider using the Okabe-Ito scale as your default\n\n\n\n\nName\nHex code   \nR, G, B (0-255)\n\n\n\n\norange\n#E69F00\n230, 159, 0\n\n\nsky blue\n#56B4E9\n86, 180, 233\n\n\nbluish green\n#009E73\n0, 158, 115\n\n\nyellow\n#F0E442\n240, 228, 66\n\n\nblue\n#0072B2\n0, 114, 178\n\n\nvermilion\n#D55E00\n213, 94, 0\n\n\nreddish purple\n#CC79A7\n204, 121, 167\n\n\nblack\n#000000\n0, 0, 0"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#cvd-is-worse-for-thin-lines-and-tiny-dots",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#cvd-is-worse-for-thin-lines-and-tiny-dots",
    "title": "Color Scales",
    "section": "CVD is worse for thin lines and tiny dots",
    "text": "CVD is worse for thin lines and tiny dots"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#when-in-doubt-run-cvd-simulations",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#when-in-doubt-run-cvd-simulations",
    "title": "Color Scales",
    "section": "When in doubt, run CVD simulations",
    "text": "When in doubt, run CVD simulations"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#when-in-doubt-run-cvd-simulations-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/color_scales_slides.html#when-in-doubt-run-cvd-simulations-1",
    "title": "Color Scales",
    "section": "When in doubt, run CVD simulations",
    "text": "When in doubt, run CVD simulations\n\n\n\n\n\n\n\n\n\n\n\nthe colorspace\npackage can\nhelp"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_exercise_solutions.html",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_exercise_solutions.html",
    "title": "Compound Figures Exercise Solutions",
    "section": "",
    "text": "Coding exercise 7.3\nIn this worksheet, we will discuss how to combine several ggplot2 plots into one compound figure.\nWe will be using the R package tidyverse, which includes ggplot() and related functions. We will also be using the package patchwork for plot composition.\n\n# load required library\nlibrary(tidyverse)\nlibrary(patchwork)\n\nWe will be working with the dataset mtcars, which contains fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models).\n\nmtcars\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\n\nCombining plots\nFirst we set up four different plots that we will subsequently combine. The plots are stored in variables p1, p2, p3, p4.\n\np1 &lt;- ggplot(mtcars) + \n  geom_point(aes(mpg, disp))\np1  \n\n\n\np2 &lt;- ggplot(mtcars) + \n  geom_boxplot(aes(gear, disp, group = gear))\np2\n\n\n\np3 &lt;- ggplot(mtcars) + \n  geom_smooth(aes(disp, qsec))\np3\n\n\n\np4 &lt;- ggplot(mtcars) + \n  geom_bar(aes(carb))\np4\n\n\n\n\nTo show plots side-by-side, we use the operator |, as in p1 | p2. Try this by making a compound plot of plots p1, p2, p3 side-by-side.\n\n # build all the code for this exercisew\n\n  # solution \n p1 | p2 | p3\n\n\n\n\nTo show plots on top of one-another, we use the operator /, as in p1 / p2. Try this by making a compound plot of plots p1, p2, p3 on top of each other.\n\n # build all the code for this exercise\n\n  p1 / p2 / p3\n\n\n\n\nWe can also use parentheses to group plots with respect to the operators | and /. For example, we can place several plots side-by-side and then place this entire row of plots on top of another plot. Try putting p1, p2, p3, on the top row, and p4 on the bottom row.\n\n(___) / ___\n\n\n# solution\n(p1 | p2 | p3 ) / p4\n\n\n\nPlot annotations\nThe patchwork package provides a powerful annotation system via the plot_annotation() function that can be added to a plot assembly. For example, we can add plot tags (the labels in the upper left corner identifying the plots) via the plot annotation tag_levels. You can set tag_levels = \"A\" to generate tags A, B, C, etc. Try this out.\n\n(p1 | p2 | p3 ) / p4\n\n\n\n\n\n# solution\n(p1 | p2 | p3 ) / p4 +\n  plot_annotation(\n    tag_levels = \"A\"\n  )\n\n\n\n\nTry also tag levels such as \"a\", \"i\", or \"1\".\nYou can also add elements such as titles, subtitles, and captions, by setting the title, subtitle, or caption argument in plot_annotation(). Try this out by adding an overall title to the figure from the previous exercise.\n\n # build all the code for this exercise\n\n # solution\n(p1 | p2 | p3 ) / p4 +\n  plot_annotation(\n    tag_levels = \"A\",\n    title = \"Various observations about old cars\"\n  )\n\n\n\n\nAlso set a subtitle and a caption.\nFinally, you can change the theme of all plots in the plot assembly via the & operator, as in (p1 | p2) & theme_bw(). Try this out.\n\n # build all the code for this exercise\n\n# solution\n(p1 | p2) & theme_bw()\n\n\n\n\nWhat happens if you write this expression without parentheses? Do you understand why?\n(Big) Challenge Problem:\nIf you have time this morning, or if you want to work on it this afternoon, try analyzing a new dataset to test your R skills. First, learn what the columns mean, what missing values you see, and then start to ask questions about patterns in the data by making plots.\nYou can browse the datasets at https://github.com/rfordatascience/tidytuesday/tree/master/data (click on a year folder and go to the README to read about the datasets). Or pick from one of the ones below:\n\n# fish consumption in different countries \nconsumption &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-12/fish-and-seafood-consumption-per-capita.csv')\n\n# world cup Cricket matches from 1996 to 2005\nmatches &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-11-30/matches.csv')\n\n# malaria deaths by age across the world and time. \n malaria_deaths&lt;- readr::read_csv('https://github.com/rfordatascience/tidytuesday/blob/master/data/2018/2018-11-13/malaria_deaths_age.csv')\n\n#meteorites and/or volcanos:\n# note to plot a map, try the following:\ncountries_map &lt;- ggplot2::map_data(\"world\")\nworld_map&lt;-ggplot() + \n  geom_map(data = countries_map, \n           map = countries_map,aes(x = long, y = lat, map_id = region, group = group),\n           fill = \"white\", color = \"black\", size = 0.1) # then add geom_point() to this map to add lat/long points\n\nmeteorites &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv\")\nvolcano &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-12/volcano.csv\")\n\n# or pick any dataset from https://github.com/rfordatascience/tidytuesday/tree/master/data , \n# just click on a year folder and go to the README to read about the datasets\n# if you have trouble loading a dataset there, ask for help!"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#compound-figures",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#compound-figures",
    "title": "Compound Figures",
    "section": "Compound figures",
    "text": "Compound figures\nTwo common scenarios:"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#compound-figures-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#compound-figures-1",
    "title": "Compound Figures",
    "section": "Compound figures",
    "text": "Compound figures\nTwo common scenarios:\n\nThe same type of plot is replicated many times (small multiples)"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#compound-figures-2",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#compound-figures-2",
    "title": "Compound Figures",
    "section": "Compound figures",
    "text": "Compound figures\nTwo common scenarios:\n\nThe same type of plot is replicated many times (small multiples)\nSeveral disparate plots are combined into one display"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#small-multiples-facets",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#small-multiples-facets",
    "title": "Compound Figures",
    "section": "1. Small multiples (facets)",
    "text": "1. Small multiples (facets)"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#small-multiples-facets-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#small-multiples-facets-1",
    "title": "Compound Figures",
    "section": "1. Small multiples (facets)",
    "text": "1. Small multiples (facets)"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#small-multiples-facets-2",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#small-multiples-facets-2",
    "title": "Compound Figures",
    "section": "1. Small multiples (facets)",
    "text": "1. Small multiples (facets)\n\nAvoid bars or other elements that are floating in space"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#small-multiples-facets-3",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#small-multiples-facets-3",
    "title": "Compound Figures",
    "section": "1. Small multiples (facets)",
    "text": "1. Small multiples (facets)"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#y-axis-ranges-should-be-consistent-among-panels",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#y-axis-ranges-should-be-consistent-among-panels",
    "title": "Compound Figures",
    "section": "y-axis ranges should be consistent among panels",
    "text": "y-axis ranges should be consistent among panels"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#y-axis-ranges-should-be-consistent-among-panels-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#y-axis-ranges-should-be-consistent-among-panels-1",
    "title": "Compound Figures",
    "section": "y-axis ranges should be consistent among panels",
    "text": "y-axis ranges should be consistent among panels"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#combining-disparate-figures-into-one-display",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#combining-disparate-figures-into-one-display",
    "title": "Compound Figures",
    "section": "2. Combining disparate figures into one display",
    "text": "2. Combining disparate figures into one display"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#dont-use-overly-large-or-otherwise-prominent-labels",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#dont-use-overly-large-or-otherwise-prominent-labels",
    "title": "Compound Figures",
    "section": "Don’t use overly large or otherwise prominent labels",
    "text": "Don’t use overly large or otherwise prominent labels"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#use-a-consistent-color-language-among-sub-plots",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#use-a-consistent-color-language-among-sub-plots",
    "title": "Compound Figures",
    "section": "Use a consistent color language among sub-plots",
    "text": "Use a consistent color language among sub-plots"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#use-a-consistent-color-language-among-sub-plots-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#use-a-consistent-color-language-among-sub-plots-1",
    "title": "Compound Figures",
    "section": "Use a consistent color language among sub-plots",
    "text": "Use a consistent color language among sub-plots"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#pay-attention-to-sub-plot-alignment",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#pay-attention-to-sub-plot-alignment",
    "title": "Compound Figures",
    "section": "Pay attention to sub-plot alignment",
    "text": "Pay attention to sub-plot alignment"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#pay-attention-to-sub-plot-alignment-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#pay-attention-to-sub-plot-alignment-1",
    "title": "Compound Figures",
    "section": "Pay attention to sub-plot alignment",
    "text": "Pay attention to sub-plot alignment"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#combine-plots-of-different-types",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#combine-plots-of-different-types",
    "title": "Compound Figures",
    "section": "Combine plots of different types",
    "text": "Combine plots of different types\n\nThis helps your readers to distinguish different parts of the analysis"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#combine-plots-of-different-types-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#combine-plots-of-different-types-1",
    "title": "Compound Figures",
    "section": "Combine plots of different types",
    "text": "Combine plots of different types\n\nThis helps your readers to distinguish different parts of the analysis"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#combine-plots-of-different-types-2",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#combine-plots-of-different-types-2",
    "title": "Compound Figures",
    "section": "Combine plots of different types",
    "text": "Combine plots of different types\n\nThis helps your readers to distinguish different parts of the analysis"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#distinguish-infographics-from-figures-in-articlebook",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#distinguish-infographics-from-figures-in-articlebook",
    "title": "Compound Figures",
    "section": "Distinguish infographics from figures in article/book",
    "text": "Distinguish infographics from figures in article/book\n\nThere are two distinct use cases:"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#distinguish-infographics-from-figures-in-articlebook-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#distinguish-infographics-from-figures-in-articlebook-1",
    "title": "Compound Figures",
    "section": "Distinguish infographics from figures in article/book",
    "text": "Distinguish infographics from figures in article/book\n\nThere are two distinct use cases:\n\nInfographic: Standalone, has title/subtitle/caption"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#distinguish-infographics-from-figures-in-articlebook-2",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#distinguish-infographics-from-figures-in-articlebook-2",
    "title": "Compound Figures",
    "section": "Distinguish infographics from figures in article/book",
    "text": "Distinguish infographics from figures in article/book\n\nThere are two distinct use cases:\n\nInfographic: Standalone, has title/subtitle/caption\n\nFigure in article/book: Caption contains title, not part of figure"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#section-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#section-1",
    "title": "Compound Figures",
    "section": "",
    "text": "Example of infographic"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#section-2",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#section-2",
    "title": "Compound Figures",
    "section": "",
    "text": "Figure 1. Corruption and human development. The most developed countries experience the least corruption. Inspired by a posting in The Economist online (2011). Data sources: Transparency International & UN Human Development Report.\n\n\n\n\nExample of figure in article or book"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#the-patchwork-package",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#the-patchwork-package",
    "title": "Compound Figures",
    "section": "The patchwork package",
    "text": "The patchwork package\n\n\n\n\n\nlibrary(patchwork)\n\n# make first plot\np1 &lt;- ggplot(mtcars) + \n  geom_point(aes(mpg, disp))\n\np1"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#the-patchwork-package-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#the-patchwork-package-1",
    "title": "Compound Figures",
    "section": "The patchwork package",
    "text": "The patchwork package\n\n\n\n\n\nlibrary(patchwork)\n\n# make first plot\np1 &lt;- ggplot(mtcars) + \n  geom_point(aes(mpg, disp))\n\n# make second plot\np2 &lt;- ggplot(mtcars) + \n  aes(gear, disp, group = gear) +\n  geom_boxplot()\n\np2"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#the-patchwork-package-2",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#the-patchwork-package-2",
    "title": "Compound Figures",
    "section": "The patchwork package",
    "text": "The patchwork package\n\n\n\n\n\nlibrary(patchwork)\n\n# make first plot\np1 &lt;- ggplot(mtcars) + \n  geom_point(aes(mpg, disp))\n\n# make second plot\np2 &lt;- ggplot(mtcars) + \n  aes(gear, disp, group = gear) +\n  geom_boxplot()\n\n# place plots side-by-side \np1 | p2"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#the-patchwork-package-3",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#the-patchwork-package-3",
    "title": "Compound Figures",
    "section": "The patchwork package",
    "text": "The patchwork package\n\n\n\n\n\nlibrary(patchwork)\n\n# make first plot\np1 &lt;- ggplot(mtcars) + \n  geom_point(aes(mpg, disp))\n\n# make second plot\np2 &lt;- ggplot(mtcars) + \n  aes(gear, disp, group = gear) +\n  geom_boxplot()\n\n# place plots on top of one-another \np1 / p2"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#the-patchwork-package-4",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#the-patchwork-package-4",
    "title": "Compound Figures",
    "section": "The patchwork package",
    "text": "The patchwork package\n\n\n\n\n\n# add a few more plots\np3 &lt;- ggplot(mtcars) + \n  geom_smooth(aes(disp, qsec))\n\np4 &lt;- ggplot(mtcars) + \n  geom_bar(aes(carb))\n\n# make complex arrangement \n(p1 | p2 | p3) / p4"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#plot-annotations-and-themes",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#plot-annotations-and-themes",
    "title": "Compound Figures",
    "section": "Plot annotations and themes",
    "text": "Plot annotations and themes\n\n\n\n\n\n(p1 | p2 | p3) / p4 +\n   plot_annotation( \n     tag_levels = \"A\" \n   ) \n\n\n\n\n\n\n\n\n\nAutomatic labeling of plots"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#plot-annotations-and-themes-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#plot-annotations-and-themes-1",
    "title": "Compound Figures",
    "section": "Plot annotations and themes",
    "text": "Plot annotations and themes\n\n\n\n\n\n(p1 | p2 | p3) / p4 +\n   plot_annotation( \n     tag_levels = \"a\" \n   ) \n\n\n\n\n\n\n\n\n\nAutomatic labeling of plots"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#plot-annotations-and-themes-2",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#plot-annotations-and-themes-2",
    "title": "Compound Figures",
    "section": "Plot annotations and themes",
    "text": "Plot annotations and themes\n\n\n\n\n\n(p1 | p2 | p3) / p4 +\n  plot_annotation(\n   tag_levels = \"a\"\n  ) & \n  theme_minimal_grid() \n\n\n\n\n\n\n\n\n\nApplying one theme to all plots"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#plot-annotations-and-themes-3",
    "href": "materials/1-workshop1/7-custom-data-visualizations/compound_figures_slides.html#plot-annotations-and-themes-3",
    "title": "Compound Figures",
    "section": "Plot annotations and themes",
    "text": "Plot annotations and themes\n\n\n\n\n\n(p1 | p2 | p3) / p4 +\n  plot_annotation(\n   tag_levels = \"a\",\n   title = \"A plot about mtcars\", \n   subtitle = \"With subtitle...\", \n   caption = \"...and caption\" \n  ) &\n  theme_minimal_grid()\n\n\n\n\n\n\n\n\n\nTitles and captions"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_exercise_solutions.html",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_exercise_solutions.html",
    "title": "Figure Design Exercise Solutions",
    "section": "",
    "text": "Coding exercise 7.2\nIn this worksheet, we will discuss how to change and customize themes.\nWe will be using the R package tidyverse, which includes ggplot() and related functions. We will also be using the packages cowplot for themes and the package palmerpenguins for the penguins dataset.\n\n# load required library\nlibrary(tidyverse)\nlibrary(cowplot)\nlibrary(palmerpenguins)\n\nWe will be working with the dataset penguins containing data on individual penguins on Antarctica.\n\npenguins\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\nReady-made themes\nLet’s start with this simple plot with no specific styling.\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE)  # na.rm = TRUE prevents warning about missing values\n\n\n\n\nThe default ggplot theme is theme_gray(). Verify that adding this theme to the plot makes no difference in the output. Then change the overall font size by providing the theme function with a numeric font size argument, e.g. theme_gray(16).\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  ___\n\n\n# solution\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme_gray()\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme_gray(16)\n\n\n\n\nThe ggplot2 package has many built-in themes, including theme_minimal(), theme_bw(), theme_void(), theme_dark(). Try these different themes on the above plot. Also try again changing the font size. You can see all themes provided by ggplot2 here: https://ggplot2.tidyverse.org/reference/ggtheme.html\n\n # build all the code for this exercise\n #| eval: TRUE\n#| echo: TRUE\n\n # solution\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme_bw(12)\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme_minimal(14)\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme_void()\n\nMany other packages also provide themes. For example, the cowplot package provides themes theme_half_open(), theme_minimal_grid(), theme_minimal_hgrid(), and theme_minimal_vgrid(). You can see all cowplot themes here: https://wilkelab.org/cowplot/articles/themes.html\n\n #| eval: TRUE\n#| echo: TRUE\n # build all the code for this exercise\n\n  # solution\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme_half_open()\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme_minimal_grid()\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme_minimal_hgrid()\n\nCompare the visual appearance of theme_minimal() from ggplot2 to theme_minimal_grid() from cowplot. What similarities and differences to you notice? Which do you prefer? (There is no correct answer here, just be aware of the differences and of your preferences.)\n\n #| eval: TRUE\n#| echo: TRUE\n # build all the code for this exercise\n\n  # solution\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme_minimal()\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme_minimal_grid()\n\n\n\nModifying theme elements\nYou can modify theme elements by adding a theme() call to the plot. Inside the theme() call you specify which theme element you want to modify (e.g., axis.title, axis.text.x, panel.background, etc) and what changes you want to make. For example, to make axis titles blue, you would write:\n\ntheme(\n  axis.title = element_text(color = \"blue\")\n)\n\nThere are many theme settings, and for each one you need to know what type of an element it is (element_text(), element_line(), element_rect() for text, lines, or rectangles, respectively). A complete description of the available options is available at the ggplot2 website: https://ggplot2.tidyverse.org/reference/theme.html\nHere, we will only try a few simple things. For example, see if you can make the legend title blue and the legend text red.\n\n# make the legend title blue and the legend text red\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE)\n\n\n\n\nNow color the area behind the legend in \"aliceblue\". Hint: The theme element you need to change is called legend.background. There is also an element legend.box.background but it is only visible if legend.background is not shown, and in the default ggplot2 themes that is not the case.\n\n # build all the code for this exercise\n\n # solution\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme(\n    legend.background = element_rect(fill = \"aliceblue\")\n  )\n\n\n\n\nAnother commonly used feature in themes are margins. Many parts of the plot theme can understand customized margins, which control how much spacing there is between different parts of a plot. Margins are typically specified with the function margin(), which takes four numbers specifying the margins in points, in the order top, right, bottom, left. So, margin(10, 5, 5, 10) would specify a top margin of 10pt, a right margin of 5pt, a bottom margin of 5pt, and a left margin of 10pt.\nTry this out by setting the legend margin (element legend.margin) such that there is no top and no bottom margin but 10pt left and right margin.\n\n # build all the code for this exercise\n\n # solution \nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme(\n    legend.background = element_rect(fill = \"aliceblue\"),\n    legend.margin = margin(0, 10, 0, 10)\n  )\n\n\n\n\nThere are many other things you can do. Try at least some of the following:\n\nChange the horizontal or vertical justification of text with hjust and vjust.\nChange the font family with family.1\nChange the panel grid. For example, create only horizontal lines, or only vertical lines.\nChange the overall margin of the plot with plot.margin.\nMove the position of the legend with legend.position and legend.justification.\nTurn off some elements by setting them to element_blank().\n\n1 Getting fonts to work well can be tricky in R. Which specific fonts work depends on the graphics device and the operating system. You can try some of the following fonts and see if they work on app.terra.bio: \"Palatino\", \"Times\", \"Helvetica\", \"Courier\", \"ITC Bookman\", \"ITC Avant Garde Gothic\", \"ITC Zapf Chancery\".\n\n\nWriting your own theme\nYou can write a theme by\n\ntheme_colorful &lt;-\n  theme_bw() +\n  theme(\n    text = element_text(color = \"mediumblue\"),\n    axis.text = element_text(color = \"springgreen4\"),\n    legend.text = element_text(color = \"firebrick4\")\n  )\n\nHint: Do you have to add theme_colorful or theme_colorful()? Do you understand which option is correct and why? If you are unsure, try both and see what happens.\n\n # build all the code for this exercise\n\n # solution\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme_colorful\n\n\n\n\nNow write your own theme and then add it to the penguing plot.\n\n # build all the code for this exercise\n\n # solution\n\nmytheme &lt;- theme_minimal_grid() +\n  theme(\n    panel.border = element_rect(size = 1, color = \"black\"),\n    legend.box.background = element_rect(size = 0.5, color = \"black\")\n  )\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  mytheme"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#section",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#section",
    "title": "Figure Design",
    "section": "",
    "text": "How to go from this …\n\n\n… to this?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRequires coordinated modification of multiple elements:\n- geoms (via arguments to geoms)\n- scales (via scale_*() functions)\n- plot appearance (via themes)"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#the-starting-point-a-rough-draft",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#the-starting-point-a-rough-draft",
    "title": "Figure Design",
    "section": "The starting point, a rough draft",
    "text": "The starting point, a rough draft\n\n\n\n\n\nggplot(lincoln_temps) +\n  aes(x = mean_temp, y = month_long) +\n  geom_density_ridges()\n\n\n\n\n\n\n\n\n\nYou can download the dataset using this code:\n\n\n\n\n\n\n\n\nlincoln_temps &lt;- readRDS(\n  url(\"https://wilkelab.org/DSC385/datasets/lincoln_temps.rds\")\n)"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#set-scale-and-bandwidth-to-shape-ridgelines",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#set-scale-and-bandwidth-to-shape-ridgelines",
    "title": "Figure Design",
    "section": "Set scale and bandwidth to shape ridgelines",
    "text": "Set scale and bandwidth to shape ridgelines\n\n\n\n\n\nggplot(lincoln_temps) +\n  aes(x = mean_temp, y = month_long) +\n  geom_density_ridges(\n    scale = 3, bandwidth = 3.4\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#set-rel_min_height-to-cut-ridgelines-near-zero",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#set-rel_min_height-to-cut-ridgelines-near-zero",
    "title": "Figure Design",
    "section": "Set rel_min_height to cut ridgelines near zero",
    "text": "Set rel_min_height to cut ridgelines near zero\n\n\n\n\n\nggplot(lincoln_temps) +\n  aes(x = mean_temp, y = month_long) +\n  geom_density_ridges(\n    scale = 3, bandwidth = 3.4,\n    rel_min_height = 0.01\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#use-scale_-functions-to-specify-axis-labels",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#use-scale_-functions-to-specify-axis-labels",
    "title": "Figure Design",
    "section": "Use scale_*() functions to specify axis labels",
    "text": "Use scale_*() functions to specify axis labels\n\n\n\n\n\nggplot(lincoln_temps) +\n  aes(x = mean_temp, y = month_long) +\n  geom_density_ridges(\n    scale = 3, bandwidth = 3.4,\n    rel_min_height = 0.01,\n  ) +\n  scale_x_continuous(\n    name = \"mean temperature (°F)\"\n  ) +\n  scale_y_discrete(\n    name = NULL  # NULL means no label\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#specify-scale-expansion",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#specify-scale-expansion",
    "title": "Figure Design",
    "section": "Specify scale expansion",
    "text": "Specify scale expansion\n\n\n\n\n\nggplot(lincoln_temps) +\n  aes(x = mean_temp, y = month_long) +\n  geom_density_ridges(\n    scale = 3, bandwidth = 3.4,\n    rel_min_height = 0.01\n  ) +\n  scale_x_continuous(\n    name = \"mean temperature (°F)\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(\n    name = NULL,\n    expand = expansion(add = c(0.2, 2.6))\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#set-overall-plot-theme",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#set-overall-plot-theme",
    "title": "Figure Design",
    "section": "Set overall plot theme",
    "text": "Set overall plot theme\n\n\n\n\n\nggplot(lincoln_temps) +\n  aes(x = mean_temp, y = month_long) +\n  geom_density_ridges(\n    scale = 3, bandwidth = 3.4,\n    rel_min_height = 0.01\n  ) +\n  scale_x_continuous(\n    name = \"mean temperature (°F)\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(\n    name = NULL,\n    expand = expansion(add = c(0.2, 2.6))\n  ) +\n  theme_minimal_grid()  # from cowplot"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#align-y-axis-labels-to-grid-lines",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#align-y-axis-labels-to-grid-lines",
    "title": "Figure Design",
    "section": "Align y axis labels to grid lines",
    "text": "Align y axis labels to grid lines\n\n\n\n\n\nggplot(lincoln_temps) +\n  aes(x = mean_temp, y = month_long) +\n  geom_density_ridges(\n    scale = 3, bandwidth = 3.4,\n    rel_min_height = 0.01\n  ) +\n  scale_x_continuous(\n    name = \"mean temperature (°F)\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(\n    name = NULL,\n    expand = expansion(add = c(0.2, 2.6))\n  ) +\n  theme_minimal_grid() +\n  theme(\n    axis.text.y = element_text(vjust = 0)\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#change-fill-color-from-default-gray-to-blue",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#change-fill-color-from-default-gray-to-blue",
    "title": "Figure Design",
    "section": "Change fill color from default gray to blue",
    "text": "Change fill color from default gray to blue\n\n\n\n\n\nggplot(lincoln_temps) +\n  aes(x = mean_temp, y = month_long) +\n  geom_density_ridges(\n    scale = 3, bandwidth = 3.4,\n    rel_min_height = 0.01,\n    fill = \"#7DCCFF\"\n  ) +\n  scale_x_continuous(\n    name = \"mean temperature (°F)\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(\n    name = NULL,\n    expand = expansion(add = c(0.2, 2.6))\n  ) +\n  theme_minimal_grid() +\n  theme(\n    axis.text.y = element_text(vjust = 0)\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#draw-lines-in-white-instead-of-black",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#draw-lines-in-white-instead-of-black",
    "title": "Figure Design",
    "section": "Draw lines in white instead of black",
    "text": "Draw lines in white instead of black\n\n\n\n\n\nggplot(lincoln_temps) +\n  aes(x = mean_temp, y = month_long) +\n  geom_density_ridges(\n    scale = 3, bandwidth = 3.4,\n    rel_min_height = 0.01,\n    fill = \"#7DCCFF\",\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"mean temperature (°F)\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(\n    name = NULL,\n    expand = expansion(add = c(0.2, 2.6))\n  ) +\n  theme_minimal_grid() +\n  theme(\n    axis.text.y = element_text(vjust = 0)\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes",
    "title": "Figure Design",
    "section": "Using ready-made themes",
    "text": "Using ready-made themes\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point()\n# default theme is theme_gray()"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-1",
    "title": "Figure Design",
    "section": "Using ready-made themes",
    "text": "Using ready-made themes\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point() + \n  theme_gray()"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-2",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-2",
    "title": "Figure Design",
    "section": "Using ready-made themes",
    "text": "Using ready-made themes\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point() + \n  theme_gray(14) # most themes take a font-size argument to scale text size"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-3",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-3",
    "title": "Figure Design",
    "section": "Using ready-made themes",
    "text": "Using ready-made themes\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point() + \n  theme_bw(14)"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-4",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-4",
    "title": "Figure Design",
    "section": "Using ready-made themes",
    "text": "Using ready-made themes\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point() + \n  theme_minimal(14)"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-5",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-5",
    "title": "Figure Design",
    "section": "Using ready-made themes",
    "text": "Using ready-made themes\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point() + \n  theme_classic(14)"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-6",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-6",
    "title": "Figure Design",
    "section": "Using ready-made themes",
    "text": "Using ready-made themes\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point() + \n  theme_half_open()  # from package cowplot"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-7",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-7",
    "title": "Figure Design",
    "section": "Using ready-made themes",
    "text": "Using ready-made themes\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point() + \n  theme_minimal_grid()  # from package cowplot"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-8",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-8",
    "title": "Figure Design",
    "section": "Using ready-made themes",
    "text": "Using ready-made themes\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point() + \n  theme_minimal_hgrid()  # from package cowplot"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-9",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-9",
    "title": "Figure Design",
    "section": "Using ready-made themes",
    "text": "Using ready-made themes\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point() + \n  theme_minimal_vgrid()  # from package cowplot"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-10",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-10",
    "title": "Figure Design",
    "section": "Using ready-made themes",
    "text": "Using ready-made themes\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point() + \n  theme_economist(14)       # from package ggthemes"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-11",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-11",
    "title": "Figure Design",
    "section": "Using ready-made themes",
    "text": "Using ready-made themes\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point() + \n  theme_economist(14) + scale_color_economist() # from package ggthemes"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-12",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#using-ready-made-themes-12",
    "title": "Figure Design",
    "section": "Using ready-made themes",
    "text": "Using ready-made themes\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point() + \n  theme_fivethirtyeight(14) + scale_color_fivethirtyeight() # from package ggthemes"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#customizing-theme-elements",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#customizing-theme-elements",
    "title": "Figure Design",
    "section": "Customizing theme elements",
    "text": "Customizing theme elements\n\n\n\n\n\nggplot(penguins) +\n  aes(flipper_length_mm, body_mass_g) +\n  geom_point(aes(color = species)) +\n  theme_minimal_grid()"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#customizing-theme-elements-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#customizing-theme-elements-1",
    "title": "Figure Design",
    "section": "Customizing theme elements",
    "text": "Customizing theme elements\n\n\n\n\n\nggplot(penguins) +\n  aes(flipper_length_mm, body_mass_g) +\n  geom_point(aes(color = species)) +\n  theme_minimal_grid() +\n  theme(\n    # change overall font family\n    # (requires font to be available)\n    text = element_text(\n      family = \"Comic Sans MS\"\n    )\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#customizing-theme-elements-2",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#customizing-theme-elements-2",
    "title": "Figure Design",
    "section": "Customizing theme elements",
    "text": "Customizing theme elements\n\n\n\n\n\nggplot(penguins) +\n  aes(flipper_length_mm, body_mass_g) +\n  geom_point(aes(color = species)) +\n  theme_minimal_grid() +\n  theme(\n    # change color of axis titles\n    axis.title = element_text(\n      color = \"royalblue2\"\n    )\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#customizing-theme-elements-3",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#customizing-theme-elements-3",
    "title": "Figure Design",
    "section": "Customizing theme elements",
    "text": "Customizing theme elements\n\n\n\n\n\nggplot(penguins) +\n  aes(flipper_length_mm, body_mass_g) +\n  geom_point(aes(color = species)) +\n  theme_minimal_grid() +\n  theme(\n    # change color of only the x axis title\n    axis.title.x = element_text(\n      color = \"royalblue2\"\n    )\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#customizing-theme-elements-4",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#customizing-theme-elements-4",
    "title": "Figure Design",
    "section": "Customizing theme elements",
    "text": "Customizing theme elements\n\n\n\n\n\nggplot(penguins) +\n  aes(flipper_length_mm, body_mass_g) +\n  geom_point(aes(color = species)) +\n  theme_minimal_grid() +\n  theme(\n    # change all text colors?\n    # why does it not work?\n    text = element_text(color = \"royalblue2\")\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#customizing-theme-elements-5",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#customizing-theme-elements-5",
    "title": "Figure Design",
    "section": "Customizing theme elements",
    "text": "Customizing theme elements\n\n\n\n\n\nggplot(penguins) +\n  aes(flipper_length_mm, body_mass_g) +\n  geom_point(aes(color = species)) +\n  theme_minimal_grid() +\n  theme(\n    text = element_text(color = \"royalblue2\"),\n    axis.text = element_text(\n      color = \"royalblue2\"\n    )\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#customizing-theme-elements-6",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#customizing-theme-elements-6",
    "title": "Figure Design",
    "section": "Customizing theme elements",
    "text": "Customizing theme elements\n\n\n\n\n\nggplot(penguins) +\n  aes(flipper_length_mm, body_mass_g) +\n  geom_point(aes(color = species)) +\n  theme_minimal_grid() +\n  theme(\n    text = element_text(color = \"royalblue2\"),\n    axis.text = element_text(\n      color = \"royalblue2\"\n    )\n  )\n\n\n\n\n\n\n\n\nThe element axis.text has its own color set in the theme. Therefore it doesn’t inherit from text."
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#horizontal-and-vertical-alignment",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#horizontal-and-vertical-alignment",
    "title": "Figure Design",
    "section": "Horizontal and vertical alignment",
    "text": "Horizontal and vertical alignment\n\n\n\n\n\nggplot(penguins) +\n  aes(flipper_length_mm, body_mass_g) +\n  geom_point(aes(color = species)) +\n  theme_minimal_grid() +\n  theme(\n    axis.title.x = element_text(\n      # horizontal justification\n      # (0 = left)\n      hjust = 0\n    )\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#horizontal-and-vertical-alignment-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#horizontal-and-vertical-alignment-1",
    "title": "Figure Design",
    "section": "Horizontal and vertical alignment",
    "text": "Horizontal and vertical alignment\n\n\n\n\n\nggplot(penguins) +\n  aes(flipper_length_mm, body_mass_g) +\n  geom_point(aes(color = species)) +\n  theme_minimal_grid() +\n  theme(\n    axis.title.x = element_text(\n      # horizontal justification\n      # (0.5 = center)\n      hjust = 0.5\n    )\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#horizontal-and-vertical-alignment-2",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#horizontal-and-vertical-alignment-2",
    "title": "Figure Design",
    "section": "Horizontal and vertical alignment",
    "text": "Horizontal and vertical alignment\n\n\n\n\n\nggplot(penguins) +\n  aes(flipper_length_mm, body_mass_g) +\n  geom_point(aes(color = species)) +\n  theme_minimal_grid() +\n  theme(\n    axis.title.x = element_text(\n      # horizontal justification\n      # (1 = right)\n      hjust = 1\n    )\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#horizontal-and-vertical-alignment-3",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#horizontal-and-vertical-alignment-3",
    "title": "Figure Design",
    "section": "Horizontal and vertical alignment",
    "text": "Horizontal and vertical alignment\n\n\n\n\n\nggplot(penguins) +\n  aes(flipper_length_mm, body_mass_g) +\n  geom_point(aes(color = species)) +\n  theme_minimal_grid() +\n  theme(\n    axis.text.y = element_text(\n      # vertical justification\n      # (0 = bottom)\n      vjust = 0\n    )\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#horizontal-and-vertical-alignment-4",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#horizontal-and-vertical-alignment-4",
    "title": "Figure Design",
    "section": "Horizontal and vertical alignment",
    "text": "Horizontal and vertical alignment\n\n\n\n\n\nggplot(penguins) +\n  aes(flipper_length_mm, body_mass_g) +\n  geom_point(aes(color = species)) +\n  theme_minimal_grid() +\n  theme(\n    axis.text.y = element_text(\n      # vertical justification\n      # (0.5 = center)\n      vjust = 0.5\n    )\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#horizontal-and-vertical-alignment-5",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#horizontal-and-vertical-alignment-5",
    "title": "Figure Design",
    "section": "Horizontal and vertical alignment",
    "text": "Horizontal and vertical alignment\n\n\n\n\n\nggplot(penguins) +\n  aes(flipper_length_mm, body_mass_g) +\n  geom_point(aes(color = species)) +\n  theme_minimal_grid() +\n  theme(\n    axis.text.y = element_text(\n      # vertical justification\n      # (1 = top)\n      vjust = 1\n    )\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#remove-elements-entirely-element_blank",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#remove-elements-entirely-element_blank",
    "title": "Figure Design",
    "section": "Remove elements entirely: element_blank()",
    "text": "Remove elements entirely: element_blank()\n\n\n\n\n\nggplot(penguins) +\n  aes(flipper_length_mm, body_mass_g) +\n  geom_point(aes(color = species)) +\n  theme_minimal_grid() +\n  theme(\n    # all text gone\n    text = element_blank()\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#remove-elements-entirely-element_blank-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#remove-elements-entirely-element_blank-1",
    "title": "Figure Design",
    "section": "Remove elements entirely: element_blank()",
    "text": "Remove elements entirely: element_blank()\n\n\n\n\n\nggplot(penguins) +\n  aes(flipper_length_mm, body_mass_g) +\n  geom_point(aes(color = species)) +\n  theme_minimal_grid() +\n  theme(\n    # no axis titles\n    axis.title = element_blank()\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#set-background-color-element_rect",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#set-background-color-element_rect",
    "title": "Figure Design",
    "section": "Set background color: element_rect()",
    "text": "Set background color: element_rect()\n\n\n\n\n\nggplot(penguins) +\n  aes(flipper_length_mm, body_mass_g) +\n  geom_point(aes(color = species)) +\n  theme_minimal_grid() +\n  theme(\n    plot.background = element_rect(\n      fill = \"aliceblue\"\n    )\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#set-background-color-element_rect-1",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#set-background-color-element_rect-1",
    "title": "Figure Design",
    "section": "Set background color: element_rect()",
    "text": "Set background color: element_rect()\n\n\n\n\n\nggplot(penguins) +\n  aes(flipper_length_mm, body_mass_g) +\n  geom_point(aes(color = species)) +\n  theme_minimal_grid() +\n  theme(\n    panel.background = element_rect(\n      fill = \"aliceblue\"\n    )\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#set-background-color-element_rect-2",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#set-background-color-element_rect-2",
    "title": "Figure Design",
    "section": "Set background color: element_rect()",
    "text": "Set background color: element_rect()\n\n\n\n\n\nggplot(penguins) +\n  aes(flipper_length_mm, body_mass_g) +\n  geom_point(aes(color = species)) +\n  theme_minimal_grid() +\n  theme(\n    legend.box.background = element_rect(\n      fill = \"aliceblue\",\n      color = \"steelblue4\" # line color\n    )\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#set-background-color-element_rect-3",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#set-background-color-element_rect-3",
    "title": "Figure Design",
    "section": "Set background color: element_rect()",
    "text": "Set background color: element_rect()\n\n\n\n\n\nggplot(penguins) +\n  aes(flipper_length_mm, body_mass_g) +\n  geom_point(aes(color = species)) +\n  theme_minimal_grid() +\n  theme(\n    legend.box.background = element_rect(\n      fill = \"aliceblue\",\n      color = \"steelblue4\" # line color\n    ),\n    legend.box.margin = margin(7, 7, 7, 7)\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#move-the-legend-legend.position",
    "href": "materials/1-workshop1/7-custom-data-visualizations/figure_design_slides.html#move-the-legend-legend.position",
    "title": "Figure Design",
    "section": "Move the legend: legend.position",
    "text": "Move the legend: legend.position\n\n\n\n\n\nggplot(penguins) +\n  aes(flipper_length_mm, body_mass_g) +\n  geom_point(aes(color = species)) +\n  theme_minimal_grid() +\n  theme(\n    legend.box.background = element_rect(\n      fill = \"aliceblue\", \n      color = \"steelblue4\" # line color\n    ),\n    legend.box.margin = margin(7, 7, 7, 7),\n    # relative position inside plot panel\n    legend.position = c(1, 0),\n    # justification relative to position\n    legend.justification = c(1, 0)\n  )"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/index.html",
    "href": "materials/1-workshop1/7-custom-data-visualizations/index.html",
    "title": "Customizing data visualizations using colorspace, ggplot2, and patchwork",
    "section": "",
    "text": "Learn how to change ggplot’s default choices for color and style and take control of final figure presentation."
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/index.html#color-scales",
    "href": "materials/1-workshop1/7-custom-data-visualizations/index.html#color-scales",
    "title": "Customizing data visualizations using colorspace, ggplot2, and patchwork",
    "section": "Color Scales",
    "text": "Color Scales\nMake slides full screen\n\n\nCoding exercise 7.1\nIn this worksheet, we will discuss how to change and customize color scales.\nWe will be using the R package tidyverse, which includes ggplot() and related functions. We will also be using the R package colorspace for the scale functions it provides.\n\n# load required library\nlibrary(tidyverse)\nlibrary(colorspace)\n\ntemperatures &lt;- read_csv(\"https://wilkelab.org/SDS375/datasets/tempnormals.csv\") %&gt;%\n  mutate(\n    location = factor(\n      location, levels = c(\"Death Valley\", \"Houston\", \"San Diego\", \"Chicago\")\n    )\n  ) %&gt;%\n  select(location, day_of_year, month, temperature)\n\ntemps_months &lt;- read_csv(\"https://wilkelab.org/SDS375/datasets/tempnormals.csv\") %&gt;%\n  group_by(location, month_name) %&gt;%\n  summarize(mean = mean(temperature)) %&gt;%\n  mutate(\n    month = factor(\n      month_name,\n      levels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\")\n    ),\n    location = factor(\n      location, levels = c(\"Death Valley\", \"Houston\", \"San Diego\", \"Chicago\")\n    )\n  ) %&gt;%\n  select(-month_name)\n\nWe will be working with the dataset temperatures that we have used in previous worksheets. This dataset contains the average temperature for each day of the year for four different locations.\n\ntemperatures\n\n# A tibble: 1,464 × 4\n   location     day_of_year month temperature\n   &lt;fct&gt;              &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;\n 1 Death Valley           1 01           51  \n 2 Death Valley           2 01           51.2\n 3 Death Valley           3 01           51.3\n 4 Death Valley           4 01           51.4\n 5 Death Valley           5 01           51.6\n 6 Death Valley           6 01           51.7\n 7 Death Valley           7 01           51.9\n 8 Death Valley           8 01           52  \n 9 Death Valley           9 01           52.2\n10 Death Valley          10 01           52.3\n# ℹ 1,454 more rows\n\n\nWe will also be working with an aggregated version of this dataset called temps_months, which contains the mean temperature for each month for the same locations.\n\ntemps_months\n\n# A tibble: 48 × 3\n# Groups:   location [4]\n   location  mean month\n   &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;\n 1 Chicago   50.4 Apr  \n 2 Chicago   74.1 Aug  \n 3 Chicago   29   Dec  \n 4 Chicago   28.9 Feb  \n 5 Chicago   24.8 Jan  \n 6 Chicago   75.8 Jul  \n 7 Chicago   71.0 Jun  \n 8 Chicago   38.8 Mar  \n 9 Chicago   60.9 May  \n10 Chicago   41.6 Nov  \n# ℹ 38 more rows\n\n\nAs a challenge, try to create this above table yourself using group_by() and summarize() like we learned about Wednesday., and then make a month column which is a factor with levels froing from “Jan” to “Dec”, and make the location column a factor with levels “Death Valley”, “Houston”, “San Diego”, “Chicago”. If you are having trouble, the solution is at the end of this page, make sure you copy it into your code so the rest of the exercise works.\n\n# check solution at the end before moving on!\ntemps_months &lt;- read_csv(\"https://wilkelab.org/SDS375/datasets/tempnormals.csv\") %&gt;%\n  group_by(___) %&gt;%\n  summarize(___) %&gt;%\n  mutate(\n    month = factor(\n      month_name,\n      ___\n    ),\n    location = factor(\n      location, ___\n    )\n  ) %&gt;%\n  select(-month_name)\n\n\nBuilt in ggplot2 color scales\nWe will start with built-in ggplot2 color scales, which require no additional packages. The scale functions are always named scale_color_*() or scale_fill_*(), depending on whether they apply to the color or fill aesthetic. The * indicates some other words specifying the type of the scale, for example scale_color_brewer() or scale_color_distiller() for discrete or continuous scales from the ColorBrewer project, respectively. You can find all available built-in scales here: https://ggplot2.tidyverse.org/reference/index.html#section-scales\nNow consider the following plot.\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE)\n\n\n\n\nIf you wanted to change the color scale to one from the ColorBrewer project, which scale function would you have to add? scale_color_brewer(), scale_color_distiller(), scale_fill_brewer(), scale_fill_distiller()?\n\n # answer the question above to yourself\n\nNow try this out.\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  ___\n\nMost color scale functions have additional customizations. How to use them depends on the specific scale function. For the ColorBrewer scales you can set direction = 1 or direction = -1 to set the direction of the scale (light to dark or dark to light). You can also set the palette via a numeric argument, e.g. palette = 1, palette = 2, palette = 3 etc.\nTry this out by setting the direction of the scale from light to dark and using palette #4.\n\n # build all the code for this exercise\n\nA popular set of scales are the viridis scales, which are provided by scale_*_viridis_c() for continuous data and scale_*_viridis_d() for discrete data. Change the above plot to use a viridis scale.\n\n # build all the code for this exercise\n\nThe viridis scales can be customized with direction (as before), option (which can be \"A\", \"B\", \"C\", \"D\", or \"E\"), and begin and end which are numerical values between 0 and 1 indicating where in the color scale the data should begin or end. For example, begin = 0.2 means that the lowest data value is mapped to the 20th percentile in the scale.\nTry different choices for option, begin, and end to see how they change the plot.\n\n # build all the code for this exercise\n\n\n\nCustomizing scale title and labels\nIn a previous worksheet, we used arguments such as name, breaks, labels, and limits to customize the axis. For color scales, instead of an axis we have a legend, and we can use the same arguments inside the scale function to customize how the legend looks.\nTry this out. Set the scale limits from 10 to 110 and set the name of the scale and the breaks as you wish.\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_viridis_c(\n    name = ___,\n    breaks = ___,\n    limits = ___\n  )\n\nNote: Color scales ignore the expand argument, so you cannot use it to expand the scale beyond the data values as you can for position scales.\n\n\nBinned scales\nResearch into human perception has shown that continuous coloring can be difficult to interpret. Therefore, it is often preferable to use a small number of discrete colors to indicate ranges of data values. You can do this in ggplot with binned scales. For example, scale_fill_viridis_b() provides a binned version of the viridis scale. Try this out.\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  ___\n\nYou can change the number of bins by providing the n.breaks argument or alternatively by setting breaks explicitly. Try this out.\n\n # build all the code for this exercise\n\n\n\nScales from the colorspace package\nThe color scales provided by the colorspace package follow a simple naming scheme of the form scale_&lt;aesthetic&gt;_&lt;datatype&gt;_&lt;colorscale&gt;(), where &lt;aesthetic&gt; is the name of the aesthetic (fill, color, colour), &lt;datatype&gt; indicates the type of variable plotted (discrete, continuous, binned), and colorscale stands for the type of the color scale (qualitative, sequential, diverging, divergingx).\nFor the mean temperature plot we have been using throughout this worksheet, which 2 color scales from the colorspace package is/are appropriate?\nscale_fill_binned_sequential(), scale_fill_discrete_qualitative(), scale_fill_continuous_sequential(), scale_color_continuous_sequential(), scale_color_continuous_diverging()&gt;\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  ___\n\nYou can customize the colorspace scales with the palette argument, which takes the name of a palette (e.g., \"Inferno\", \"BluYl\", \"Lajolla\"). Try this out. Also try reversing the scale direction with rev = TRUE or rev = FALSE. (The colorspace scales use rev instead of direction.) You can find the names of all supported scales here (consider specifically single-hue and multi-hue sequential palettes).\n\n # build all the code for this exercise\n\nYou can also use begin and end just like in the viridis scales.\n\n\nManual scales\nFor discrete data with a small number of categories, it’s usually best to set colors manually. This can be done with the scale functions scale_*_manual(). These functions take an argument values that specifies the color values to use.\nTo see how this works, let’s go back to this plot of temperatures over time for four locations.\n\nggplot(temperatures, aes(day_of_year, temperature, color = location)) +\n  geom_line(size = 1.5)\n\n\n\n\nLet’s use the following four colors: \"gold2\", \"firebrick\", \"blue3\", \"springgreen4\". We can visualize this palette using the function swatchplot() from the colorspace package.\n\ncolorspace::swatchplot(c(\"gold2\", \"firebrick\", \"blue3\", \"springgreen4\"))\n\n\n\n\nNow apply this color palette to the temperatures plot, by using the manual color scale. Hint: use the values argument to provide the colors to the manual scale.\n\nggplot(temperatures, aes(day_of_year, temperature, color = location)) +\n  geom_line(size = 1.5) +\n  ___\n\nOne problem with this approach is that we can’t easily control which data value gets assigned to which color. What if we wanted San Diego to be shown in green and Chicago in blue? The simplest way to resolve this issue is to use a named vector. A named vector in R is a vector where each value has a name. Named vectors are created by writing c(name1 = value1, name2 = value2, ...). See the following example.\n\n# regular vector\nc(\"cat\", \"mouse\", \"house\")\n\n[1] \"cat\"   \"mouse\" \"house\"\n\n# named vector\nc(A = \"cat\", B = \"mouse\", C = \"house\")\n\n      A       B       C \n  \"cat\" \"mouse\" \"house\" \n\n\nThe names in the second example are A, B, and C. Notice that the names are not in quotes. However, if you need a name containing a space (such as Death Valley), you need to enclose the name in backticks. Thus, our named vector of colors could be written like so:\n\nc(`Death Valley` = \"gold2\", Houston = \"firebrick\", Chicago = \"blue3\", `San Diego` = \"springgreen4\")\n\n  Death Valley        Houston        Chicago      San Diego \n       \"gold2\"    \"firebrick\"        \"blue3\" \"springgreen4\" \n\n\nNow try to use this color vector in the figure showing temperatures over time.\n\n # build all the code for this exercise\n\nTry some other colors also. For example, you could use the Okabe-Ito colors:\n\n# Okabe-Ito colors\ncolorspace::swatchplot(c(\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\", \"#000000\"))\n\n\n\n\nAlternatively, you can find a list of all named colors here. You can also run the command colors() in your R console to get a list of all available color names.\nHint: It’s a good idea to never use the colors \"red\", \"green\", \"blue\", \"cyan\", \"magenta\", \"yellow\". They are extreme points in the RGB color space and tend to look unnatural and too crazy. Try this by making a swatch plot of these colors, and compare for example to the color scale containing the colors \"firebrick\", \"springgreen4\", \"blue3\", \"turquoise3\", \"darkorchid2\", \"gold2\". Do you see the difference?\n\n # build all the code for this exercise\n\nSolution to the challenge to make the summary table of mean temperature by month:\n\n# paste this below the \"temperatures\" code-chunk\ntemps_months &lt;- read_csv(\"https://wilkelab.org/SDS375/datasets/tempnormals.csv\") %&gt;%\n  group_by(location, month_name) %&gt;%\n  summarize(mean = mean(temperature)) %&gt;%\n  mutate(\n    month = factor(\n      month_name,\n      levels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\")\n    ),\n    location = factor(\n      location, levels = c(\"Death Valley\", \"Houston\", \"San Diego\", \"Chicago\")\n    )\n  ) %&gt;%\n  select(-month_name)\n\nColor Scales Exercise Solutions"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/index.html#figure-design",
    "href": "materials/1-workshop1/7-custom-data-visualizations/index.html#figure-design",
    "title": "Customizing data visualizations using colorspace, ggplot2, and patchwork",
    "section": "Figure Design",
    "text": "Figure Design\nMake slides full screen\n\n\nCoding exercise 7.2\nIn this worksheet, we will discuss how to change and customize themes.\nWe will be using the R package tidyverse, which includes ggplot() and related functions. We will also be using the packages cowplot for themes and the package palmerpenguins for the penguins dataset.\n\n# load required library\nlibrary(tidyverse)\nlibrary(cowplot)\nlibrary(palmerpenguins)\n\nWe will be working with the dataset penguins containing data on individual penguins on Antarctica.\n\npenguins\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\nReady-made themes\nLet’s start with this simple plot with no specific styling.\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE)  # na.rm = TRUE prevents warning about missing values\n\n\n\n\nThe default ggplot theme is theme_gray(). Verify that adding this theme to the plot makes no difference in the output. Then change the overall font size by providing the theme function with a numeric font size argument, e.g. theme_gray(16).\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  ___\n\nThe ggplot2 package has many built-in themes, including theme_minimal(), theme_bw(), theme_void(), theme_dark(). Try these different themes on the above plot. Also try again changing the font size. You can see all themes provided by ggplot2 here: https://ggplot2.tidyverse.org/reference/ggtheme.html\n\n # build all the code for this exercise\n\nMany other packages also provide themes. For example, the cowplot package provides themes theme_half_open(), theme_minimal_grid(), theme_minimal_hgrid(), and theme_minimal_vgrid(). You can see all cowplot themes here: https://wilkelab.org/cowplot/articles/themes.html\n\n # build all the code for this exercise\n\nCompare the visual appearance of theme_minimal() from ggplot2 to theme_minimal_grid() from cowplot. What similarities and differences to you notice? Which do you prefer? (There is no correct answer here, just be aware of the differences and of your preferences.)\n\n # build all the code for this exercise\n\n\n\nModifying theme elements\nYou can modify theme elements by adding a theme() call to the plot. Inside the theme() call you specify which theme element you want to modify (e.g., axis.title, axis.text.x, panel.background, etc) and what changes you want to make. For example, to make axis titles blue, you would write:\n\ntheme(\n  axis.title = element_text(color = \"blue\")\n)\n\nThere are many theme settings, and for each one you need to know what type of an element it is (element_text(), element_line(), element_rect() for text, lines, or rectangles, respectively). A complete description of the available options is available at the ggplot2 website: https://ggplot2.tidyverse.org/reference/theme.html\nHere, we will only try a few simple things. For example, see if you can make the legend title blue and the legend text red.\n\n# make the legend title blue and the legend text red\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE)\n\n\n\n\nNow color the area behind the legend in \"aliceblue\". Hint: The theme element you need to change is called legend.background. There is also an element legend.box.background but it is only visible if legend.background is not shown, and in the default ggplot2 themes that is not the case.\n\n # build all the code for this exercise\n\nAnother commonly used feature in themes are margins. Many parts of the plot theme can understand customized margins, which control how much spacing there is between different parts of a plot. Margins are typically specified with the function margin(), which takes four numbers specifying the margins in points, in the order top, right, bottom, left. So, margin(10, 5, 5, 10) would specify a top margin of 10pt, a right margin of 5pt, a bottom margin of 5pt, and a left margin of 10pt.\nTry this out by setting the legend margin (element legend.margin) such that there is no top and no bottom margin but 10pt left and right margin.\n\n # build all the code for this exercise\n\nThere are many other things you can do. Try at least some of the following:\n\nChange the horizontal or vertical justification of text with hjust and vjust.\nChange the font family with family.1\nChange the panel grid. For example, create only horizontal lines, or only vertical lines.\nChange the overall margin of the plot with plot.margin.\nMove the position of the legend with legend.position and legend.justification.\nTurn off some elements by setting them to element_blank().\n\n1 Getting fonts to work well can be tricky in R. Which specific fonts work depends on the graphics device and the operating system. You can try some of the following fonts and see if they work on app.terra.bio: \"Palatino\", \"Times\", \"Helvetica\", \"Courier\", \"ITC Bookman\", \"ITC Avant Garde Gothic\", \"ITC Zapf Chancery\".\n\n\nWriting your own theme\nYou can write a theme by\n\ntheme_colorful &lt;-\n  theme_bw() +\n  theme(\n    text = element_text(color = \"mediumblue\"),\n    axis.text = element_text(color = \"springgreen4\"),\n    legend.text = element_text(color = \"firebrick4\")\n  )\n\nHint: Do you have to add theme_colorful or theme_colorful()? Do you understand which option is correct and why? If you are unsure, try both and see what happens.\n\n # build all the code for this exercise\n\nNow write your own theme and then add it to the penguing plot.\n\n # build all the code for this exercise\n\nFigure Design Exercise Solutions"
  },
  {
    "objectID": "materials/1-workshop1/7-custom-data-visualizations/index.html#compound-figures",
    "href": "materials/1-workshop1/7-custom-data-visualizations/index.html#compound-figures",
    "title": "Customizing data visualizations using colorspace, ggplot2, and patchwork",
    "section": "Compound Figures",
    "text": "Compound Figures\nMake slides full screen\n\n\nCoding exercise 7.3\nIn this worksheet, we will discuss how to combine several ggplot2 plots into one compound figure.\nWe will be using the R package tidyverse, which includes ggplot() and related functions. We will also be using the package patchwork for plot composition.\n\n# load required library\nlibrary(tidyverse)\nlibrary(patchwork)\n\nWe will be working with the dataset mtcars, which contains fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models).\n\nmtcars\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\n\nCombining plots\nFirst we set up four different plots that we will subsequently combine. The plots are stored in variables p1, p2, p3, p4.\n\np1 &lt;- ggplot(mtcars) + \n  geom_point(aes(mpg, disp))\np1  \n\n\n\np2 &lt;- ggplot(mtcars) + \n  geom_boxplot(aes(gear, disp, group = gear))\np2\n\n\n\np3 &lt;- ggplot(mtcars) + \n  geom_smooth(aes(disp, qsec))\np3\n\n\n\np4 &lt;- ggplot(mtcars) + \n  geom_bar(aes(carb))\np4\n\n\n\n\nTo show plots side-by-side, we use the operator |, as in p1 | p2. Try this by making a compound plot of plots p1, p2, p3 side-by-side.\n\n # build all the code for this exercise\n\nTo show plots on top of one-another, we use the operator /, as in p1 / p2. Try this by making a compound plot of plots p1, p2, p3 on top of each other.\n\n # build all the code for this exercise\n\nWe can also use parentheses to group plots with respect to the operators | and /. For example, we can place several plots side-by-side and then place this entire row of plots on top of another plot. Try putting p1, p2, p3, on the top row, and p4 on the bottom row.\n\n(___) / ___\n\n\n\nPlot annotations\nThe patchwork package provides a powerful annotation system via the plot_annotation() function that can be added to a plot assembly. For example, we can add plot tags (the labels in the upper left corner identifying the plots) via the plot annotation tag_levels. You can set tag_levels = \"A\" to generate tags A, B, C, etc. Try this out.\n\n(p1 | p2 | p3 ) / p4\n\n\n\n\nTry also tag levels such as \"a\", \"i\", or \"1\".\nYou can also add elements such as titles, subtitles, and captions, by setting the title, subtitle, or caption argument in plot_annotation(). Try this out by adding an overall title to the figure from the previous exercise.\n\n # build all the code for this exercise\n\nAlso set a subtitle and a caption.\nFinally, you can change the theme of all plots in the plot assembly via the & operator, as in (p1 | p2) & theme_bw(). Try this out.\n\n # build all the code for this exercise\n\nWhat happens if you write this expression without parentheses? Do you understand why?\n(Big) Challenge Problem:\nIf you have time this morning, or if you want to work on it this afternoon, try analyzing a new dataset to test your R skills. First, learn what the columns mean, what missing values you see, and then start to ask questions about patterns in the data by making plots.\nYou can browse the datasets at https://github.com/rfordatascience/tidytuesday/tree/master/data (click on a year folder and go to the README to read about the datasets). Or pick from one of the ones below:\n\n# fish consumption in different countries \nconsumption &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-12/fish-and-seafood-consumption-per-capita.csv')\n\n# world cup Cricket matches from 1996 to 2005\nmatches &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-11-30/matches.csv')\n\n# malaria deaths by age across the world and time. \n malaria_deaths&lt;- readr::read_csv('https://github.com/rfordatascience/tidytuesday/blob/master/data/2018/2018-11-13/malaria_deaths_age.csv')\n\n#meteorites and/or volcanos:\n# note to plot a map, try the following:\ncountries_map &lt;- ggplot2::map_data(\"world\")\nworld_map&lt;-ggplot() + \n  geom_map(data = countries_map, \n           map = countries_map,aes(x = long, y = lat, map_id = region, group = group),\n           fill = \"white\", color = \"black\", size = 0.1) # then add geom_point() to this map to add lat/long points\n\nmeteorites &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv\")\nvolcano &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-12/volcano.csv\")\n\n# or pick any dataset from https://github.com/rfordatascience/tidytuesday/tree/master/data , \n# just click on a year folder and go to the README to read about the datasets\n# if you have trouble loading a dataset there, ask for help!\n\nCompound Figures Exercise Solutions"
  },
  {
    "objectID": "materials/1-workshop1/group-projects/exercise_1.html#activity",
    "href": "materials/1-workshop1/group-projects/exercise_1.html#activity",
    "title": "Exploring Data for Patterns",
    "section": "Activity",
    "text": "Activity\n\nPatterns are the essence of data exploration and our eyes’ ability to pick them out is integral to data understanding. Much of the data we work with, however, do not have a natural form and we need to make decisions about how they are to be represented. Try different ways to visualize the datasets so meaningful patterns may be found.\n\n\nGenetic profiles of cancer\nThese datasets contains 10 cancer samples. Table 1 describes the mutational status for a set of genes (A-E) and whether a mutation if absent (0) or present (1). Table 2 summarizes the expression levels of those genes, ranging from no expression (0) to high expression (3).\n\n\nTable 1: Mutational status for a set of genes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsample -&gt;\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\nGene A\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n\n\nGene B\n0\n0\n0\n0\n1\n1\n1\n0\n1\n1\n\n\nGene C\n0\n0\n1\n0\n0\n0\n1\n1\n1\n1\n\n\nGene D\n1\n1\n0\n0\n1\n1\n0\n0\n0\n0\n\n\nGene E\n0\n1\n1\n0\n1\n0\n0\n0\n1\n0\n\n\n\n\n\n\nTable 2: Expression levels for a set of genes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsample -&gt;\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\nGene A\n2\n1\n1\n2\n2\n0\n2\n1\n1\n2\n\n\nGene B\n1\n1\n2\n1\n0\n0\n0\n2\n0\n0\n\n\nGene C\n1\n1\n3\n1\n2\n2\n3\n0\n3\n0\n\n\nGene D\n0\n0\n2\n1\n3\n3\n2\n1\n1\n1\n\n\nGene E\n1\n3\n3\n1\n3\n1\n2\n1\n3\n2\n\n\n\n\n\n\n          1. Think about the problem on your own for 5 minutes.\n          2. In your groups, discuss and create different visualizations to highlight underlying patterns\n          3. Summarize the group’s approach\n          4. Elect/volunteer a spokesperson to present the solution\n\n\nConsider the following concepts when creating your visualizations\n\n\n\n\nPatterns\nPatterns are the essence of data exploration. What kinds of representation will produce the most meaningful insights?\n   \n\n\nEncodings\nSome visual estimations are easier to make than others. How might you use encodings that are less accurate but otherwise better at conveying overall trends?\n  \n\n\n\n\nColor\nColor is a powerful encoding that presents several challenges. Have you chosen a color scale that is optimal for that data type?\n   \n\n\nSalience and Relevance\nPop-out effects enable quick recognition. Are the most noticeable elements of your visualizations also the most relevant?"
  },
  {
    "objectID": "materials/1-workshop1/group-projects/index.html",
    "href": "materials/1-workshop1/group-projects/index.html",
    "title": "Group Projects",
    "section": "",
    "text": "This is a randomized controlled trial to study whether yogurt consumption has an effect on the microbiome post antibiotic treatment. Absolute abundance of bacteria was measured by 3 qPCR assays (for total, L. crispatus, L. iners). Cytokine levels (in copies/ml of vaginal fluid) were also measured by Luminex. We also looked at the number and type of immune cells in the vagina using Flow Cytometry. Data was collected at two timepoints, pre and post antibiotic treatment.\n\n\n\nTo investigate whether the consumption of yogurt influences microbiome composition after antibiotics treatment.\n\n\n\n\n\n\nThis is an observational study to evaluate the relationship between birth control and vaginal inflammation In response to menstruation. Absolute abundance of bacteria was measured by 3 qPCR assays (for total Bacteria, L. crispatus, L. iners). Cytokine levels (in copies/ml of vaginal fluid) were also measured by Luminex. We also looked at the number and type of immune cells in the vagina using Flow Cytometry. Data was collected at four timepoints; before, at the start, the end, and after menstruation.\n\n\n\nTo investigate whether taking birth control is associated with vaginal inflammation throughout the menstrual cycle.\n\n\n\n\nSession Structure - 1:30-2:00\nRead Research Project.\nDownload project data files\n- 2:00-3:00\nLoad the demographic table into an R tibble.\nMake notes about what each column name is and what it means.\nExamine and note basic parameters (using R commands) - number of participants, visit structure, number of features measured for each, type of data measured (binary, categorical)\nPlot a histogram of all numeric features (eg, distribution of age) and bar plots for counts of categorical variables (eg. how many female).\n- 3:00 - 3:30 - Break\n- 3:30 - 5:00\nPreproccessing the data to prepare for tableone\nUse tableone for the dataset"
  },
  {
    "objectID": "materials/1-workshop1/group-projects/index.html#research-project-a---does-eating-yogurt-change-the-vaginal-microbiome",
    "href": "materials/1-workshop1/group-projects/index.html#research-project-a---does-eating-yogurt-change-the-vaginal-microbiome",
    "title": "Group Projects",
    "section": "",
    "text": "This is a randomized controlled trial to study whether yogurt consumption has an effect on the microbiome post antibiotic treatment. Absolute abundance of bacteria was measured by 3 qPCR assays (for total, L. crispatus, L. iners). Cytokine levels (in copies/ml of vaginal fluid) were also measured by Luminex. We also looked at the number and type of immune cells in the vagina using Flow Cytometry. Data was collected at two timepoints, pre and post antibiotic treatment.\n\n\n\nTo investigate whether the consumption of yogurt influences microbiome composition after antibiotics treatment."
  },
  {
    "objectID": "materials/1-workshop1/group-projects/index.html#research-project-b---does-birth-control-change-inflammation-during-menses",
    "href": "materials/1-workshop1/group-projects/index.html#research-project-b---does-birth-control-change-inflammation-during-menses",
    "title": "Group Projects",
    "section": "",
    "text": "This is an observational study to evaluate the relationship between birth control and vaginal inflammation In response to menstruation. Absolute abundance of bacteria was measured by 3 qPCR assays (for total Bacteria, L. crispatus, L. iners). Cytokine levels (in copies/ml of vaginal fluid) were also measured by Luminex. We also looked at the number and type of immune cells in the vagina using Flow Cytometry. Data was collected at four timepoints; before, at the start, the end, and after menstruation.\n\n\n\nTo investigate whether taking birth control is associated with vaginal inflammation throughout the menstrual cycle."
  },
  {
    "objectID": "materials/1-workshop1/group-projects/index.html#wednesday-pm-session",
    "href": "materials/1-workshop1/group-projects/index.html#wednesday-pm-session",
    "title": "Group Projects",
    "section": "",
    "text": "Session Structure - 1:30-2:00\nRead Research Project.\nDownload project data files\n- 2:00-3:00\nLoad the demographic table into an R tibble.\nMake notes about what each column name is and what it means.\nExamine and note basic parameters (using R commands) - number of participants, visit structure, number of features measured for each, type of data measured (binary, categorical)\nPlot a histogram of all numeric features (eg, distribution of age) and bar plots for counts of categorical variables (eg. how many female).\n- 3:00 - 3:30 - Break\n- 3:30 - 5:00\nPreproccessing the data to prepare for tableone\nUse tableone for the dataset"
  },
  {
    "objectID": "materials/1-workshop1/group-projects/slides.html#even-numbered-groups",
    "href": "materials/1-workshop1/group-projects/slides.html#even-numbered-groups",
    "title": "Welcome to the workshop",
    "section": "Even Numbered Groups:",
    "text": "Even Numbered Groups:\n\n\nback to module"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Please install R and RStudio on your laptop. If you already have R and Rstudio installed, please make sure they are up-to date. Please install R version 4.3.1 and RStudio version 2023.09.0 Click here for instructions on installing R and RStudio"
  },
  {
    "objectID": "resources.html#before-the-workshop-installing-r-and-rstudio",
    "href": "resources.html#before-the-workshop-installing-r-and-rstudio",
    "title": "Resources",
    "section": "",
    "text": "Please install R and RStudio on your laptop. If you already have R and Rstudio installed, please make sure they are up-to date. Please install R version 4.3.1 and RStudio version 2023.09.0 Click here for instructions on installing R and RStudio"
  },
  {
    "objectID": "resources.html#textbooks",
    "href": "resources.html#textbooks",
    "title": "Resources",
    "section": "Textbooks",
    "text": "Textbooks\n\nR for Data Science: Import, Tidy, Transform, Visualize, and Model Data by Garrett Grolemund and Hadley Wickham\nLink"
  },
  {
    "objectID": "resources.html#definitions-from-glosario",
    "href": "resources.html#definitions-from-glosario",
    "title": "Resources",
    "section": "Definitions from Glosario",
    "text": "Definitions from Glosario\nFurther definitions at Glosario\nArgument: one of possibly several expressions that are passed to a function. Oftentimes parameter and arugument are used interchangably, even though techincally parameter refers to the variable and argument refers to the value.\nAssignment operator: Symbol that assigns values on the right to an object on the left. Looks like &lt;-. Keyboard shortcut is Alt + -\nComment: Text written in a script that is not treated as code to be run, but rather as text that describes what the code is doing. These are usually short notes, beginning with a #\nComprehensive R Archive Network (CRAN): A public repository of R packages.\nData frame: A two-dimensional data structure for storing tabular data in memory. Rows represent records and columns represent variables.\nFunction: A code block which gathers a sequence of operations into a whole, preserving it for ongoing use by defining a set of tasks that takes zero or more required and optional arguments as inputs and returns expected outputs (return values), if any. Functions enable repeating these defined tasks with one command, known as a function call.\nNA: A special value used to represent data that is not available.\nPipe operator: The %&gt;% used to make the output of one function the input of the next.\nPackage: A collection of code, data, and documentation that can be distributed and re-used. Also referred to in some languages as a library or module.\nParameter: A variable specified in a function definition whose value is passed to the function when the function is called. Parameters and arguments are distinct, but related concepts. Parameters are variables and arguments are the values assigned to those variables. In practice though these terms are often used interchangeably.\nPositional argument: An argument to a function that gets its value according to its place in the function’s definition, as opposed to a named argument that is explicitly matched by name.\nReproducible research: The practice of describing and documenting research results in such a way that another researcher or person can re-run the analysis code on the same data to obtain the same result.\nTibble: A modern replacement for R’s data frame, which stores tabular data in columns and rows, defined and used in the tidyverse. Almost always when you are working with a data frame, you are actually working with a tibble.\nTidy data: Tabular data that satisfies three conditions that facilitate initial cleaning, and later exploration and analysis—(1) each variable forms a column, (2) each observation forms a row, and (3) each type of observation unit forms a table.\nTidyverse: A collection of R packages for operating on tabular data in consistent ways.\nVariable: A name in a program that has some data associated with it. A variable’s value can be changed after definition.\nVector: A sequence of values that have all the same type. Vectors are the fundamental data structure in R; a scalar is just a vector with exactly one element."
  }
]